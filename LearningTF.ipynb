{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据获取，预处理的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        index = np.random.randint(0, np.shape(self.train_data)[0], batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型类   tf.keras.layers    tf.keras.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        outputs = tf.nn.softmax(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练 tf.keras.losses     tf.keras.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "data_loader = MNISTLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 2.438133\n",
      "batch 1: loss 2.273934\n",
      "batch 2: loss 2.355415\n",
      "batch 3: loss 2.272263\n",
      "batch 4: loss 2.181853\n",
      "batch 5: loss 2.091420\n",
      "batch 6: loss 2.146718\n",
      "batch 7: loss 1.954695\n",
      "batch 8: loss 1.872318\n",
      "batch 9: loss 1.837145\n",
      "batch 10: loss 1.738694\n",
      "batch 11: loss 1.768432\n",
      "batch 12: loss 1.792785\n",
      "batch 13: loss 1.599320\n",
      "batch 14: loss 1.419369\n",
      "batch 15: loss 1.598553\n",
      "batch 16: loss 1.366261\n",
      "batch 17: loss 1.573335\n",
      "batch 18: loss 1.518774\n",
      "batch 19: loss 1.447316\n",
      "batch 20: loss 1.315905\n",
      "batch 21: loss 1.121393\n",
      "batch 22: loss 1.279834\n",
      "batch 23: loss 1.298772\n",
      "batch 24: loss 1.272601\n",
      "batch 25: loss 1.194776\n",
      "batch 26: loss 1.077628\n",
      "batch 27: loss 1.015672\n",
      "batch 28: loss 1.130749\n",
      "batch 29: loss 0.904288\n",
      "batch 30: loss 0.868203\n",
      "batch 31: loss 1.070194\n",
      "batch 32: loss 0.845088\n",
      "batch 33: loss 0.907807\n",
      "batch 34: loss 1.161140\n",
      "batch 35: loss 0.839448\n",
      "batch 36: loss 0.846559\n",
      "batch 37: loss 0.854337\n",
      "batch 38: loss 0.764163\n",
      "batch 39: loss 0.887984\n",
      "batch 40: loss 0.906739\n",
      "batch 41: loss 0.798458\n",
      "batch 42: loss 0.910937\n",
      "batch 43: loss 0.855616\n",
      "batch 44: loss 0.585795\n",
      "batch 45: loss 0.579261\n",
      "batch 46: loss 0.772566\n",
      "batch 47: loss 0.729631\n",
      "batch 48: loss 0.735790\n",
      "batch 49: loss 0.656435\n",
      "batch 50: loss 0.597649\n",
      "batch 51: loss 0.663039\n",
      "batch 52: loss 0.510023\n",
      "batch 53: loss 0.499862\n",
      "batch 54: loss 0.494033\n",
      "batch 55: loss 0.544600\n",
      "batch 56: loss 0.448335\n",
      "batch 57: loss 0.638516\n",
      "batch 58: loss 0.604804\n",
      "batch 59: loss 0.729415\n",
      "batch 60: loss 0.677040\n",
      "batch 61: loss 0.626605\n",
      "batch 62: loss 0.491739\n",
      "batch 63: loss 0.401254\n",
      "batch 64: loss 0.505679\n",
      "batch 65: loss 0.549666\n",
      "batch 66: loss 0.472011\n",
      "batch 67: loss 0.391300\n",
      "batch 68: loss 0.481433\n",
      "batch 69: loss 0.427748\n",
      "batch 70: loss 0.454326\n",
      "batch 71: loss 0.479060\n",
      "batch 72: loss 0.560769\n",
      "batch 73: loss 0.513042\n",
      "batch 74: loss 0.623688\n",
      "batch 75: loss 0.584088\n",
      "batch 76: loss 0.305610\n",
      "batch 77: loss 0.537162\n",
      "batch 78: loss 0.457372\n",
      "batch 79: loss 0.553968\n",
      "batch 80: loss 0.552805\n",
      "batch 81: loss 0.631978\n",
      "batch 82: loss 0.421002\n",
      "batch 83: loss 0.408457\n",
      "batch 84: loss 0.426940\n",
      "batch 85: loss 0.641052\n",
      "batch 86: loss 0.538270\n",
      "batch 87: loss 0.655626\n",
      "batch 88: loss 0.585133\n",
      "batch 89: loss 0.362141\n",
      "batch 90: loss 0.491092\n",
      "batch 91: loss 0.528893\n",
      "batch 92: loss 0.365695\n",
      "batch 93: loss 0.427899\n",
      "batch 94: loss 0.396822\n",
      "batch 95: loss 0.486486\n",
      "batch 96: loss 0.376068\n",
      "batch 97: loss 0.324289\n",
      "batch 98: loss 0.373019\n",
      "batch 99: loss 0.484427\n",
      "batch 100: loss 0.526129\n",
      "batch 101: loss 0.306415\n",
      "batch 102: loss 0.491502\n",
      "batch 103: loss 0.633292\n",
      "batch 104: loss 0.239512\n",
      "batch 105: loss 0.450287\n",
      "batch 106: loss 0.455829\n",
      "batch 107: loss 0.619721\n",
      "batch 108: loss 0.431831\n",
      "batch 109: loss 0.518706\n",
      "batch 110: loss 0.570356\n",
      "batch 111: loss 0.353023\n",
      "batch 112: loss 0.367920\n",
      "batch 113: loss 0.304495\n",
      "batch 114: loss 0.346282\n",
      "batch 115: loss 0.376834\n",
      "batch 116: loss 0.562499\n",
      "batch 117: loss 0.311001\n",
      "batch 118: loss 0.375378\n",
      "batch 119: loss 0.254141\n",
      "batch 120: loss 0.314147\n",
      "batch 121: loss 0.325226\n",
      "batch 122: loss 0.508045\n",
      "batch 123: loss 0.281079\n",
      "batch 124: loss 0.610761\n",
      "batch 125: loss 0.344365\n",
      "batch 126: loss 0.270095\n",
      "batch 127: loss 0.357540\n",
      "batch 128: loss 0.322686\n",
      "batch 129: loss 0.472495\n",
      "batch 130: loss 0.355530\n",
      "batch 131: loss 0.357027\n",
      "batch 132: loss 0.421519\n",
      "batch 133: loss 0.281695\n",
      "batch 134: loss 0.406415\n",
      "batch 135: loss 0.376335\n",
      "batch 136: loss 0.408592\n",
      "batch 137: loss 0.562565\n",
      "batch 138: loss 0.374444\n",
      "batch 139: loss 0.404912\n",
      "batch 140: loss 0.368146\n",
      "batch 141: loss 0.384058\n",
      "batch 142: loss 0.322231\n",
      "batch 143: loss 0.403678\n",
      "batch 144: loss 0.684385\n",
      "batch 145: loss 0.217335\n",
      "batch 146: loss 0.314305\n",
      "batch 147: loss 0.360131\n",
      "batch 148: loss 0.518104\n",
      "batch 149: loss 0.209907\n",
      "batch 150: loss 0.301047\n",
      "batch 151: loss 0.198820\n",
      "batch 152: loss 0.344176\n",
      "batch 153: loss 0.303229\n",
      "batch 154: loss 0.510377\n",
      "batch 155: loss 0.260007\n",
      "batch 156: loss 0.358598\n",
      "batch 157: loss 0.287488\n",
      "batch 158: loss 0.323987\n",
      "batch 159: loss 0.237868\n",
      "batch 160: loss 0.356839\n",
      "batch 161: loss 0.444150\n",
      "batch 162: loss 0.478256\n",
      "batch 163: loss 0.276759\n",
      "batch 164: loss 0.370414\n",
      "batch 165: loss 0.300027\n",
      "batch 166: loss 0.252645\n",
      "batch 167: loss 0.727026\n",
      "batch 168: loss 0.373942\n",
      "batch 169: loss 0.271110\n",
      "batch 170: loss 0.440862\n",
      "batch 171: loss 0.178916\n",
      "batch 172: loss 0.384037\n",
      "batch 173: loss 0.527184\n",
      "batch 174: loss 0.153302\n",
      "batch 175: loss 0.314974\n",
      "batch 176: loss 0.325381\n",
      "batch 177: loss 0.242675\n",
      "batch 178: loss 0.512615\n",
      "batch 179: loss 0.314081\n",
      "batch 180: loss 0.348190\n",
      "batch 181: loss 0.449995\n",
      "batch 182: loss 0.286771\n",
      "batch 183: loss 0.341908\n",
      "batch 184: loss 0.188381\n",
      "batch 185: loss 0.371664\n",
      "batch 186: loss 0.421966\n",
      "batch 187: loss 0.465618\n",
      "batch 188: loss 0.272382\n",
      "batch 189: loss 0.336649\n",
      "batch 190: loss 0.231243\n",
      "batch 191: loss 0.456238\n",
      "batch 192: loss 0.233720\n",
      "batch 193: loss 0.340474\n",
      "batch 194: loss 0.414229\n",
      "batch 195: loss 0.556327\n",
      "batch 196: loss 0.376129\n",
      "batch 197: loss 0.485123\n",
      "batch 198: loss 0.295609\n",
      "batch 199: loss 0.250386\n",
      "batch 200: loss 0.654060\n",
      "batch 201: loss 0.379937\n",
      "batch 202: loss 0.195739\n",
      "batch 203: loss 0.323643\n",
      "batch 204: loss 0.444458\n",
      "batch 205: loss 0.440228\n",
      "batch 206: loss 0.272547\n",
      "batch 207: loss 0.473063\n",
      "batch 208: loss 0.283304\n",
      "batch 209: loss 0.205437\n",
      "batch 210: loss 0.435948\n",
      "batch 211: loss 0.261455\n",
      "batch 212: loss 0.413870\n",
      "batch 213: loss 0.297635\n",
      "batch 214: loss 0.308065\n",
      "batch 215: loss 0.502612\n",
      "batch 216: loss 0.198151\n",
      "batch 217: loss 0.283178\n",
      "batch 218: loss 0.278689\n",
      "batch 219: loss 0.437698\n",
      "batch 220: loss 0.314116\n",
      "batch 221: loss 0.448801\n",
      "batch 222: loss 0.464349\n",
      "batch 223: loss 0.270449\n",
      "batch 224: loss 0.309777\n",
      "batch 225: loss 0.310389\n",
      "batch 226: loss 0.235379\n",
      "batch 227: loss 0.310438\n",
      "batch 228: loss 0.243087\n",
      "batch 229: loss 0.360618\n",
      "batch 230: loss 0.200849\n",
      "batch 231: loss 0.398437\n",
      "batch 232: loss 0.355892\n",
      "batch 233: loss 0.185135\n",
      "batch 234: loss 0.251383\n",
      "batch 235: loss 0.250367\n",
      "batch 236: loss 0.370542\n",
      "batch 237: loss 0.433988\n",
      "batch 238: loss 0.523187\n",
      "batch 239: loss 0.501677\n",
      "batch 240: loss 0.264653\n",
      "batch 241: loss 0.373035\n",
      "batch 242: loss 0.431061\n",
      "batch 243: loss 0.404923\n",
      "batch 244: loss 0.232195\n",
      "batch 245: loss 0.298294\n",
      "batch 246: loss 0.164826\n",
      "batch 247: loss 0.512169\n",
      "batch 248: loss 0.248187\n",
      "batch 249: loss 0.241578\n",
      "batch 250: loss 0.172155\n",
      "batch 251: loss 0.303348\n",
      "batch 252: loss 0.258336\n",
      "batch 253: loss 0.296446\n",
      "batch 254: loss 0.269398\n",
      "batch 255: loss 0.322465\n",
      "batch 256: loss 0.127607\n",
      "batch 257: loss 0.456600\n",
      "batch 258: loss 0.334284\n",
      "batch 259: loss 0.151064\n",
      "batch 260: loss 0.245607\n",
      "batch 261: loss 0.393236\n",
      "batch 262: loss 0.340045\n",
      "batch 263: loss 0.332729\n",
      "batch 264: loss 0.316913\n",
      "batch 265: loss 0.376373\n",
      "batch 266: loss 0.167389\n",
      "batch 267: loss 0.227646\n",
      "batch 268: loss 0.251785\n",
      "batch 269: loss 0.396557\n",
      "batch 270: loss 0.315055\n",
      "batch 271: loss 0.086060\n",
      "batch 272: loss 0.213583\n",
      "batch 273: loss 0.561623\n",
      "batch 274: loss 0.258989\n",
      "batch 275: loss 0.226629\n",
      "batch 276: loss 0.201005\n",
      "batch 277: loss 0.257511\n",
      "batch 278: loss 0.321448\n",
      "batch 279: loss 0.192312\n",
      "batch 280: loss 0.198569\n",
      "batch 281: loss 0.330429\n",
      "batch 282: loss 0.353858\n",
      "batch 283: loss 0.124349\n",
      "batch 284: loss 0.215555\n",
      "batch 285: loss 0.267969\n",
      "batch 286: loss 0.305862\n",
      "batch 287: loss 0.309428\n",
      "batch 288: loss 0.372545\n",
      "batch 289: loss 0.394427\n",
      "batch 290: loss 0.281316\n",
      "batch 291: loss 0.311124\n",
      "batch 292: loss 0.250308\n",
      "batch 293: loss 0.572158\n",
      "batch 294: loss 0.222825\n",
      "batch 295: loss 0.200602\n",
      "batch 296: loss 0.245502\n",
      "batch 297: loss 0.184442\n",
      "batch 298: loss 0.323770\n",
      "batch 299: loss 0.325532\n",
      "batch 300: loss 0.227077\n",
      "batch 301: loss 0.199917\n",
      "batch 302: loss 0.201870\n",
      "batch 303: loss 0.310121\n",
      "batch 304: loss 0.173529\n",
      "batch 305: loss 0.439019\n",
      "batch 306: loss 0.205707\n",
      "batch 307: loss 0.402398\n",
      "batch 308: loss 0.466951\n",
      "batch 309: loss 0.305474\n",
      "batch 310: loss 0.423163\n",
      "batch 311: loss 0.322422\n",
      "batch 312: loss 0.357728\n",
      "batch 313: loss 0.349832\n",
      "batch 314: loss 0.293370\n",
      "batch 315: loss 0.292821\n",
      "batch 316: loss 0.380522\n",
      "batch 317: loss 0.295116\n",
      "batch 318: loss 0.412484\n",
      "batch 319: loss 0.244656\n",
      "batch 320: loss 0.391263\n",
      "batch 321: loss 0.123716\n",
      "batch 322: loss 0.196601\n",
      "batch 323: loss 0.461440\n",
      "batch 324: loss 0.209921\n",
      "batch 325: loss 0.400879\n",
      "batch 326: loss 0.373661\n",
      "batch 327: loss 0.421968\n",
      "batch 328: loss 0.214811\n",
      "batch 329: loss 0.210170\n",
      "batch 330: loss 0.379953\n",
      "batch 331: loss 0.210108\n",
      "batch 332: loss 0.264692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 333: loss 0.172308\n",
      "batch 334: loss 0.198127\n",
      "batch 335: loss 0.509073\n",
      "batch 336: loss 0.132321\n",
      "batch 337: loss 0.396576\n",
      "batch 338: loss 0.285402\n",
      "batch 339: loss 0.125688\n",
      "batch 340: loss 0.298166\n",
      "batch 341: loss 0.354519\n",
      "batch 342: loss 0.202544\n",
      "batch 343: loss 0.190226\n",
      "batch 344: loss 0.243647\n",
      "batch 345: loss 0.224673\n",
      "batch 346: loss 0.324189\n",
      "batch 347: loss 0.235534\n",
      "batch 348: loss 0.163767\n",
      "batch 349: loss 0.413491\n",
      "batch 350: loss 0.379918\n",
      "batch 351: loss 0.286801\n",
      "batch 352: loss 0.201032\n",
      "batch 353: loss 0.193176\n",
      "batch 354: loss 0.303939\n",
      "batch 355: loss 0.208271\n",
      "batch 356: loss 0.233065\n",
      "batch 357: loss 0.148381\n",
      "batch 358: loss 0.267533\n",
      "batch 359: loss 0.343363\n",
      "batch 360: loss 0.313611\n",
      "batch 361: loss 0.205873\n",
      "batch 362: loss 0.380588\n",
      "batch 363: loss 0.362755\n",
      "batch 364: loss 0.167483\n",
      "batch 365: loss 0.158388\n",
      "batch 366: loss 0.334325\n",
      "batch 367: loss 0.410258\n",
      "batch 368: loss 0.185753\n",
      "batch 369: loss 0.388926\n",
      "batch 370: loss 0.461327\n",
      "batch 371: loss 0.261707\n",
      "batch 372: loss 0.314858\n",
      "batch 373: loss 0.240685\n",
      "batch 374: loss 0.318870\n",
      "batch 375: loss 0.190481\n",
      "batch 376: loss 0.467459\n",
      "batch 377: loss 0.313803\n",
      "batch 378: loss 0.272651\n",
      "batch 379: loss 0.485043\n",
      "batch 380: loss 0.271061\n",
      "batch 381: loss 0.211285\n",
      "batch 382: loss 0.251002\n",
      "batch 383: loss 0.249679\n",
      "batch 384: loss 0.262120\n",
      "batch 385: loss 0.135409\n",
      "batch 386: loss 0.215260\n",
      "batch 387: loss 0.263341\n",
      "batch 388: loss 0.379777\n",
      "batch 389: loss 0.197560\n",
      "batch 390: loss 0.305652\n",
      "batch 391: loss 0.172635\n",
      "batch 392: loss 0.417937\n",
      "batch 393: loss 0.375183\n",
      "batch 394: loss 0.266769\n",
      "batch 395: loss 0.217311\n",
      "batch 396: loss 0.111356\n",
      "batch 397: loss 0.255635\n",
      "batch 398: loss 0.238324\n",
      "batch 399: loss 0.202889\n",
      "batch 400: loss 0.169668\n",
      "batch 401: loss 0.291623\n",
      "batch 402: loss 0.209059\n",
      "batch 403: loss 0.135123\n",
      "batch 404: loss 0.451074\n",
      "batch 405: loss 0.408605\n",
      "batch 406: loss 0.202388\n",
      "batch 407: loss 0.124197\n",
      "batch 408: loss 0.209878\n",
      "batch 409: loss 0.198380\n",
      "batch 410: loss 0.208401\n",
      "batch 411: loss 0.193383\n",
      "batch 412: loss 0.126010\n",
      "batch 413: loss 0.215591\n",
      "batch 414: loss 0.406348\n",
      "batch 415: loss 0.183877\n",
      "batch 416: loss 0.265156\n",
      "batch 417: loss 0.281817\n",
      "batch 418: loss 0.296516\n",
      "batch 419: loss 0.187145\n",
      "batch 420: loss 0.196022\n",
      "batch 421: loss 0.253162\n",
      "batch 422: loss 0.167763\n",
      "batch 423: loss 0.234634\n",
      "batch 424: loss 0.169359\n",
      "batch 425: loss 0.261414\n",
      "batch 426: loss 0.141063\n",
      "batch 427: loss 0.160312\n",
      "batch 428: loss 0.197920\n",
      "batch 429: loss 0.209587\n",
      "batch 430: loss 0.231809\n",
      "batch 431: loss 0.260065\n",
      "batch 432: loss 0.235052\n",
      "batch 433: loss 0.245756\n",
      "batch 434: loss 0.167952\n",
      "batch 435: loss 0.195824\n",
      "batch 436: loss 0.153053\n",
      "batch 437: loss 0.287244\n",
      "batch 438: loss 0.383135\n",
      "batch 439: loss 0.281719\n",
      "batch 440: loss 0.415717\n",
      "batch 441: loss 0.389305\n",
      "batch 442: loss 0.194484\n",
      "batch 443: loss 0.782016\n",
      "batch 444: loss 0.229783\n",
      "batch 445: loss 0.128211\n",
      "batch 446: loss 0.198468\n",
      "batch 447: loss 0.302183\n",
      "batch 448: loss 0.323887\n",
      "batch 449: loss 0.169502\n",
      "batch 450: loss 0.262327\n",
      "batch 451: loss 0.153369\n",
      "batch 452: loss 0.227955\n",
      "batch 453: loss 0.274197\n",
      "batch 454: loss 0.253332\n",
      "batch 455: loss 0.327629\n",
      "batch 456: loss 0.380410\n",
      "batch 457: loss 0.313460\n",
      "batch 458: loss 0.579346\n",
      "batch 459: loss 0.207205\n",
      "batch 460: loss 0.492430\n",
      "batch 461: loss 0.496205\n",
      "batch 462: loss 0.246981\n",
      "batch 463: loss 0.411008\n",
      "batch 464: loss 0.191615\n",
      "batch 465: loss 0.130289\n",
      "batch 466: loss 0.219777\n",
      "batch 467: loss 0.241609\n",
      "batch 468: loss 0.150527\n",
      "batch 469: loss 0.204807\n",
      "batch 470: loss 0.213683\n",
      "batch 471: loss 0.289751\n",
      "batch 472: loss 0.240702\n",
      "batch 473: loss 0.157788\n",
      "batch 474: loss 0.330717\n",
      "batch 475: loss 0.138335\n",
      "batch 476: loss 0.255517\n",
      "batch 477: loss 0.208800\n",
      "batch 478: loss 0.246809\n",
      "batch 479: loss 0.169983\n",
      "batch 480: loss 0.083624\n",
      "batch 481: loss 0.300884\n",
      "batch 482: loss 0.081690\n",
      "batch 483: loss 0.261995\n",
      "batch 484: loss 0.143260\n",
      "batch 485: loss 0.208257\n",
      "batch 486: loss 0.142075\n",
      "batch 487: loss 0.144686\n",
      "batch 488: loss 0.236560\n",
      "batch 489: loss 0.418311\n",
      "batch 490: loss 0.109881\n",
      "batch 491: loss 0.127436\n",
      "batch 492: loss 0.286499\n",
      "batch 493: loss 0.303706\n",
      "batch 494: loss 0.299395\n",
      "batch 495: loss 0.371642\n",
      "batch 496: loss 0.294051\n",
      "batch 497: loss 0.158409\n",
      "batch 498: loss 0.286419\n",
      "batch 499: loss 0.434840\n",
      "batch 500: loss 0.291902\n",
      "batch 501: loss 0.336050\n",
      "batch 502: loss 0.186874\n",
      "batch 503: loss 0.181421\n",
      "batch 504: loss 0.146294\n",
      "batch 505: loss 0.179305\n",
      "batch 506: loss 0.109746\n",
      "batch 507: loss 0.279527\n",
      "batch 508: loss 0.234316\n",
      "batch 509: loss 0.161027\n",
      "batch 510: loss 0.091657\n",
      "batch 511: loss 0.098811\n",
      "batch 512: loss 0.093762\n",
      "batch 513: loss 0.132462\n",
      "batch 514: loss 0.274600\n",
      "batch 515: loss 0.157888\n",
      "batch 516: loss 0.256867\n",
      "batch 517: loss 0.344617\n",
      "batch 518: loss 0.441611\n",
      "batch 519: loss 0.330999\n",
      "batch 520: loss 0.284566\n",
      "batch 521: loss 0.426542\n",
      "batch 522: loss 0.162593\n",
      "batch 523: loss 0.458361\n",
      "batch 524: loss 0.264286\n",
      "batch 525: loss 0.194101\n",
      "batch 526: loss 0.172503\n",
      "batch 527: loss 0.339805\n",
      "batch 528: loss 0.152626\n",
      "batch 529: loss 0.201789\n",
      "batch 530: loss 0.095535\n",
      "batch 531: loss 0.228894\n",
      "batch 532: loss 0.234684\n",
      "batch 533: loss 0.287815\n",
      "batch 534: loss 0.130999\n",
      "batch 535: loss 0.183352\n",
      "batch 536: loss 0.117387\n",
      "batch 537: loss 0.320504\n",
      "batch 538: loss 0.163256\n",
      "batch 539: loss 0.099071\n",
      "batch 540: loss 0.203758\n",
      "batch 541: loss 0.223479\n",
      "batch 542: loss 0.210046\n",
      "batch 543: loss 0.330910\n",
      "batch 544: loss 0.150430\n",
      "batch 545: loss 0.260471\n",
      "batch 546: loss 0.251756\n",
      "batch 547: loss 0.147595\n",
      "batch 548: loss 0.132239\n",
      "batch 549: loss 0.207244\n",
      "batch 550: loss 0.181863\n",
      "batch 551: loss 0.644580\n",
      "batch 552: loss 0.400492\n",
      "batch 553: loss 0.371099\n",
      "batch 554: loss 0.304559\n",
      "batch 555: loss 0.248097\n",
      "batch 556: loss 0.529579\n",
      "batch 557: loss 0.136637\n",
      "batch 558: loss 0.200381\n",
      "batch 559: loss 0.317026\n",
      "batch 560: loss 0.244265\n",
      "batch 561: loss 0.177674\n",
      "batch 562: loss 0.384937\n",
      "batch 563: loss 0.196592\n",
      "batch 564: loss 0.308963\n",
      "batch 565: loss 0.240080\n",
      "batch 566: loss 0.290589\n",
      "batch 567: loss 0.376269\n",
      "batch 568: loss 0.200423\n",
      "batch 569: loss 0.457800\n",
      "batch 570: loss 0.152456\n",
      "batch 571: loss 0.235927\n",
      "batch 572: loss 0.226047\n",
      "batch 573: loss 0.123657\n",
      "batch 574: loss 0.394029\n",
      "batch 575: loss 0.125254\n",
      "batch 576: loss 0.291062\n",
      "batch 577: loss 0.383880\n",
      "batch 578: loss 0.277637\n",
      "batch 579: loss 0.493373\n",
      "batch 580: loss 0.155869\n",
      "batch 581: loss 0.090414\n",
      "batch 582: loss 0.208471\n",
      "batch 583: loss 0.369227\n",
      "batch 584: loss 0.285625\n",
      "batch 585: loss 0.171007\n",
      "batch 586: loss 0.226084\n",
      "batch 587: loss 0.268565\n",
      "batch 588: loss 0.294355\n",
      "batch 589: loss 0.274252\n",
      "batch 590: loss 0.234026\n",
      "batch 591: loss 0.265743\n",
      "batch 592: loss 0.252375\n",
      "batch 593: loss 0.164794\n",
      "batch 594: loss 0.285093\n",
      "batch 595: loss 0.129935\n",
      "batch 596: loss 0.329310\n",
      "batch 597: loss 0.418143\n",
      "batch 598: loss 0.175849\n",
      "batch 599: loss 0.202523\n",
      "batch 600: loss 0.230996\n",
      "batch 601: loss 0.329366\n",
      "batch 602: loss 0.547501\n",
      "batch 603: loss 0.140474\n",
      "batch 604: loss 0.340708\n",
      "batch 605: loss 0.152631\n",
      "batch 606: loss 0.205667\n",
      "batch 607: loss 0.439633\n",
      "batch 608: loss 0.437247\n",
      "batch 609: loss 0.227464\n",
      "batch 610: loss 0.097581\n",
      "batch 611: loss 0.292609\n",
      "batch 612: loss 0.080991\n",
      "batch 613: loss 0.391659\n",
      "batch 614: loss 0.190189\n",
      "batch 615: loss 0.218259\n",
      "batch 616: loss 0.342387\n",
      "batch 617: loss 0.164381\n",
      "batch 618: loss 0.276709\n",
      "batch 619: loss 0.190297\n",
      "batch 620: loss 0.330531\n",
      "batch 621: loss 0.102469\n",
      "batch 622: loss 0.251131\n",
      "batch 623: loss 0.092436\n",
      "batch 624: loss 0.303827\n",
      "batch 625: loss 0.186191\n",
      "batch 626: loss 0.108237\n",
      "batch 627: loss 0.206730\n",
      "batch 628: loss 0.164508\n",
      "batch 629: loss 0.223643\n",
      "batch 630: loss 0.159861\n",
      "batch 631: loss 0.086942\n",
      "batch 632: loss 0.270119\n",
      "batch 633: loss 0.210679\n",
      "batch 634: loss 0.275659\n",
      "batch 635: loss 0.097312\n",
      "batch 636: loss 0.161169\n",
      "batch 637: loss 0.248225\n",
      "batch 638: loss 0.140813\n",
      "batch 639: loss 0.138789\n",
      "batch 640: loss 0.195431\n",
      "batch 641: loss 0.208209\n",
      "batch 642: loss 0.176907\n",
      "batch 643: loss 0.161704\n",
      "batch 644: loss 0.209852\n",
      "batch 645: loss 0.071373\n",
      "batch 646: loss 0.239597\n",
      "batch 647: loss 0.201002\n",
      "batch 648: loss 0.141010\n",
      "batch 649: loss 0.272594\n",
      "batch 650: loss 0.218222\n",
      "batch 651: loss 0.213233\n",
      "batch 652: loss 0.204450\n",
      "batch 653: loss 0.354499\n",
      "batch 654: loss 0.180443\n",
      "batch 655: loss 0.199857\n",
      "batch 656: loss 0.157268\n",
      "batch 657: loss 0.202948\n",
      "batch 658: loss 0.195667\n",
      "batch 659: loss 0.186227\n",
      "batch 660: loss 0.222516\n",
      "batch 661: loss 0.179986\n",
      "batch 662: loss 0.209614\n",
      "batch 663: loss 0.181647\n",
      "batch 664: loss 0.264317\n",
      "batch 665: loss 0.267898\n",
      "batch 666: loss 0.156981\n",
      "batch 667: loss 0.275627\n",
      "batch 668: loss 0.355433\n",
      "batch 669: loss 0.346490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 670: loss 0.232246\n",
      "batch 671: loss 0.342955\n",
      "batch 672: loss 0.307051\n",
      "batch 673: loss 0.291257\n",
      "batch 674: loss 0.400734\n",
      "batch 675: loss 0.308997\n",
      "batch 676: loss 0.388449\n",
      "batch 677: loss 0.280194\n",
      "batch 678: loss 0.115115\n",
      "batch 679: loss 0.156057\n",
      "batch 680: loss 0.169511\n",
      "batch 681: loss 0.185613\n",
      "batch 682: loss 0.184230\n",
      "batch 683: loss 0.211868\n",
      "batch 684: loss 0.247305\n",
      "batch 685: loss 0.369734\n",
      "batch 686: loss 0.355961\n",
      "batch 687: loss 0.262209\n",
      "batch 688: loss 0.074488\n",
      "batch 689: loss 0.284408\n",
      "batch 690: loss 0.184993\n",
      "batch 691: loss 0.116622\n",
      "batch 692: loss 0.291178\n",
      "batch 693: loss 0.258720\n",
      "batch 694: loss 0.138539\n",
      "batch 695: loss 0.113394\n",
      "batch 696: loss 0.228311\n",
      "batch 697: loss 0.217063\n",
      "batch 698: loss 0.160929\n",
      "batch 699: loss 0.207107\n",
      "batch 700: loss 0.181734\n",
      "batch 701: loss 0.087337\n",
      "batch 702: loss 0.355201\n",
      "batch 703: loss 0.269486\n",
      "batch 704: loss 0.168906\n",
      "batch 705: loss 0.271224\n",
      "batch 706: loss 0.210080\n",
      "batch 707: loss 0.151846\n",
      "batch 708: loss 0.311158\n",
      "batch 709: loss 0.401927\n",
      "batch 710: loss 0.205586\n",
      "batch 711: loss 0.267307\n",
      "batch 712: loss 0.056688\n",
      "batch 713: loss 0.075245\n",
      "batch 714: loss 0.357350\n",
      "batch 715: loss 0.143955\n",
      "batch 716: loss 0.298126\n",
      "batch 717: loss 0.141787\n",
      "batch 718: loss 0.157923\n",
      "batch 719: loss 0.215676\n",
      "batch 720: loss 0.252341\n",
      "batch 721: loss 0.252280\n",
      "batch 722: loss 0.097009\n",
      "batch 723: loss 0.069420\n",
      "batch 724: loss 0.177063\n",
      "batch 725: loss 0.212041\n",
      "batch 726: loss 0.161902\n",
      "batch 727: loss 0.308170\n",
      "batch 728: loss 0.362830\n",
      "batch 729: loss 0.083368\n",
      "batch 730: loss 0.167870\n",
      "batch 731: loss 0.344644\n",
      "batch 732: loss 0.125178\n",
      "batch 733: loss 0.248785\n",
      "batch 734: loss 0.191698\n",
      "batch 735: loss 0.081079\n",
      "batch 736: loss 0.268434\n",
      "batch 737: loss 0.143698\n",
      "batch 738: loss 0.259892\n",
      "batch 739: loss 0.333256\n",
      "batch 740: loss 0.300580\n",
      "batch 741: loss 0.160507\n",
      "batch 742: loss 0.165442\n",
      "batch 743: loss 0.272340\n",
      "batch 744: loss 0.179568\n",
      "batch 745: loss 0.233259\n",
      "batch 746: loss 0.113666\n",
      "batch 747: loss 0.087205\n",
      "batch 748: loss 0.229447\n",
      "batch 749: loss 0.113663\n",
      "batch 750: loss 0.249003\n",
      "batch 751: loss 0.141734\n",
      "batch 752: loss 0.267749\n",
      "batch 753: loss 0.353043\n",
      "batch 754: loss 0.251471\n",
      "batch 755: loss 0.218662\n",
      "batch 756: loss 0.122235\n",
      "batch 757: loss 0.622385\n",
      "batch 758: loss 0.341592\n",
      "batch 759: loss 0.137367\n",
      "batch 760: loss 0.206044\n",
      "batch 761: loss 0.157671\n",
      "batch 762: loss 0.323176\n",
      "batch 763: loss 0.120872\n",
      "batch 764: loss 0.148480\n",
      "batch 765: loss 0.207904\n",
      "batch 766: loss 0.211549\n",
      "batch 767: loss 0.160049\n",
      "batch 768: loss 0.217764\n",
      "batch 769: loss 0.279065\n",
      "batch 770: loss 0.268202\n",
      "batch 771: loss 0.509263\n",
      "batch 772: loss 0.187969\n",
      "batch 773: loss 0.459564\n",
      "batch 774: loss 0.270182\n",
      "batch 775: loss 0.130597\n",
      "batch 776: loss 0.173662\n",
      "batch 777: loss 0.193528\n",
      "batch 778: loss 0.176230\n",
      "batch 779: loss 0.166928\n",
      "batch 780: loss 0.273242\n",
      "batch 781: loss 0.112400\n",
      "batch 782: loss 0.180604\n",
      "batch 783: loss 0.151605\n",
      "batch 784: loss 0.084201\n",
      "batch 785: loss 0.186710\n",
      "batch 786: loss 0.112030\n",
      "batch 787: loss 0.211060\n",
      "batch 788: loss 0.237646\n",
      "batch 789: loss 0.275525\n",
      "batch 790: loss 0.098184\n",
      "batch 791: loss 0.256934\n",
      "batch 792: loss 0.116297\n",
      "batch 793: loss 0.274191\n",
      "batch 794: loss 0.527011\n",
      "batch 795: loss 0.094400\n",
      "batch 796: loss 0.093562\n",
      "batch 797: loss 0.181476\n",
      "batch 798: loss 0.123111\n",
      "batch 799: loss 0.258836\n",
      "batch 800: loss 0.160890\n",
      "batch 801: loss 0.220835\n",
      "batch 802: loss 0.306231\n",
      "batch 803: loss 0.237992\n",
      "batch 804: loss 0.158862\n",
      "batch 805: loss 0.111991\n",
      "batch 806: loss 0.225124\n",
      "batch 807: loss 0.349170\n",
      "batch 808: loss 0.156039\n",
      "batch 809: loss 0.198832\n",
      "batch 810: loss 0.146031\n",
      "batch 811: loss 0.156252\n",
      "batch 812: loss 0.219175\n",
      "batch 813: loss 0.347776\n",
      "batch 814: loss 0.081018\n",
      "batch 815: loss 0.086788\n",
      "batch 816: loss 0.216922\n",
      "batch 817: loss 0.307476\n",
      "batch 818: loss 0.231801\n",
      "batch 819: loss 0.177399\n",
      "batch 820: loss 0.169375\n",
      "batch 821: loss 0.344551\n",
      "batch 822: loss 0.153239\n",
      "batch 823: loss 0.093689\n",
      "batch 824: loss 0.179997\n",
      "batch 825: loss 0.374611\n",
      "batch 826: loss 0.081779\n",
      "batch 827: loss 0.258538\n",
      "batch 828: loss 0.104646\n",
      "batch 829: loss 0.213799\n",
      "batch 830: loss 0.150338\n",
      "batch 831: loss 0.141615\n",
      "batch 832: loss 0.087584\n",
      "batch 833: loss 0.247632\n",
      "batch 834: loss 0.159800\n",
      "batch 835: loss 0.097139\n",
      "batch 836: loss 0.076477\n",
      "batch 837: loss 0.146387\n",
      "batch 838: loss 0.158613\n",
      "batch 839: loss 0.241757\n",
      "batch 840: loss 0.580286\n",
      "batch 841: loss 0.246284\n",
      "batch 842: loss 0.263323\n",
      "batch 843: loss 0.080341\n",
      "batch 844: loss 0.126732\n",
      "batch 845: loss 0.291602\n",
      "batch 846: loss 0.093509\n",
      "batch 847: loss 0.185077\n",
      "batch 848: loss 0.222044\n",
      "batch 849: loss 0.086261\n",
      "batch 850: loss 0.060599\n",
      "batch 851: loss 0.265253\n",
      "batch 852: loss 0.150098\n",
      "batch 853: loss 0.112291\n",
      "batch 854: loss 0.200779\n",
      "batch 855: loss 0.143534\n",
      "batch 856: loss 0.227928\n",
      "batch 857: loss 0.222327\n",
      "batch 858: loss 0.067147\n",
      "batch 859: loss 0.145811\n",
      "batch 860: loss 0.137103\n",
      "batch 861: loss 0.369881\n",
      "batch 862: loss 0.139771\n",
      "batch 863: loss 0.149370\n",
      "batch 864: loss 0.298711\n",
      "batch 865: loss 0.288940\n",
      "batch 866: loss 0.158908\n",
      "batch 867: loss 0.332025\n",
      "batch 868: loss 0.416774\n",
      "batch 869: loss 0.129090\n",
      "batch 870: loss 0.088017\n",
      "batch 871: loss 0.222690\n",
      "batch 872: loss 0.161074\n",
      "batch 873: loss 0.092875\n",
      "batch 874: loss 0.102693\n",
      "batch 875: loss 0.326582\n",
      "batch 876: loss 0.211017\n",
      "batch 877: loss 0.046786\n",
      "batch 878: loss 0.122253\n",
      "batch 879: loss 0.378329\n",
      "batch 880: loss 0.142970\n",
      "batch 881: loss 0.112829\n",
      "batch 882: loss 0.074513\n",
      "batch 883: loss 0.212261\n",
      "batch 884: loss 0.036033\n",
      "batch 885: loss 0.288873\n",
      "batch 886: loss 0.317836\n",
      "batch 887: loss 0.326792\n",
      "batch 888: loss 0.142811\n",
      "batch 889: loss 0.223147\n",
      "batch 890: loss 0.064856\n",
      "batch 891: loss 0.244572\n",
      "batch 892: loss 0.198337\n",
      "batch 893: loss 0.171502\n",
      "batch 894: loss 0.141851\n",
      "batch 895: loss 0.152504\n",
      "batch 896: loss 0.205289\n",
      "batch 897: loss 0.204171\n",
      "batch 898: loss 0.182141\n",
      "batch 899: loss 0.247179\n",
      "batch 900: loss 0.094439\n",
      "batch 901: loss 0.207318\n",
      "batch 902: loss 0.046769\n",
      "batch 903: loss 0.069837\n",
      "batch 904: loss 0.159316\n",
      "batch 905: loss 0.227205\n",
      "batch 906: loss 0.204860\n",
      "batch 907: loss 0.094578\n",
      "batch 908: loss 0.065981\n",
      "batch 909: loss 0.035734\n",
      "batch 910: loss 0.067567\n",
      "batch 911: loss 0.264963\n",
      "batch 912: loss 0.159188\n",
      "batch 913: loss 0.101719\n",
      "batch 914: loss 0.051770\n",
      "batch 915: loss 0.070795\n",
      "batch 916: loss 0.086740\n",
      "batch 917: loss 0.208361\n",
      "batch 918: loss 0.339996\n",
      "batch 919: loss 0.236327\n",
      "batch 920: loss 0.246203\n",
      "batch 921: loss 0.250068\n",
      "batch 922: loss 0.211509\n",
      "batch 923: loss 0.111546\n",
      "batch 924: loss 0.030147\n",
      "batch 925: loss 0.241163\n",
      "batch 926: loss 0.052924\n",
      "batch 927: loss 0.204526\n",
      "batch 928: loss 0.466360\n",
      "batch 929: loss 0.305995\n",
      "batch 930: loss 0.168928\n",
      "batch 931: loss 0.328401\n",
      "batch 932: loss 0.139549\n",
      "batch 933: loss 0.256084\n",
      "batch 934: loss 0.139755\n",
      "batch 935: loss 0.133830\n",
      "batch 936: loss 0.121471\n",
      "batch 937: loss 0.108875\n",
      "batch 938: loss 0.060189\n",
      "batch 939: loss 0.309947\n",
      "batch 940: loss 0.239296\n",
      "batch 941: loss 0.225497\n",
      "batch 942: loss 0.110665\n",
      "batch 943: loss 0.229585\n",
      "batch 944: loss 0.353927\n",
      "batch 945: loss 0.144971\n",
      "batch 946: loss 0.252674\n",
      "batch 947: loss 0.190049\n",
      "batch 948: loss 0.269120\n",
      "batch 949: loss 0.224596\n",
      "batch 950: loss 0.210202\n",
      "batch 951: loss 0.356114\n",
      "batch 952: loss 0.128818\n",
      "batch 953: loss 0.140409\n",
      "batch 954: loss 0.123697\n",
      "batch 955: loss 0.360288\n",
      "batch 956: loss 0.229850\n",
      "batch 957: loss 0.158194\n",
      "batch 958: loss 0.258881\n",
      "batch 959: loss 0.185209\n",
      "batch 960: loss 0.392396\n",
      "batch 961: loss 0.157604\n",
      "batch 962: loss 0.196747\n",
      "batch 963: loss 0.235464\n",
      "batch 964: loss 0.206356\n",
      "batch 965: loss 0.202161\n",
      "batch 966: loss 0.174877\n",
      "batch 967: loss 0.138551\n",
      "batch 968: loss 0.087250\n",
      "batch 969: loss 0.362792\n",
      "batch 970: loss 0.283637\n",
      "batch 971: loss 0.168167\n",
      "batch 972: loss 0.072208\n",
      "batch 973: loss 0.157504\n",
      "batch 974: loss 0.316717\n",
      "batch 975: loss 0.110428\n",
      "batch 976: loss 0.251858\n",
      "batch 977: loss 0.130388\n",
      "batch 978: loss 0.115407\n",
      "batch 979: loss 0.079229\n",
      "batch 980: loss 0.315918\n",
      "batch 981: loss 0.169850\n",
      "batch 982: loss 0.118249\n",
      "batch 983: loss 0.118358\n",
      "batch 984: loss 0.132303\n",
      "batch 985: loss 0.138295\n",
      "batch 986: loss 0.037346\n",
      "batch 987: loss 0.134728\n",
      "batch 988: loss 0.140017\n",
      "batch 989: loss 0.150892\n",
      "batch 990: loss 0.276618\n",
      "batch 991: loss 0.165930\n",
      "batch 992: loss 0.217103\n",
      "batch 993: loss 0.296216\n",
      "batch 994: loss 0.106056\n",
      "batch 995: loss 0.155209\n",
      "batch 996: loss 0.100246\n",
      "batch 997: loss 0.101002\n",
      "batch 998: loss 0.237279\n",
      "batch 999: loss 0.091728\n",
      "batch 1000: loss 0.205002\n",
      "batch 1001: loss 0.110134\n",
      "batch 1002: loss 0.117509\n",
      "batch 1003: loss 0.225995\n",
      "batch 1004: loss 0.143122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1005: loss 0.221929\n",
      "batch 1006: loss 0.203036\n",
      "batch 1007: loss 0.166824\n",
      "batch 1008: loss 0.191108\n",
      "batch 1009: loss 0.098934\n",
      "batch 1010: loss 0.214455\n",
      "batch 1011: loss 0.264127\n",
      "batch 1012: loss 0.071164\n",
      "batch 1013: loss 0.196858\n",
      "batch 1014: loss 0.254317\n",
      "batch 1015: loss 0.216082\n",
      "batch 1016: loss 0.212308\n",
      "batch 1017: loss 0.353487\n",
      "batch 1018: loss 0.441830\n",
      "batch 1019: loss 0.135525\n",
      "batch 1020: loss 0.150710\n",
      "batch 1021: loss 0.154704\n",
      "batch 1022: loss 0.106424\n",
      "batch 1023: loss 0.211322\n",
      "batch 1024: loss 0.163746\n",
      "batch 1025: loss 0.095586\n",
      "batch 1026: loss 0.211833\n",
      "batch 1027: loss 0.108249\n",
      "batch 1028: loss 0.160094\n",
      "batch 1029: loss 0.255276\n",
      "batch 1030: loss 0.408355\n",
      "batch 1031: loss 0.160982\n",
      "batch 1032: loss 0.107724\n",
      "batch 1033: loss 0.059702\n",
      "batch 1034: loss 0.319899\n",
      "batch 1035: loss 0.177109\n",
      "batch 1036: loss 0.152864\n",
      "batch 1037: loss 0.234080\n",
      "batch 1038: loss 0.263151\n",
      "batch 1039: loss 0.176015\n",
      "batch 1040: loss 0.113232\n",
      "batch 1041: loss 0.180857\n",
      "batch 1042: loss 0.117127\n",
      "batch 1043: loss 0.057804\n",
      "batch 1044: loss 0.263093\n",
      "batch 1045: loss 0.126676\n",
      "batch 1046: loss 0.117222\n",
      "batch 1047: loss 0.226846\n",
      "batch 1048: loss 0.101247\n",
      "batch 1049: loss 0.108294\n",
      "batch 1050: loss 0.048851\n",
      "batch 1051: loss 0.301223\n",
      "batch 1052: loss 0.262855\n",
      "batch 1053: loss 0.239723\n",
      "batch 1054: loss 0.068178\n",
      "batch 1055: loss 0.070681\n",
      "batch 1056: loss 0.189594\n",
      "batch 1057: loss 0.114213\n",
      "batch 1058: loss 0.103905\n",
      "batch 1059: loss 0.138054\n",
      "batch 1060: loss 0.187500\n",
      "batch 1061: loss 0.097522\n",
      "batch 1062: loss 0.053167\n",
      "batch 1063: loss 0.179148\n",
      "batch 1064: loss 0.132956\n",
      "batch 1065: loss 0.080619\n",
      "batch 1066: loss 0.155062\n",
      "batch 1067: loss 0.137045\n",
      "batch 1068: loss 0.142202\n",
      "batch 1069: loss 0.178521\n",
      "batch 1070: loss 0.228751\n",
      "batch 1071: loss 0.156452\n",
      "batch 1072: loss 0.104356\n",
      "batch 1073: loss 0.211317\n",
      "batch 1074: loss 0.110009\n",
      "batch 1075: loss 0.085942\n",
      "batch 1076: loss 0.157928\n",
      "batch 1077: loss 0.182275\n",
      "batch 1078: loss 0.063973\n",
      "batch 1079: loss 0.126664\n",
      "batch 1080: loss 0.144267\n",
      "batch 1081: loss 0.379634\n",
      "batch 1082: loss 0.192429\n",
      "batch 1083: loss 0.142795\n",
      "batch 1084: loss 0.233525\n",
      "batch 1085: loss 0.216351\n",
      "batch 1086: loss 0.253403\n",
      "batch 1087: loss 0.449730\n",
      "batch 1088: loss 0.234557\n",
      "batch 1089: loss 0.144232\n",
      "batch 1090: loss 0.198078\n",
      "batch 1091: loss 0.126591\n",
      "batch 1092: loss 0.317862\n",
      "batch 1093: loss 0.177586\n",
      "batch 1094: loss 0.154607\n",
      "batch 1095: loss 0.171966\n",
      "batch 1096: loss 0.085697\n",
      "batch 1097: loss 0.111236\n",
      "batch 1098: loss 0.282573\n",
      "batch 1099: loss 0.074000\n",
      "batch 1100: loss 0.131890\n",
      "batch 1101: loss 0.111065\n",
      "batch 1102: loss 0.260872\n",
      "batch 1103: loss 0.140111\n",
      "batch 1104: loss 0.084213\n",
      "batch 1105: loss 0.316294\n",
      "batch 1106: loss 0.091682\n",
      "batch 1107: loss 0.055345\n",
      "batch 1108: loss 0.109541\n",
      "batch 1109: loss 0.258962\n",
      "batch 1110: loss 0.088859\n",
      "batch 1111: loss 0.301747\n",
      "batch 1112: loss 0.205778\n",
      "batch 1113: loss 0.213459\n",
      "batch 1114: loss 0.121514\n",
      "batch 1115: loss 0.237216\n",
      "batch 1116: loss 0.185815\n",
      "batch 1117: loss 0.132850\n",
      "batch 1118: loss 0.053765\n",
      "batch 1119: loss 0.277094\n",
      "batch 1120: loss 0.185093\n",
      "batch 1121: loss 0.165193\n",
      "batch 1122: loss 0.112692\n",
      "batch 1123: loss 0.119456\n",
      "batch 1124: loss 0.122270\n",
      "batch 1125: loss 0.231235\n",
      "batch 1126: loss 0.215497\n",
      "batch 1127: loss 0.142590\n",
      "batch 1128: loss 0.269170\n",
      "batch 1129: loss 0.157710\n",
      "batch 1130: loss 0.174750\n",
      "batch 1131: loss 0.420779\n",
      "batch 1132: loss 0.175185\n",
      "batch 1133: loss 0.262636\n",
      "batch 1134: loss 0.364171\n",
      "batch 1135: loss 0.437591\n",
      "batch 1136: loss 0.098322\n",
      "batch 1137: loss 0.248394\n",
      "batch 1138: loss 0.134715\n",
      "batch 1139: loss 0.274989\n",
      "batch 1140: loss 0.131899\n",
      "batch 1141: loss 0.241234\n",
      "batch 1142: loss 0.126080\n",
      "batch 1143: loss 0.128916\n",
      "batch 1144: loss 0.073381\n",
      "batch 1145: loss 0.297358\n",
      "batch 1146: loss 0.077653\n",
      "batch 1147: loss 0.132736\n",
      "batch 1148: loss 0.054837\n",
      "batch 1149: loss 0.084889\n",
      "batch 1150: loss 0.136977\n",
      "batch 1151: loss 0.127169\n",
      "batch 1152: loss 0.068042\n",
      "batch 1153: loss 0.276648\n",
      "batch 1154: loss 0.085239\n",
      "batch 1155: loss 0.127220\n",
      "batch 1156: loss 0.163007\n",
      "batch 1157: loss 0.169154\n",
      "batch 1158: loss 0.053627\n",
      "batch 1159: loss 0.201381\n",
      "batch 1160: loss 0.123700\n",
      "batch 1161: loss 0.151334\n",
      "batch 1162: loss 0.053720\n",
      "batch 1163: loss 0.173074\n",
      "batch 1164: loss 0.090689\n",
      "batch 1165: loss 0.227134\n",
      "batch 1166: loss 0.303706\n",
      "batch 1167: loss 0.094882\n",
      "batch 1168: loss 0.156953\n",
      "batch 1169: loss 0.344607\n",
      "batch 1170: loss 0.131997\n",
      "batch 1171: loss 0.177682\n",
      "batch 1172: loss 0.122453\n",
      "batch 1173: loss 0.126316\n",
      "batch 1174: loss 0.203305\n",
      "batch 1175: loss 0.129895\n",
      "batch 1176: loss 0.217493\n",
      "batch 1177: loss 0.205644\n",
      "batch 1178: loss 0.235892\n",
      "batch 1179: loss 0.055155\n",
      "batch 1180: loss 0.038423\n",
      "batch 1181: loss 0.213572\n",
      "batch 1182: loss 0.155189\n",
      "batch 1183: loss 0.118601\n",
      "batch 1184: loss 0.132059\n",
      "batch 1185: loss 0.110972\n",
      "batch 1186: loss 0.074196\n",
      "batch 1187: loss 0.211156\n",
      "batch 1188: loss 0.127637\n",
      "batch 1189: loss 0.068275\n",
      "batch 1190: loss 0.092796\n",
      "batch 1191: loss 0.292543\n",
      "batch 1192: loss 0.263464\n",
      "batch 1193: loss 0.126586\n",
      "batch 1194: loss 0.151497\n",
      "batch 1195: loss 0.147352\n",
      "batch 1196: loss 0.089906\n",
      "batch 1197: loss 0.350424\n",
      "batch 1198: loss 0.211756\n",
      "batch 1199: loss 0.062991\n",
      "batch 1200: loss 0.043113\n",
      "batch 1201: loss 0.225632\n",
      "batch 1202: loss 0.184304\n",
      "batch 1203: loss 0.140163\n",
      "batch 1204: loss 0.069084\n",
      "batch 1205: loss 0.319509\n",
      "batch 1206: loss 0.029384\n",
      "batch 1207: loss 0.053665\n",
      "batch 1208: loss 0.133167\n",
      "batch 1209: loss 0.122880\n",
      "batch 1210: loss 0.111714\n",
      "batch 1211: loss 0.200573\n",
      "batch 1212: loss 0.142183\n",
      "batch 1213: loss 0.086534\n",
      "batch 1214: loss 0.298891\n",
      "batch 1215: loss 0.025635\n",
      "batch 1216: loss 0.098379\n",
      "batch 1217: loss 0.137483\n",
      "batch 1218: loss 0.079376\n",
      "batch 1219: loss 0.035682\n",
      "batch 1220: loss 0.195172\n",
      "batch 1221: loss 0.122668\n",
      "batch 1222: loss 0.070139\n",
      "batch 1223: loss 0.109621\n",
      "batch 1224: loss 0.268003\n",
      "batch 1225: loss 0.135951\n",
      "batch 1226: loss 0.242938\n",
      "batch 1227: loss 0.149683\n",
      "batch 1228: loss 0.238447\n",
      "batch 1229: loss 0.259984\n",
      "batch 1230: loss 0.161525\n",
      "batch 1231: loss 0.046961\n",
      "batch 1232: loss 0.186005\n",
      "batch 1233: loss 0.249753\n",
      "batch 1234: loss 0.115535\n",
      "batch 1235: loss 0.251402\n",
      "batch 1236: loss 0.122376\n",
      "batch 1237: loss 0.105996\n",
      "batch 1238: loss 0.088835\n",
      "batch 1239: loss 0.140970\n",
      "batch 1240: loss 0.083181\n",
      "batch 1241: loss 0.072423\n",
      "batch 1242: loss 0.031447\n",
      "batch 1243: loss 0.150262\n",
      "batch 1244: loss 0.160338\n",
      "batch 1245: loss 0.097130\n",
      "batch 1246: loss 0.072173\n",
      "batch 1247: loss 0.190655\n",
      "batch 1248: loss 0.071872\n",
      "batch 1249: loss 0.146474\n",
      "batch 1250: loss 0.437463\n",
      "batch 1251: loss 0.126594\n",
      "batch 1252: loss 0.193617\n",
      "batch 1253: loss 0.291971\n",
      "batch 1254: loss 0.045700\n",
      "batch 1255: loss 0.134075\n",
      "batch 1256: loss 0.124984\n",
      "batch 1257: loss 0.243808\n",
      "batch 1258: loss 0.151794\n",
      "batch 1259: loss 0.107766\n",
      "batch 1260: loss 0.179158\n",
      "batch 1261: loss 0.271322\n",
      "batch 1262: loss 0.046553\n",
      "batch 1263: loss 0.119613\n",
      "batch 1264: loss 0.324210\n",
      "batch 1265: loss 0.099850\n",
      "batch 1266: loss 0.164652\n",
      "batch 1267: loss 0.227291\n",
      "batch 1268: loss 0.081906\n",
      "batch 1269: loss 0.060162\n",
      "batch 1270: loss 0.078546\n",
      "batch 1271: loss 0.113871\n",
      "batch 1272: loss 0.197077\n",
      "batch 1273: loss 0.065504\n",
      "batch 1274: loss 0.046514\n",
      "batch 1275: loss 0.113345\n",
      "batch 1276: loss 0.047327\n",
      "batch 1277: loss 0.198392\n",
      "batch 1278: loss 0.294264\n",
      "batch 1279: loss 0.134370\n",
      "batch 1280: loss 0.135459\n",
      "batch 1281: loss 0.051787\n",
      "batch 1282: loss 0.164531\n",
      "batch 1283: loss 0.125371\n",
      "batch 1284: loss 0.118673\n",
      "batch 1285: loss 0.111168\n",
      "batch 1286: loss 0.072745\n",
      "batch 1287: loss 0.442820\n",
      "batch 1288: loss 0.143073\n",
      "batch 1289: loss 0.222723\n",
      "batch 1290: loss 0.083455\n",
      "batch 1291: loss 0.126144\n",
      "batch 1292: loss 0.133922\n",
      "batch 1293: loss 0.269173\n",
      "batch 1294: loss 0.123351\n",
      "batch 1295: loss 0.187958\n",
      "batch 1296: loss 0.195051\n",
      "batch 1297: loss 0.067320\n",
      "batch 1298: loss 0.122547\n",
      "batch 1299: loss 0.084792\n",
      "batch 1300: loss 0.054516\n",
      "batch 1301: loss 0.141315\n",
      "batch 1302: loss 0.106763\n",
      "batch 1303: loss 0.085596\n",
      "batch 1304: loss 0.093345\n",
      "batch 1305: loss 0.221861\n",
      "batch 1306: loss 0.176859\n",
      "batch 1307: loss 0.088896\n",
      "batch 1308: loss 0.105370\n",
      "batch 1309: loss 0.207657\n",
      "batch 1310: loss 0.168527\n",
      "batch 1311: loss 0.033925\n",
      "batch 1312: loss 0.114206\n",
      "batch 1313: loss 0.133821\n",
      "batch 1314: loss 0.155674\n",
      "batch 1315: loss 0.104137\n",
      "batch 1316: loss 0.185329\n",
      "batch 1317: loss 0.040480\n",
      "batch 1318: loss 0.183028\n",
      "batch 1319: loss 0.460822\n",
      "batch 1320: loss 0.107830\n",
      "batch 1321: loss 0.171063\n",
      "batch 1322: loss 0.100544\n",
      "batch 1323: loss 0.248929\n",
      "batch 1324: loss 0.070405\n",
      "batch 1325: loss 0.097899\n",
      "batch 1326: loss 0.112866\n",
      "batch 1327: loss 0.186768\n",
      "batch 1328: loss 0.267923\n",
      "batch 1329: loss 0.235430\n",
      "batch 1330: loss 0.091133\n",
      "batch 1331: loss 0.097129\n",
      "batch 1332: loss 0.226037\n",
      "batch 1333: loss 0.174106\n",
      "batch 1334: loss 0.022752\n",
      "batch 1335: loss 0.253791\n",
      "batch 1336: loss 0.317117\n",
      "batch 1337: loss 0.255092\n",
      "batch 1338: loss 0.095010\n",
      "batch 1339: loss 0.128050\n",
      "batch 1340: loss 0.192933\n",
      "batch 1341: loss 0.260255\n",
      "batch 1342: loss 0.077283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1343: loss 0.181572\n",
      "batch 1344: loss 0.124535\n",
      "batch 1345: loss 0.110635\n",
      "batch 1346: loss 0.062804\n",
      "batch 1347: loss 0.115794\n",
      "batch 1348: loss 0.083502\n",
      "batch 1349: loss 0.073093\n",
      "batch 1350: loss 0.180666\n",
      "batch 1351: loss 0.054115\n",
      "batch 1352: loss 0.212064\n",
      "batch 1353: loss 0.441950\n",
      "batch 1354: loss 0.156293\n",
      "batch 1355: loss 0.338918\n",
      "batch 1356: loss 0.193677\n",
      "batch 1357: loss 0.071389\n",
      "batch 1358: loss 0.043808\n",
      "batch 1359: loss 0.115723\n",
      "batch 1360: loss 0.160234\n",
      "batch 1361: loss 0.086074\n",
      "batch 1362: loss 0.139353\n",
      "batch 1363: loss 0.199011\n",
      "batch 1364: loss 0.269550\n",
      "batch 1365: loss 0.113000\n",
      "batch 1366: loss 0.169264\n",
      "batch 1367: loss 0.040457\n",
      "batch 1368: loss 0.074780\n",
      "batch 1369: loss 0.324395\n",
      "batch 1370: loss 0.125488\n",
      "batch 1371: loss 0.163521\n",
      "batch 1372: loss 0.090384\n",
      "batch 1373: loss 0.146167\n",
      "batch 1374: loss 0.106601\n",
      "batch 1375: loss 0.122729\n",
      "batch 1376: loss 0.121462\n",
      "batch 1377: loss 0.131891\n",
      "batch 1378: loss 0.206210\n",
      "batch 1379: loss 0.087353\n",
      "batch 1380: loss 0.046529\n",
      "batch 1381: loss 0.173740\n",
      "batch 1382: loss 0.042956\n",
      "batch 1383: loss 0.218046\n",
      "batch 1384: loss 0.111410\n",
      "batch 1385: loss 0.228995\n",
      "batch 1386: loss 0.071146\n",
      "batch 1387: loss 0.102349\n",
      "batch 1388: loss 0.114252\n",
      "batch 1389: loss 0.108481\n",
      "batch 1390: loss 0.047656\n",
      "batch 1391: loss 0.057561\n",
      "batch 1392: loss 0.135152\n",
      "batch 1393: loss 0.197825\n",
      "batch 1394: loss 0.070647\n",
      "batch 1395: loss 0.133020\n",
      "batch 1396: loss 0.125904\n",
      "batch 1397: loss 0.084454\n",
      "batch 1398: loss 0.108755\n",
      "batch 1399: loss 0.250447\n",
      "batch 1400: loss 0.074270\n",
      "batch 1401: loss 0.081549\n",
      "batch 1402: loss 0.428350\n",
      "batch 1403: loss 0.205504\n",
      "batch 1404: loss 0.174178\n",
      "batch 1405: loss 0.286396\n",
      "batch 1406: loss 0.189062\n",
      "batch 1407: loss 0.184317\n",
      "batch 1408: loss 0.133203\n",
      "batch 1409: loss 0.149169\n",
      "batch 1410: loss 0.158770\n",
      "batch 1411: loss 0.167594\n",
      "batch 1412: loss 0.256944\n",
      "batch 1413: loss 0.079822\n",
      "batch 1414: loss 0.182307\n",
      "batch 1415: loss 0.237432\n",
      "batch 1416: loss 0.308996\n",
      "batch 1417: loss 0.204573\n",
      "batch 1418: loss 0.298954\n",
      "batch 1419: loss 0.326289\n",
      "batch 1420: loss 0.107010\n",
      "batch 1421: loss 0.158213\n",
      "batch 1422: loss 0.176872\n",
      "batch 1423: loss 0.142207\n",
      "batch 1424: loss 0.078670\n",
      "batch 1425: loss 0.074482\n",
      "batch 1426: loss 0.120863\n",
      "batch 1427: loss 0.259416\n",
      "batch 1428: loss 0.159724\n",
      "batch 1429: loss 0.072675\n",
      "batch 1430: loss 0.220237\n",
      "batch 1431: loss 0.170385\n",
      "batch 1432: loss 0.204685\n",
      "batch 1433: loss 0.172902\n",
      "batch 1434: loss 0.054169\n",
      "batch 1435: loss 0.090203\n",
      "batch 1436: loss 0.130555\n",
      "batch 1437: loss 0.110706\n",
      "batch 1438: loss 0.163732\n",
      "batch 1439: loss 0.106807\n",
      "batch 1440: loss 0.160403\n",
      "batch 1441: loss 0.101000\n",
      "batch 1442: loss 0.094053\n",
      "batch 1443: loss 0.350911\n",
      "batch 1444: loss 0.162486\n",
      "batch 1445: loss 0.191749\n",
      "batch 1446: loss 0.101841\n",
      "batch 1447: loss 0.202985\n",
      "batch 1448: loss 0.167396\n",
      "batch 1449: loss 0.118192\n",
      "batch 1450: loss 0.031248\n",
      "batch 1451: loss 0.091616\n",
      "batch 1452: loss 0.077068\n",
      "batch 1453: loss 0.148163\n",
      "batch 1454: loss 0.249927\n",
      "batch 1455: loss 0.125933\n",
      "batch 1456: loss 0.075084\n",
      "batch 1457: loss 0.208542\n",
      "batch 1458: loss 0.133518\n",
      "batch 1459: loss 0.074678\n",
      "batch 1460: loss 0.150028\n",
      "batch 1461: loss 0.078677\n",
      "batch 1462: loss 0.079691\n",
      "batch 1463: loss 0.240131\n",
      "batch 1464: loss 0.122977\n",
      "batch 1465: loss 0.056346\n",
      "batch 1466: loss 0.094827\n",
      "batch 1467: loss 0.077173\n",
      "batch 1468: loss 0.028887\n",
      "batch 1469: loss 0.350498\n",
      "batch 1470: loss 0.104035\n",
      "batch 1471: loss 0.106950\n",
      "batch 1472: loss 0.146926\n",
      "batch 1473: loss 0.071225\n",
      "batch 1474: loss 0.080656\n",
      "batch 1475: loss 0.038901\n",
      "batch 1476: loss 0.184075\n",
      "batch 1477: loss 0.211883\n",
      "batch 1478: loss 0.232378\n",
      "batch 1479: loss 0.087925\n",
      "batch 1480: loss 0.207074\n",
      "batch 1481: loss 0.121687\n",
      "batch 1482: loss 0.150228\n",
      "batch 1483: loss 0.116942\n",
      "batch 1484: loss 0.319965\n",
      "batch 1485: loss 0.140421\n",
      "batch 1486: loss 0.134081\n",
      "batch 1487: loss 0.134877\n",
      "batch 1488: loss 0.093882\n",
      "batch 1489: loss 0.109813\n",
      "batch 1490: loss 0.250166\n",
      "batch 1491: loss 0.060790\n",
      "batch 1492: loss 0.084610\n",
      "batch 1493: loss 0.126991\n",
      "batch 1494: loss 0.070556\n",
      "batch 1495: loss 0.118192\n",
      "batch 1496: loss 0.086808\n",
      "batch 1497: loss 0.073619\n",
      "batch 1498: loss 0.073901\n",
      "batch 1499: loss 0.029880\n",
      "batch 1500: loss 0.150430\n",
      "batch 1501: loss 0.277827\n",
      "batch 1502: loss 0.036642\n",
      "batch 1503: loss 0.044415\n",
      "batch 1504: loss 0.083852\n",
      "batch 1505: loss 0.129010\n",
      "batch 1506: loss 0.098077\n",
      "batch 1507: loss 0.086636\n",
      "batch 1508: loss 0.075293\n",
      "batch 1509: loss 0.155168\n",
      "batch 1510: loss 0.108806\n",
      "batch 1511: loss 0.026879\n",
      "batch 1512: loss 0.144302\n",
      "batch 1513: loss 0.068840\n",
      "batch 1514: loss 0.108491\n",
      "batch 1515: loss 0.201583\n",
      "batch 1516: loss 0.167120\n",
      "batch 1517: loss 0.150189\n",
      "batch 1518: loss 0.089384\n",
      "batch 1519: loss 0.200357\n",
      "batch 1520: loss 0.058201\n",
      "batch 1521: loss 0.183017\n",
      "batch 1522: loss 0.089343\n",
      "batch 1523: loss 0.141493\n",
      "batch 1524: loss 0.189033\n",
      "batch 1525: loss 0.129373\n",
      "batch 1526: loss 0.074476\n",
      "batch 1527: loss 0.185226\n",
      "batch 1528: loss 0.095097\n",
      "batch 1529: loss 0.246707\n",
      "batch 1530: loss 0.310300\n",
      "batch 1531: loss 0.139538\n",
      "batch 1532: loss 0.044713\n",
      "batch 1533: loss 0.067042\n",
      "batch 1534: loss 0.135626\n",
      "batch 1535: loss 0.204535\n",
      "batch 1536: loss 0.127474\n",
      "batch 1537: loss 0.170692\n",
      "batch 1538: loss 0.069517\n",
      "batch 1539: loss 0.147273\n",
      "batch 1540: loss 0.111065\n",
      "batch 1541: loss 0.110018\n",
      "batch 1542: loss 0.084593\n",
      "batch 1543: loss 0.075265\n",
      "batch 1544: loss 0.146689\n",
      "batch 1545: loss 0.285761\n",
      "batch 1546: loss 0.083216\n",
      "batch 1547: loss 0.128458\n",
      "batch 1548: loss 0.189736\n",
      "batch 1549: loss 0.171457\n",
      "batch 1550: loss 0.175205\n",
      "batch 1551: loss 0.054904\n",
      "batch 1552: loss 0.047899\n",
      "batch 1553: loss 0.090262\n",
      "batch 1554: loss 0.068274\n",
      "batch 1555: loss 0.064496\n",
      "batch 1556: loss 0.267590\n",
      "batch 1557: loss 0.037319\n",
      "batch 1558: loss 0.124291\n",
      "batch 1559: loss 0.203273\n",
      "batch 1560: loss 0.188756\n",
      "batch 1561: loss 0.087341\n",
      "batch 1562: loss 0.054671\n",
      "batch 1563: loss 0.077370\n",
      "batch 1564: loss 0.054684\n",
      "batch 1565: loss 0.056300\n",
      "batch 1566: loss 0.089545\n",
      "batch 1567: loss 0.164625\n",
      "batch 1568: loss 0.081550\n",
      "batch 1569: loss 0.226701\n",
      "batch 1570: loss 0.165275\n",
      "batch 1571: loss 0.103625\n",
      "batch 1572: loss 0.420410\n",
      "batch 1573: loss 0.086812\n",
      "batch 1574: loss 0.112442\n",
      "batch 1575: loss 0.156826\n",
      "batch 1576: loss 0.209729\n",
      "batch 1577: loss 0.153265\n",
      "batch 1578: loss 0.028434\n",
      "batch 1579: loss 0.154895\n",
      "batch 1580: loss 0.222722\n",
      "batch 1581: loss 0.288599\n",
      "batch 1582: loss 0.118528\n",
      "batch 1583: loss 0.169406\n",
      "batch 1584: loss 0.260688\n",
      "batch 1585: loss 0.205045\n",
      "batch 1586: loss 0.353255\n",
      "batch 1587: loss 0.178778\n",
      "batch 1588: loss 0.165237\n",
      "batch 1589: loss 0.206435\n",
      "batch 1590: loss 0.092503\n",
      "batch 1591: loss 0.134643\n",
      "batch 1592: loss 0.092570\n",
      "batch 1593: loss 0.163781\n",
      "batch 1594: loss 0.233638\n",
      "batch 1595: loss 0.095185\n",
      "batch 1596: loss 0.186845\n",
      "batch 1597: loss 0.127863\n",
      "batch 1598: loss 0.254735\n",
      "batch 1599: loss 0.079928\n",
      "batch 1600: loss 0.162051\n",
      "batch 1601: loss 0.081372\n",
      "batch 1602: loss 0.216876\n",
      "batch 1603: loss 0.113561\n",
      "batch 1604: loss 0.105230\n",
      "batch 1605: loss 0.171183\n",
      "batch 1606: loss 0.191298\n",
      "batch 1607: loss 0.214442\n",
      "batch 1608: loss 0.162296\n",
      "batch 1609: loss 0.077121\n",
      "batch 1610: loss 0.308078\n",
      "batch 1611: loss 0.193186\n",
      "batch 1612: loss 0.083927\n",
      "batch 1613: loss 0.059088\n",
      "batch 1614: loss 0.066965\n",
      "batch 1615: loss 0.046934\n",
      "batch 1616: loss 0.082169\n",
      "batch 1617: loss 0.129688\n",
      "batch 1618: loss 0.195787\n",
      "batch 1619: loss 0.228549\n",
      "batch 1620: loss 0.137699\n",
      "batch 1621: loss 0.136337\n",
      "batch 1622: loss 0.044072\n",
      "batch 1623: loss 0.048227\n",
      "batch 1624: loss 0.316436\n",
      "batch 1625: loss 0.157833\n",
      "batch 1626: loss 0.017503\n",
      "batch 1627: loss 0.186187\n",
      "batch 1628: loss 0.192337\n",
      "batch 1629: loss 0.103967\n",
      "batch 1630: loss 0.160479\n",
      "batch 1631: loss 0.115404\n",
      "batch 1632: loss 0.125310\n",
      "batch 1633: loss 0.115901\n",
      "batch 1634: loss 0.135700\n",
      "batch 1635: loss 0.077992\n",
      "batch 1636: loss 0.211100\n",
      "batch 1637: loss 0.064924\n",
      "batch 1638: loss 0.072664\n",
      "batch 1639: loss 0.140013\n",
      "batch 1640: loss 0.183244\n",
      "batch 1641: loss 0.091483\n",
      "batch 1642: loss 0.100342\n",
      "batch 1643: loss 0.085424\n",
      "batch 1644: loss 0.036775\n",
      "batch 1645: loss 0.225463\n",
      "batch 1646: loss 0.149729\n",
      "batch 1647: loss 0.037463\n",
      "batch 1648: loss 0.210650\n",
      "batch 1649: loss 0.216163\n",
      "batch 1650: loss 0.108795\n",
      "batch 1651: loss 0.079076\n",
      "batch 1652: loss 0.047303\n",
      "batch 1653: loss 0.103991\n",
      "batch 1654: loss 0.128359\n",
      "batch 1655: loss 0.196739\n",
      "batch 1656: loss 0.051232\n",
      "batch 1657: loss 0.152324\n",
      "batch 1658: loss 0.070052\n",
      "batch 1659: loss 0.134944\n",
      "batch 1660: loss 0.110194\n",
      "batch 1661: loss 0.042029\n",
      "batch 1662: loss 0.139351\n",
      "batch 1663: loss 0.145310\n",
      "batch 1664: loss 0.136235\n",
      "batch 1665: loss 0.151411\n",
      "batch 1666: loss 0.175993\n",
      "batch 1667: loss 0.115238\n",
      "batch 1668: loss 0.020990\n",
      "batch 1669: loss 0.086990\n",
      "batch 1670: loss 0.204540\n",
      "batch 1671: loss 0.155008\n",
      "batch 1672: loss 0.113187\n",
      "batch 1673: loss 0.102589\n",
      "batch 1674: loss 0.140821\n",
      "batch 1675: loss 0.117700\n",
      "batch 1676: loss 0.195179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1677: loss 0.160194\n",
      "batch 1678: loss 0.035753\n",
      "batch 1679: loss 0.141109\n",
      "batch 1680: loss 0.058940\n",
      "batch 1681: loss 0.094044\n",
      "batch 1682: loss 0.273682\n",
      "batch 1683: loss 0.044207\n",
      "batch 1684: loss 0.193323\n",
      "batch 1685: loss 0.136382\n",
      "batch 1686: loss 0.134447\n",
      "batch 1687: loss 0.088205\n",
      "batch 1688: loss 0.158309\n",
      "batch 1689: loss 0.159827\n",
      "batch 1690: loss 0.241754\n",
      "batch 1691: loss 0.064703\n",
      "batch 1692: loss 0.057464\n",
      "batch 1693: loss 0.345379\n",
      "batch 1694: loss 0.055618\n",
      "batch 1695: loss 0.103882\n",
      "batch 1696: loss 0.112979\n",
      "batch 1697: loss 0.270604\n",
      "batch 1698: loss 0.380239\n",
      "batch 1699: loss 0.098131\n",
      "batch 1700: loss 0.083716\n",
      "batch 1701: loss 0.278071\n",
      "batch 1702: loss 0.150444\n",
      "batch 1703: loss 0.079158\n",
      "batch 1704: loss 0.041771\n",
      "batch 1705: loss 0.052621\n",
      "batch 1706: loss 0.196216\n",
      "batch 1707: loss 0.078263\n",
      "batch 1708: loss 0.136213\n",
      "batch 1709: loss 0.075868\n",
      "batch 1710: loss 0.225519\n",
      "batch 1711: loss 0.118236\n",
      "batch 1712: loss 0.080280\n",
      "batch 1713: loss 0.202467\n",
      "batch 1714: loss 0.054207\n",
      "batch 1715: loss 0.062495\n",
      "batch 1716: loss 0.081315\n",
      "batch 1717: loss 0.095998\n",
      "batch 1718: loss 0.033679\n",
      "batch 1719: loss 0.115050\n",
      "batch 1720: loss 0.098652\n",
      "batch 1721: loss 0.143047\n",
      "batch 1722: loss 0.142528\n",
      "batch 1723: loss 0.060422\n",
      "batch 1724: loss 0.121074\n",
      "batch 1725: loss 0.246935\n",
      "batch 1726: loss 0.314936\n",
      "batch 1727: loss 0.107163\n",
      "batch 1728: loss 0.271554\n",
      "batch 1729: loss 0.188590\n",
      "batch 1730: loss 0.113058\n",
      "batch 1731: loss 0.054369\n",
      "batch 1732: loss 0.036381\n",
      "batch 1733: loss 0.186397\n",
      "batch 1734: loss 0.147354\n",
      "batch 1735: loss 0.241281\n",
      "batch 1736: loss 0.168295\n",
      "batch 1737: loss 0.120246\n",
      "batch 1738: loss 0.114449\n",
      "batch 1739: loss 0.120289\n",
      "batch 1740: loss 0.270016\n",
      "batch 1741: loss 0.090930\n",
      "batch 1742: loss 0.112088\n",
      "batch 1743: loss 0.197374\n",
      "batch 1744: loss 0.095495\n",
      "batch 1745: loss 0.086490\n",
      "batch 1746: loss 0.087645\n",
      "batch 1747: loss 0.101300\n",
      "batch 1748: loss 0.099442\n",
      "batch 1749: loss 0.161690\n",
      "batch 1750: loss 0.121610\n",
      "batch 1751: loss 0.190054\n",
      "batch 1752: loss 0.078709\n",
      "batch 1753: loss 0.132829\n",
      "batch 1754: loss 0.205511\n",
      "batch 1755: loss 0.195680\n",
      "batch 1756: loss 0.088611\n",
      "batch 1757: loss 0.053051\n",
      "batch 1758: loss 0.163763\n",
      "batch 1759: loss 0.176963\n",
      "batch 1760: loss 0.089199\n",
      "batch 1761: loss 0.164436\n",
      "batch 1762: loss 0.119393\n",
      "batch 1763: loss 0.060043\n",
      "batch 1764: loss 0.209574\n",
      "batch 1765: loss 0.133205\n",
      "batch 1766: loss 0.097762\n",
      "batch 1767: loss 0.126468\n",
      "batch 1768: loss 0.058278\n",
      "batch 1769: loss 0.209582\n",
      "batch 1770: loss 0.126258\n",
      "batch 1771: loss 0.251390\n",
      "batch 1772: loss 0.089846\n",
      "batch 1773: loss 0.063912\n",
      "batch 1774: loss 0.138062\n",
      "batch 1775: loss 0.113385\n",
      "batch 1776: loss 0.076088\n",
      "batch 1777: loss 0.120433\n",
      "batch 1778: loss 0.086099\n",
      "batch 1779: loss 0.113847\n",
      "batch 1780: loss 0.220797\n",
      "batch 1781: loss 0.183116\n",
      "batch 1782: loss 0.163928\n",
      "batch 1783: loss 0.098228\n",
      "batch 1784: loss 0.030547\n",
      "batch 1785: loss 0.085202\n",
      "batch 1786: loss 0.214317\n",
      "batch 1787: loss 0.061757\n",
      "batch 1788: loss 0.183928\n",
      "batch 1789: loss 0.032261\n",
      "batch 1790: loss 0.056976\n",
      "batch 1791: loss 0.409324\n",
      "batch 1792: loss 0.180931\n",
      "batch 1793: loss 0.175298\n",
      "batch 1794: loss 0.036502\n",
      "batch 1795: loss 0.156987\n",
      "batch 1796: loss 0.077825\n",
      "batch 1797: loss 0.097761\n",
      "batch 1798: loss 0.321268\n",
      "batch 1799: loss 0.055167\n",
      "batch 1800: loss 0.353596\n",
      "batch 1801: loss 0.201523\n",
      "batch 1802: loss 0.117273\n",
      "batch 1803: loss 0.277172\n",
      "batch 1804: loss 0.119250\n",
      "batch 1805: loss 0.083414\n",
      "batch 1806: loss 0.132330\n",
      "batch 1807: loss 0.015104\n",
      "batch 1808: loss 0.085513\n",
      "batch 1809: loss 0.142953\n",
      "batch 1810: loss 0.034318\n",
      "batch 1811: loss 0.272696\n",
      "batch 1812: loss 0.107068\n",
      "batch 1813: loss 0.057012\n",
      "batch 1814: loss 0.192677\n",
      "batch 1815: loss 0.105046\n",
      "batch 1816: loss 0.264795\n",
      "batch 1817: loss 0.100528\n",
      "batch 1818: loss 0.121682\n",
      "batch 1819: loss 0.075359\n",
      "batch 1820: loss 0.069542\n",
      "batch 1821: loss 0.228516\n",
      "batch 1822: loss 0.055260\n",
      "batch 1823: loss 0.064589\n",
      "batch 1824: loss 0.092538\n",
      "batch 1825: loss 0.049222\n",
      "batch 1826: loss 0.046318\n",
      "batch 1827: loss 0.064693\n",
      "batch 1828: loss 0.177656\n",
      "batch 1829: loss 0.123830\n",
      "batch 1830: loss 0.163134\n",
      "batch 1831: loss 0.206616\n",
      "batch 1832: loss 0.153171\n",
      "batch 1833: loss 0.123422\n",
      "batch 1834: loss 0.117879\n",
      "batch 1835: loss 0.098064\n",
      "batch 1836: loss 0.116654\n",
      "batch 1837: loss 0.048367\n",
      "batch 1838: loss 0.254091\n",
      "batch 1839: loss 0.043728\n",
      "batch 1840: loss 0.157690\n",
      "batch 1841: loss 0.148759\n",
      "batch 1842: loss 0.157465\n",
      "batch 1843: loss 0.135989\n",
      "batch 1844: loss 0.075309\n",
      "batch 1845: loss 0.135754\n",
      "batch 1846: loss 0.169467\n",
      "batch 1847: loss 0.152924\n",
      "batch 1848: loss 0.160849\n",
      "batch 1849: loss 0.101878\n",
      "batch 1850: loss 0.070547\n",
      "batch 1851: loss 0.047382\n",
      "batch 1852: loss 0.118267\n",
      "batch 1853: loss 0.202234\n",
      "batch 1854: loss 0.074796\n",
      "batch 1855: loss 0.151528\n",
      "batch 1856: loss 0.130789\n",
      "batch 1857: loss 0.047778\n",
      "batch 1858: loss 0.091418\n",
      "batch 1859: loss 0.064881\n",
      "batch 1860: loss 0.132070\n",
      "batch 1861: loss 0.128800\n",
      "batch 1862: loss 0.112355\n",
      "batch 1863: loss 0.076453\n",
      "batch 1864: loss 0.110125\n",
      "batch 1865: loss 0.102826\n",
      "batch 1866: loss 0.059155\n",
      "batch 1867: loss 0.216390\n",
      "batch 1868: loss 0.015126\n",
      "batch 1869: loss 0.154858\n",
      "batch 1870: loss 0.246776\n",
      "batch 1871: loss 0.073640\n",
      "batch 1872: loss 0.028787\n",
      "batch 1873: loss 0.103563\n",
      "batch 1874: loss 0.099487\n",
      "batch 1875: loss 0.045923\n",
      "batch 1876: loss 0.119538\n",
      "batch 1877: loss 0.374090\n",
      "batch 1878: loss 0.110107\n",
      "batch 1879: loss 0.237703\n",
      "batch 1880: loss 0.111568\n",
      "batch 1881: loss 0.031849\n",
      "batch 1882: loss 0.157113\n",
      "batch 1883: loss 0.023687\n",
      "batch 1884: loss 0.114771\n",
      "batch 1885: loss 0.060175\n",
      "batch 1886: loss 0.141462\n",
      "batch 1887: loss 0.064432\n",
      "batch 1888: loss 0.119512\n",
      "batch 1889: loss 0.054189\n",
      "batch 1890: loss 0.075744\n",
      "batch 1891: loss 0.146657\n",
      "batch 1892: loss 0.162854\n",
      "batch 1893: loss 0.291794\n",
      "batch 1894: loss 0.106743\n",
      "batch 1895: loss 0.058580\n",
      "batch 1896: loss 0.112382\n",
      "batch 1897: loss 0.106710\n",
      "batch 1898: loss 0.054503\n",
      "batch 1899: loss 0.277254\n",
      "batch 1900: loss 0.143161\n",
      "batch 1901: loss 0.155274\n",
      "batch 1902: loss 0.122902\n",
      "batch 1903: loss 0.348648\n",
      "batch 1904: loss 0.028665\n",
      "batch 1905: loss 0.091712\n",
      "batch 1906: loss 0.097734\n",
      "batch 1907: loss 0.102389\n",
      "batch 1908: loss 0.125462\n",
      "batch 1909: loss 0.098120\n",
      "batch 1910: loss 0.041210\n",
      "batch 1911: loss 0.073359\n",
      "batch 1912: loss 0.155045\n",
      "batch 1913: loss 0.030313\n",
      "batch 1914: loss 0.119004\n",
      "batch 1915: loss 0.132869\n",
      "batch 1916: loss 0.180324\n",
      "batch 1917: loss 0.083368\n",
      "batch 1918: loss 0.112760\n",
      "batch 1919: loss 0.202270\n",
      "batch 1920: loss 0.089257\n",
      "batch 1921: loss 0.086081\n",
      "batch 1922: loss 0.066075\n",
      "batch 1923: loss 0.084034\n",
      "batch 1924: loss 0.119604\n",
      "batch 1925: loss 0.118098\n",
      "batch 1926: loss 0.076998\n",
      "batch 1927: loss 0.172911\n",
      "batch 1928: loss 0.129670\n",
      "batch 1929: loss 0.148819\n",
      "batch 1930: loss 0.142366\n",
      "batch 1931: loss 0.055356\n",
      "batch 1932: loss 0.108785\n",
      "batch 1933: loss 0.148565\n",
      "batch 1934: loss 0.156241\n",
      "batch 1935: loss 0.191685\n",
      "batch 1936: loss 0.107974\n",
      "batch 1937: loss 0.065866\n",
      "batch 1938: loss 0.122672\n",
      "batch 1939: loss 0.059083\n",
      "batch 1940: loss 0.101743\n",
      "batch 1941: loss 0.087891\n",
      "batch 1942: loss 0.021342\n",
      "batch 1943: loss 0.049126\n",
      "batch 1944: loss 0.155884\n",
      "batch 1945: loss 0.117397\n",
      "batch 1946: loss 0.056140\n",
      "batch 1947: loss 0.176715\n",
      "batch 1948: loss 0.051012\n",
      "batch 1949: loss 0.050086\n",
      "batch 1950: loss 0.180654\n",
      "batch 1951: loss 0.097844\n",
      "batch 1952: loss 0.133607\n",
      "batch 1953: loss 0.071665\n",
      "batch 1954: loss 0.071106\n",
      "batch 1955: loss 0.056871\n",
      "batch 1956: loss 0.140425\n",
      "batch 1957: loss 0.107210\n",
      "batch 1958: loss 0.066261\n",
      "batch 1959: loss 0.092584\n",
      "batch 1960: loss 0.062708\n",
      "batch 1961: loss 0.041124\n",
      "batch 1962: loss 0.153096\n",
      "batch 1963: loss 0.186548\n",
      "batch 1964: loss 0.257664\n",
      "batch 1965: loss 0.095284\n",
      "batch 1966: loss 0.102218\n",
      "batch 1967: loss 0.161486\n",
      "batch 1968: loss 0.291797\n",
      "batch 1969: loss 0.089098\n",
      "batch 1970: loss 0.026017\n",
      "batch 1971: loss 0.063785\n",
      "batch 1972: loss 0.156475\n",
      "batch 1973: loss 0.118464\n",
      "batch 1974: loss 0.165387\n",
      "batch 1975: loss 0.227684\n",
      "batch 1976: loss 0.052408\n",
      "batch 1977: loss 0.056700\n",
      "batch 1978: loss 0.061951\n",
      "batch 1979: loss 0.200796\n",
      "batch 1980: loss 0.039546\n",
      "batch 1981: loss 0.213370\n",
      "batch 1982: loss 0.133834\n",
      "batch 1983: loss 0.168657\n",
      "batch 1984: loss 0.059555\n",
      "batch 1985: loss 0.168561\n",
      "batch 1986: loss 0.063368\n",
      "batch 1987: loss 0.039187\n",
      "batch 1988: loss 0.046446\n",
      "batch 1989: loss 0.093552\n",
      "batch 1990: loss 0.073352\n",
      "batch 1991: loss 0.055937\n",
      "batch 1992: loss 0.106299\n",
      "batch 1993: loss 0.105671\n",
      "batch 1994: loss 0.190233\n",
      "batch 1995: loss 0.122287\n",
      "batch 1996: loss 0.174232\n",
      "batch 1997: loss 0.122776\n",
      "batch 1998: loss 0.059078\n",
      "batch 1999: loss 0.229503\n",
      "batch 2000: loss 0.257534\n",
      "batch 2001: loss 0.243840\n",
      "batch 2002: loss 0.093917\n",
      "batch 2003: loss 0.152830\n",
      "batch 2004: loss 0.114469\n",
      "batch 2005: loss 0.080622\n",
      "batch 2006: loss 0.084144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2007: loss 0.072340\n",
      "batch 2008: loss 0.133862\n",
      "batch 2009: loss 0.093813\n",
      "batch 2010: loss 0.189375\n",
      "batch 2011: loss 0.047397\n",
      "batch 2012: loss 0.124968\n",
      "batch 2013: loss 0.073413\n",
      "batch 2014: loss 0.303389\n",
      "batch 2015: loss 0.109084\n",
      "batch 2016: loss 0.223872\n",
      "batch 2017: loss 0.047719\n",
      "batch 2018: loss 0.089301\n",
      "batch 2019: loss 0.072166\n",
      "batch 2020: loss 0.098508\n",
      "batch 2021: loss 0.081114\n",
      "batch 2022: loss 0.044827\n",
      "batch 2023: loss 0.085451\n",
      "batch 2024: loss 0.237212\n",
      "batch 2025: loss 0.280838\n",
      "batch 2026: loss 0.151866\n",
      "batch 2027: loss 0.127723\n",
      "batch 2028: loss 0.271027\n",
      "batch 2029: loss 0.141278\n",
      "batch 2030: loss 0.067672\n",
      "batch 2031: loss 0.193344\n",
      "batch 2032: loss 0.206371\n",
      "batch 2033: loss 0.080495\n",
      "batch 2034: loss 0.106537\n",
      "batch 2035: loss 0.081373\n",
      "batch 2036: loss 0.063803\n",
      "batch 2037: loss 0.229890\n",
      "batch 2038: loss 0.283576\n",
      "batch 2039: loss 0.055973\n",
      "batch 2040: loss 0.120511\n",
      "batch 2041: loss 0.239391\n",
      "batch 2042: loss 0.119733\n",
      "batch 2043: loss 0.073612\n",
      "batch 2044: loss 0.061366\n",
      "batch 2045: loss 0.183088\n",
      "batch 2046: loss 0.160481\n",
      "batch 2047: loss 0.100549\n",
      "batch 2048: loss 0.088080\n",
      "batch 2049: loss 0.069948\n",
      "batch 2050: loss 0.264748\n",
      "batch 2051: loss 0.267139\n",
      "batch 2052: loss 0.030746\n",
      "batch 2053: loss 0.084710\n",
      "batch 2054: loss 0.059913\n",
      "batch 2055: loss 0.238432\n",
      "batch 2056: loss 0.201334\n",
      "batch 2057: loss 0.122434\n",
      "batch 2058: loss 0.039036\n",
      "batch 2059: loss 0.090448\n",
      "batch 2060: loss 0.100688\n",
      "batch 2061: loss 0.119292\n",
      "batch 2062: loss 0.061347\n",
      "batch 2063: loss 0.090014\n",
      "batch 2064: loss 0.106200\n",
      "batch 2065: loss 0.070060\n",
      "batch 2066: loss 0.072586\n",
      "batch 2067: loss 0.153100\n",
      "batch 2068: loss 0.079880\n",
      "batch 2069: loss 0.045539\n",
      "batch 2070: loss 0.019984\n",
      "batch 2071: loss 0.031091\n",
      "batch 2072: loss 0.126805\n",
      "batch 2073: loss 0.064175\n",
      "batch 2074: loss 0.128061\n",
      "batch 2075: loss 0.114007\n",
      "batch 2076: loss 0.225998\n",
      "batch 2077: loss 0.039318\n",
      "batch 2078: loss 0.037043\n",
      "batch 2079: loss 0.184618\n",
      "batch 2080: loss 0.240271\n",
      "batch 2081: loss 0.210388\n",
      "batch 2082: loss 0.065723\n",
      "batch 2083: loss 0.110665\n",
      "batch 2084: loss 0.053307\n",
      "batch 2085: loss 0.065977\n",
      "batch 2086: loss 0.094827\n",
      "batch 2087: loss 0.076569\n",
      "batch 2088: loss 0.027500\n",
      "batch 2089: loss 0.054981\n",
      "batch 2090: loss 0.104750\n",
      "batch 2091: loss 0.092652\n",
      "batch 2092: loss 0.179455\n",
      "batch 2093: loss 0.144706\n",
      "batch 2094: loss 0.195978\n",
      "batch 2095: loss 0.123250\n",
      "batch 2096: loss 0.084772\n",
      "batch 2097: loss 0.036097\n",
      "batch 2098: loss 0.238548\n",
      "batch 2099: loss 0.061864\n",
      "batch 2100: loss 0.038866\n",
      "batch 2101: loss 0.242999\n",
      "batch 2102: loss 0.105762\n",
      "batch 2103: loss 0.122829\n",
      "batch 2104: loss 0.181528\n",
      "batch 2105: loss 0.073429\n",
      "batch 2106: loss 0.073444\n",
      "batch 2107: loss 0.282305\n",
      "batch 2108: loss 0.075098\n",
      "batch 2109: loss 0.130261\n",
      "batch 2110: loss 0.093116\n",
      "batch 2111: loss 0.191528\n",
      "batch 2112: loss 0.065231\n",
      "batch 2113: loss 0.148344\n",
      "batch 2114: loss 0.036032\n",
      "batch 2115: loss 0.132678\n",
      "batch 2116: loss 0.062988\n",
      "batch 2117: loss 0.059636\n",
      "batch 2118: loss 0.161769\n",
      "batch 2119: loss 0.175845\n",
      "batch 2120: loss 0.141918\n",
      "batch 2121: loss 0.164248\n",
      "batch 2122: loss 0.247444\n",
      "batch 2123: loss 0.153390\n",
      "batch 2124: loss 0.053566\n",
      "batch 2125: loss 0.077189\n",
      "batch 2126: loss 0.090932\n",
      "batch 2127: loss 0.038584\n",
      "batch 2128: loss 0.071464\n",
      "batch 2129: loss 0.076067\n",
      "batch 2130: loss 0.042272\n",
      "batch 2131: loss 0.087711\n",
      "batch 2132: loss 0.283907\n",
      "batch 2133: loss 0.090049\n",
      "batch 2134: loss 0.103265\n",
      "batch 2135: loss 0.041340\n",
      "batch 2136: loss 0.092038\n",
      "batch 2137: loss 0.085433\n",
      "batch 2138: loss 0.061592\n",
      "batch 2139: loss 0.123698\n",
      "batch 2140: loss 0.123025\n",
      "batch 2141: loss 0.117055\n",
      "batch 2142: loss 0.022618\n",
      "batch 2143: loss 0.194655\n",
      "batch 2144: loss 0.159609\n",
      "batch 2145: loss 0.176331\n",
      "batch 2146: loss 0.044156\n",
      "batch 2147: loss 0.150924\n",
      "batch 2148: loss 0.096479\n",
      "batch 2149: loss 0.128365\n",
      "batch 2150: loss 0.172042\n",
      "batch 2151: loss 0.136606\n",
      "batch 2152: loss 0.084921\n",
      "batch 2153: loss 0.056761\n",
      "batch 2154: loss 0.042521\n",
      "batch 2155: loss 0.262550\n",
      "batch 2156: loss 0.215275\n",
      "batch 2157: loss 0.030417\n",
      "batch 2158: loss 0.431038\n",
      "batch 2159: loss 0.067415\n",
      "batch 2160: loss 0.083278\n",
      "batch 2161: loss 0.137991\n",
      "batch 2162: loss 0.216836\n",
      "batch 2163: loss 0.174790\n",
      "batch 2164: loss 0.124752\n",
      "batch 2165: loss 0.106005\n",
      "batch 2166: loss 0.123976\n",
      "batch 2167: loss 0.225755\n",
      "batch 2168: loss 0.126716\n",
      "batch 2169: loss 0.110453\n",
      "batch 2170: loss 0.095726\n",
      "batch 2171: loss 0.047536\n",
      "batch 2172: loss 0.064964\n",
      "batch 2173: loss 0.174212\n",
      "batch 2174: loss 0.072131\n",
      "batch 2175: loss 0.059129\n",
      "batch 2176: loss 0.225466\n",
      "batch 2177: loss 0.072080\n",
      "batch 2178: loss 0.088798\n",
      "batch 2179: loss 0.173231\n",
      "batch 2180: loss 0.076829\n",
      "batch 2181: loss 0.068884\n",
      "batch 2182: loss 0.083789\n",
      "batch 2183: loss 0.065513\n",
      "batch 2184: loss 0.177515\n",
      "batch 2185: loss 0.108544\n",
      "batch 2186: loss 0.065189\n",
      "batch 2187: loss 0.070732\n",
      "batch 2188: loss 0.091285\n",
      "batch 2189: loss 0.117509\n",
      "batch 2190: loss 0.074876\n",
      "batch 2191: loss 0.331645\n",
      "batch 2192: loss 0.042576\n",
      "batch 2193: loss 0.095741\n",
      "batch 2194: loss 0.133908\n",
      "batch 2195: loss 0.155838\n",
      "batch 2196: loss 0.018477\n",
      "batch 2197: loss 0.064082\n",
      "batch 2198: loss 0.152355\n",
      "batch 2199: loss 0.126826\n",
      "batch 2200: loss 0.039309\n",
      "batch 2201: loss 0.115366\n",
      "batch 2202: loss 0.072698\n",
      "batch 2203: loss 0.194564\n",
      "batch 2204: loss 0.152959\n",
      "batch 2205: loss 0.068604\n",
      "batch 2206: loss 0.064238\n",
      "batch 2207: loss 0.124976\n",
      "batch 2208: loss 0.172556\n",
      "batch 2209: loss 0.206162\n",
      "batch 2210: loss 0.091062\n",
      "batch 2211: loss 0.075613\n",
      "batch 2212: loss 0.066536\n",
      "batch 2213: loss 0.181773\n",
      "batch 2214: loss 0.145993\n",
      "batch 2215: loss 0.071976\n",
      "batch 2216: loss 0.095809\n",
      "batch 2217: loss 0.040544\n",
      "batch 2218: loss 0.148527\n",
      "batch 2219: loss 0.051596\n",
      "batch 2220: loss 0.261351\n",
      "batch 2221: loss 0.039060\n",
      "batch 2222: loss 0.112570\n",
      "batch 2223: loss 0.051251\n",
      "batch 2224: loss 0.041505\n",
      "batch 2225: loss 0.074234\n",
      "batch 2226: loss 0.039641\n",
      "batch 2227: loss 0.101816\n",
      "batch 2228: loss 0.114070\n",
      "batch 2229: loss 0.058826\n",
      "batch 2230: loss 0.027626\n",
      "batch 2231: loss 0.092180\n",
      "batch 2232: loss 0.086248\n",
      "batch 2233: loss 0.038454\n",
      "batch 2234: loss 0.083691\n",
      "batch 2235: loss 0.025174\n",
      "batch 2236: loss 0.043327\n",
      "batch 2237: loss 0.043516\n",
      "batch 2238: loss 0.127792\n",
      "batch 2239: loss 0.076030\n",
      "batch 2240: loss 0.076475\n",
      "batch 2241: loss 0.086313\n",
      "batch 2242: loss 0.028738\n",
      "batch 2243: loss 0.373837\n",
      "batch 2244: loss 0.048241\n",
      "batch 2245: loss 0.166159\n",
      "batch 2246: loss 0.111426\n",
      "batch 2247: loss 0.035003\n",
      "batch 2248: loss 0.073268\n",
      "batch 2249: loss 0.147849\n",
      "batch 2250: loss 0.128305\n",
      "batch 2251: loss 0.074138\n",
      "batch 2252: loss 0.048470\n",
      "batch 2253: loss 0.016192\n",
      "batch 2254: loss 0.048840\n",
      "batch 2255: loss 0.083168\n",
      "batch 2256: loss 0.042149\n",
      "batch 2257: loss 0.274325\n",
      "batch 2258: loss 0.055070\n",
      "batch 2259: loss 0.093785\n",
      "batch 2260: loss 0.069264\n",
      "batch 2261: loss 0.094527\n",
      "batch 2262: loss 0.144524\n",
      "batch 2263: loss 0.057496\n",
      "batch 2264: loss 0.107285\n",
      "batch 2265: loss 0.107685\n",
      "batch 2266: loss 0.111026\n",
      "batch 2267: loss 0.072476\n",
      "batch 2268: loss 0.230069\n",
      "batch 2269: loss 0.054632\n",
      "batch 2270: loss 0.131448\n",
      "batch 2271: loss 0.217064\n",
      "batch 2272: loss 0.104878\n",
      "batch 2273: loss 0.126311\n",
      "batch 2274: loss 0.114941\n",
      "batch 2275: loss 0.080389\n",
      "batch 2276: loss 0.117835\n",
      "batch 2277: loss 0.177018\n",
      "batch 2278: loss 0.097963\n",
      "batch 2279: loss 0.037282\n",
      "batch 2280: loss 0.082815\n",
      "batch 2281: loss 0.030284\n",
      "batch 2282: loss 0.089968\n",
      "batch 2283: loss 0.039864\n",
      "batch 2284: loss 0.124053\n",
      "batch 2285: loss 0.269018\n",
      "batch 2286: loss 0.039912\n",
      "batch 2287: loss 0.136100\n",
      "batch 2288: loss 0.183600\n",
      "batch 2289: loss 0.029416\n",
      "batch 2290: loss 0.159076\n",
      "batch 2291: loss 0.028617\n",
      "batch 2292: loss 0.075772\n",
      "batch 2293: loss 0.026452\n",
      "batch 2294: loss 0.108727\n",
      "batch 2295: loss 0.226268\n",
      "batch 2296: loss 0.086951\n",
      "batch 2297: loss 0.248824\n",
      "batch 2298: loss 0.129881\n",
      "batch 2299: loss 0.041567\n",
      "batch 2300: loss 0.051471\n",
      "batch 2301: loss 0.210575\n",
      "batch 2302: loss 0.055128\n",
      "batch 2303: loss 0.073367\n",
      "batch 2304: loss 0.113935\n",
      "batch 2305: loss 0.050601\n",
      "batch 2306: loss 0.048855\n",
      "batch 2307: loss 0.176680\n",
      "batch 2308: loss 0.138527\n",
      "batch 2309: loss 0.259082\n",
      "batch 2310: loss 0.377889\n",
      "batch 2311: loss 0.104060\n",
      "batch 2312: loss 0.039266\n",
      "batch 2313: loss 0.185613\n",
      "batch 2314: loss 0.135326\n",
      "batch 2315: loss 0.064445\n",
      "batch 2316: loss 0.131197\n",
      "batch 2317: loss 0.059965\n",
      "batch 2318: loss 0.031732\n",
      "batch 2319: loss 0.066046\n",
      "batch 2320: loss 0.154504\n",
      "batch 2321: loss 0.203516\n",
      "batch 2322: loss 0.084909\n",
      "batch 2323: loss 0.226929\n",
      "batch 2324: loss 0.262566\n",
      "batch 2325: loss 0.215820\n",
      "batch 2326: loss 0.137957\n",
      "batch 2327: loss 0.213909\n",
      "batch 2328: loss 0.140959\n",
      "batch 2329: loss 0.179665\n",
      "batch 2330: loss 0.152147\n",
      "batch 2331: loss 0.081722\n",
      "batch 2332: loss 0.040078\n",
      "batch 2333: loss 0.050736\n",
      "batch 2334: loss 0.077955\n",
      "batch 2335: loss 0.112114\n",
      "batch 2336: loss 0.083829\n",
      "batch 2337: loss 0.235627\n",
      "batch 2338: loss 0.134979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2339: loss 0.089268\n",
      "batch 2340: loss 0.064107\n",
      "batch 2341: loss 0.117457\n",
      "batch 2342: loss 0.114749\n",
      "batch 2343: loss 0.084663\n",
      "batch 2344: loss 0.049583\n",
      "batch 2345: loss 0.082707\n",
      "batch 2346: loss 0.103206\n",
      "batch 2347: loss 0.053971\n",
      "batch 2348: loss 0.436312\n",
      "batch 2349: loss 0.083268\n",
      "batch 2350: loss 0.054404\n",
      "batch 2351: loss 0.016921\n",
      "batch 2352: loss 0.158012\n",
      "batch 2353: loss 0.142246\n",
      "batch 2354: loss 0.046114\n",
      "batch 2355: loss 0.404361\n",
      "batch 2356: loss 0.054854\n",
      "batch 2357: loss 0.156947\n",
      "batch 2358: loss 0.051046\n",
      "batch 2359: loss 0.113070\n",
      "batch 2360: loss 0.048772\n",
      "batch 2361: loss 0.170007\n",
      "batch 2362: loss 0.135803\n",
      "batch 2363: loss 0.065859\n",
      "batch 2364: loss 0.067526\n",
      "batch 2365: loss 0.084251\n",
      "batch 2366: loss 0.052549\n",
      "batch 2367: loss 0.027904\n",
      "batch 2368: loss 0.109133\n",
      "batch 2369: loss 0.322382\n",
      "batch 2370: loss 0.092979\n",
      "batch 2371: loss 0.103315\n",
      "batch 2372: loss 0.082282\n",
      "batch 2373: loss 0.135728\n",
      "batch 2374: loss 0.152199\n",
      "batch 2375: loss 0.041260\n",
      "batch 2376: loss 0.069801\n",
      "batch 2377: loss 0.049004\n",
      "batch 2378: loss 0.158268\n",
      "batch 2379: loss 0.058484\n",
      "batch 2380: loss 0.052563\n",
      "batch 2381: loss 0.051229\n",
      "batch 2382: loss 0.133910\n",
      "batch 2383: loss 0.071371\n",
      "batch 2384: loss 0.108041\n",
      "batch 2385: loss 0.074737\n",
      "batch 2386: loss 0.090082\n",
      "batch 2387: loss 0.196117\n",
      "batch 2388: loss 0.116195\n",
      "batch 2389: loss 0.011069\n",
      "batch 2390: loss 0.087842\n",
      "batch 2391: loss 0.134959\n",
      "batch 2392: loss 0.211246\n",
      "batch 2393: loss 0.021277\n",
      "batch 2394: loss 0.132483\n",
      "batch 2395: loss 0.134101\n",
      "batch 2396: loss 0.046573\n",
      "batch 2397: loss 0.066994\n",
      "batch 2398: loss 0.059428\n",
      "batch 2399: loss 0.103142\n",
      "batch 2400: loss 0.134207\n",
      "batch 2401: loss 0.059763\n",
      "batch 2402: loss 0.181567\n",
      "batch 2403: loss 0.133915\n",
      "batch 2404: loss 0.021058\n",
      "batch 2405: loss 0.050931\n",
      "batch 2406: loss 0.159159\n",
      "batch 2407: loss 0.062917\n",
      "batch 2408: loss 0.072124\n",
      "batch 2409: loss 0.071864\n",
      "batch 2410: loss 0.296236\n",
      "batch 2411: loss 0.072314\n",
      "batch 2412: loss 0.121107\n",
      "batch 2413: loss 0.075039\n",
      "batch 2414: loss 0.172957\n",
      "batch 2415: loss 0.044989\n",
      "batch 2416: loss 0.141410\n",
      "batch 2417: loss 0.181678\n",
      "batch 2418: loss 0.040246\n",
      "batch 2419: loss 0.124560\n",
      "batch 2420: loss 0.040137\n",
      "batch 2421: loss 0.127806\n",
      "batch 2422: loss 0.064206\n",
      "batch 2423: loss 0.174974\n",
      "batch 2424: loss 0.136774\n",
      "batch 2425: loss 0.031594\n",
      "batch 2426: loss 0.028780\n",
      "batch 2427: loss 0.058343\n",
      "batch 2428: loss 0.206789\n",
      "batch 2429: loss 0.116504\n",
      "batch 2430: loss 0.161758\n",
      "batch 2431: loss 0.075701\n",
      "batch 2432: loss 0.113804\n",
      "batch 2433: loss 0.038746\n",
      "batch 2434: loss 0.035671\n",
      "batch 2435: loss 0.058290\n",
      "batch 2436: loss 0.044403\n",
      "batch 2437: loss 0.092324\n",
      "batch 2438: loss 0.090563\n",
      "batch 2439: loss 0.188550\n",
      "batch 2440: loss 0.117616\n",
      "batch 2441: loss 0.040689\n",
      "batch 2442: loss 0.035676\n",
      "batch 2443: loss 0.087776\n",
      "batch 2444: loss 0.322221\n",
      "batch 2445: loss 0.116054\n",
      "batch 2446: loss 0.150147\n",
      "batch 2447: loss 0.075932\n",
      "batch 2448: loss 0.070916\n",
      "batch 2449: loss 0.079177\n",
      "batch 2450: loss 0.054768\n",
      "batch 2451: loss 0.064145\n",
      "batch 2452: loss 0.134575\n",
      "batch 2453: loss 0.095822\n",
      "batch 2454: loss 0.050672\n",
      "batch 2455: loss 0.043175\n",
      "batch 2456: loss 0.118854\n",
      "batch 2457: loss 0.077465\n",
      "batch 2458: loss 0.097075\n",
      "batch 2459: loss 0.176971\n",
      "batch 2460: loss 0.105365\n",
      "batch 2461: loss 0.094682\n",
      "batch 2462: loss 0.116308\n",
      "batch 2463: loss 0.041887\n",
      "batch 2464: loss 0.145318\n",
      "batch 2465: loss 0.054515\n",
      "batch 2466: loss 0.196257\n",
      "batch 2467: loss 0.034678\n",
      "batch 2468: loss 0.175099\n",
      "batch 2469: loss 0.266168\n",
      "batch 2470: loss 0.151515\n",
      "batch 2471: loss 0.058208\n",
      "batch 2472: loss 0.089987\n",
      "batch 2473: loss 0.129584\n",
      "batch 2474: loss 0.056618\n",
      "batch 2475: loss 0.077746\n",
      "batch 2476: loss 0.039356\n",
      "batch 2477: loss 0.042893\n",
      "batch 2478: loss 0.083020\n",
      "batch 2479: loss 0.067682\n",
      "batch 2480: loss 0.046412\n",
      "batch 2481: loss 0.157921\n",
      "batch 2482: loss 0.033408\n",
      "batch 2483: loss 0.030369\n",
      "batch 2484: loss 0.305308\n",
      "batch 2485: loss 0.030121\n",
      "batch 2486: loss 0.072134\n",
      "batch 2487: loss 0.154274\n",
      "batch 2488: loss 0.046041\n",
      "batch 2489: loss 0.133096\n",
      "batch 2490: loss 0.113553\n",
      "batch 2491: loss 0.060867\n",
      "batch 2492: loss 0.026895\n",
      "batch 2493: loss 0.099222\n",
      "batch 2494: loss 0.097766\n",
      "batch 2495: loss 0.113697\n",
      "batch 2496: loss 0.207117\n",
      "batch 2497: loss 0.047204\n",
      "batch 2498: loss 0.216333\n",
      "batch 2499: loss 0.112820\n",
      "batch 2500: loss 0.062864\n",
      "batch 2501: loss 0.032698\n",
      "batch 2502: loss 0.213636\n",
      "batch 2503: loss 0.177690\n",
      "batch 2504: loss 0.074089\n",
      "batch 2505: loss 0.069088\n",
      "batch 2506: loss 0.031518\n",
      "batch 2507: loss 0.142616\n",
      "batch 2508: loss 0.055245\n",
      "batch 2509: loss 0.169460\n",
      "batch 2510: loss 0.193513\n",
      "batch 2511: loss 0.022874\n",
      "batch 2512: loss 0.193031\n",
      "batch 2513: loss 0.144128\n",
      "batch 2514: loss 0.171394\n",
      "batch 2515: loss 0.064008\n",
      "batch 2516: loss 0.262274\n",
      "batch 2517: loss 0.415743\n",
      "batch 2518: loss 0.097547\n",
      "batch 2519: loss 0.187510\n",
      "batch 2520: loss 0.109011\n",
      "batch 2521: loss 0.052704\n",
      "batch 2522: loss 0.064259\n",
      "batch 2523: loss 0.058326\n",
      "batch 2524: loss 0.042507\n",
      "batch 2525: loss 0.115038\n",
      "batch 2526: loss 0.073961\n",
      "batch 2527: loss 0.023511\n",
      "batch 2528: loss 0.158141\n",
      "batch 2529: loss 0.178972\n",
      "batch 2530: loss 0.064197\n",
      "batch 2531: loss 0.044901\n",
      "batch 2532: loss 0.221744\n",
      "batch 2533: loss 0.027031\n",
      "batch 2534: loss 0.018708\n",
      "batch 2535: loss 0.037087\n",
      "batch 2536: loss 0.111649\n",
      "batch 2537: loss 0.306777\n",
      "batch 2538: loss 0.049776\n",
      "batch 2539: loss 0.020358\n",
      "batch 2540: loss 0.075409\n",
      "batch 2541: loss 0.115189\n",
      "batch 2542: loss 0.100193\n",
      "batch 2543: loss 0.064288\n",
      "batch 2544: loss 0.150505\n",
      "batch 2545: loss 0.179208\n",
      "batch 2546: loss 0.021247\n",
      "batch 2547: loss 0.140716\n",
      "batch 2548: loss 0.184565\n",
      "batch 2549: loss 0.034882\n",
      "batch 2550: loss 0.225210\n",
      "batch 2551: loss 0.081371\n",
      "batch 2552: loss 0.036770\n",
      "batch 2553: loss 0.156438\n",
      "batch 2554: loss 0.030348\n",
      "batch 2555: loss 0.064766\n",
      "batch 2556: loss 0.048557\n",
      "batch 2557: loss 0.123540\n",
      "batch 2558: loss 0.101934\n",
      "batch 2559: loss 0.055219\n",
      "batch 2560: loss 0.135961\n",
      "batch 2561: loss 0.074287\n",
      "batch 2562: loss 0.100916\n",
      "batch 2563: loss 0.041181\n",
      "batch 2564: loss 0.117815\n",
      "batch 2565: loss 0.063760\n",
      "batch 2566: loss 0.055746\n",
      "batch 2567: loss 0.053650\n",
      "batch 2568: loss 0.232272\n",
      "batch 2569: loss 0.149800\n",
      "batch 2570: loss 0.034065\n",
      "batch 2571: loss 0.122913\n",
      "batch 2572: loss 0.078392\n",
      "batch 2573: loss 0.104113\n",
      "batch 2574: loss 0.049950\n",
      "batch 2575: loss 0.105808\n",
      "batch 2576: loss 0.016578\n",
      "batch 2577: loss 0.027892\n",
      "batch 2578: loss 0.026902\n",
      "batch 2579: loss 0.119199\n",
      "batch 2580: loss 0.022689\n",
      "batch 2581: loss 0.043850\n",
      "batch 2582: loss 0.056883\n",
      "batch 2583: loss 0.176266\n",
      "batch 2584: loss 0.076987\n",
      "batch 2585: loss 0.090776\n",
      "batch 2586: loss 0.120699\n",
      "batch 2587: loss 0.018799\n",
      "batch 2588: loss 0.103739\n",
      "batch 2589: loss 0.061555\n",
      "batch 2590: loss 0.099904\n",
      "batch 2591: loss 0.113999\n",
      "batch 2592: loss 0.143560\n",
      "batch 2593: loss 0.112250\n",
      "batch 2594: loss 0.140802\n",
      "batch 2595: loss 0.047570\n",
      "batch 2596: loss 0.137281\n",
      "batch 2597: loss 0.109649\n",
      "batch 2598: loss 0.133594\n",
      "batch 2599: loss 0.059470\n",
      "batch 2600: loss 0.036995\n",
      "batch 2601: loss 0.043737\n",
      "batch 2602: loss 0.118556\n",
      "batch 2603: loss 0.073357\n",
      "batch 2604: loss 0.048547\n",
      "batch 2605: loss 0.062278\n",
      "batch 2606: loss 0.051321\n",
      "batch 2607: loss 0.171879\n",
      "batch 2608: loss 0.055015\n",
      "batch 2609: loss 0.108079\n",
      "batch 2610: loss 0.124886\n",
      "batch 2611: loss 0.293854\n",
      "batch 2612: loss 0.130416\n",
      "batch 2613: loss 0.055204\n",
      "batch 2614: loss 0.030649\n",
      "batch 2615: loss 0.139620\n",
      "batch 2616: loss 0.057205\n",
      "batch 2617: loss 0.054882\n",
      "batch 2618: loss 0.172665\n",
      "batch 2619: loss 0.047357\n",
      "batch 2620: loss 0.086663\n",
      "batch 2621: loss 0.022091\n",
      "batch 2622: loss 0.032767\n",
      "batch 2623: loss 0.138785\n",
      "batch 2624: loss 0.044216\n",
      "batch 2625: loss 0.055047\n",
      "batch 2626: loss 0.040812\n",
      "batch 2627: loss 0.030015\n",
      "batch 2628: loss 0.045703\n",
      "batch 2629: loss 0.042676\n",
      "batch 2630: loss 0.098463\n",
      "batch 2631: loss 0.158766\n",
      "batch 2632: loss 0.110840\n",
      "batch 2633: loss 0.038886\n",
      "batch 2634: loss 0.057324\n",
      "batch 2635: loss 0.153798\n",
      "batch 2636: loss 0.125299\n",
      "batch 2637: loss 0.113948\n",
      "batch 2638: loss 0.074492\n",
      "batch 2639: loss 0.038656\n",
      "batch 2640: loss 0.073463\n",
      "batch 2641: loss 0.065403\n",
      "batch 2642: loss 0.104326\n",
      "batch 2643: loss 0.115999\n",
      "batch 2644: loss 0.078082\n",
      "batch 2645: loss 0.307658\n",
      "batch 2646: loss 0.165502\n",
      "batch 2647: loss 0.096965\n",
      "batch 2648: loss 0.144707\n",
      "batch 2649: loss 0.046469\n",
      "batch 2650: loss 0.191447\n",
      "batch 2651: loss 0.038643\n",
      "batch 2652: loss 0.022425\n",
      "batch 2653: loss 0.034252\n",
      "batch 2654: loss 0.277008\n",
      "batch 2655: loss 0.133337\n",
      "batch 2656: loss 0.042823\n",
      "batch 2657: loss 0.259799\n",
      "batch 2658: loss 0.119196\n",
      "batch 2659: loss 0.053852\n",
      "batch 2660: loss 0.082527\n",
      "batch 2661: loss 0.031707\n",
      "batch 2662: loss 0.041080\n",
      "batch 2663: loss 0.089039\n",
      "batch 2664: loss 0.036549\n",
      "batch 2665: loss 0.228815\n",
      "batch 2666: loss 0.238675\n",
      "batch 2667: loss 0.104953\n",
      "batch 2668: loss 0.187596\n",
      "batch 2669: loss 0.061814\n",
      "batch 2670: loss 0.049876\n",
      "batch 2671: loss 0.155336\n",
      "batch 2672: loss 0.041518\n",
      "batch 2673: loss 0.041129\n",
      "batch 2674: loss 0.075201\n",
      "batch 2675: loss 0.093071\n",
      "batch 2676: loss 0.075895\n",
      "batch 2677: loss 0.058857\n",
      "batch 2678: loss 0.166195\n",
      "batch 2679: loss 0.251985\n",
      "batch 2680: loss 0.038824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2681: loss 0.114992\n",
      "batch 2682: loss 0.040958\n",
      "batch 2683: loss 0.064496\n",
      "batch 2684: loss 0.115168\n",
      "batch 2685: loss 0.054857\n",
      "batch 2686: loss 0.059141\n",
      "batch 2687: loss 0.011904\n",
      "batch 2688: loss 0.079529\n",
      "batch 2689: loss 0.024099\n",
      "batch 2690: loss 0.215777\n",
      "batch 2691: loss 0.075046\n",
      "batch 2692: loss 0.066942\n",
      "batch 2693: loss 0.159111\n",
      "batch 2694: loss 0.176741\n",
      "batch 2695: loss 0.196946\n",
      "batch 2696: loss 0.041107\n",
      "batch 2697: loss 0.051088\n",
      "batch 2698: loss 0.051604\n",
      "batch 2699: loss 0.201741\n",
      "batch 2700: loss 0.159544\n",
      "batch 2701: loss 0.108727\n",
      "batch 2702: loss 0.028287\n",
      "batch 2703: loss 0.032168\n",
      "batch 2704: loss 0.055052\n",
      "batch 2705: loss 0.171080\n",
      "batch 2706: loss 0.043639\n",
      "batch 2707: loss 0.177002\n",
      "batch 2708: loss 0.037802\n",
      "batch 2709: loss 0.165160\n",
      "batch 2710: loss 0.099388\n",
      "batch 2711: loss 0.043725\n",
      "batch 2712: loss 0.076239\n",
      "batch 2713: loss 0.094707\n",
      "batch 2714: loss 0.066269\n",
      "batch 2715: loss 0.154890\n",
      "batch 2716: loss 0.126170\n",
      "batch 2717: loss 0.052647\n",
      "batch 2718: loss 0.082448\n",
      "batch 2719: loss 0.167017\n",
      "batch 2720: loss 0.036531\n",
      "batch 2721: loss 0.066969\n",
      "batch 2722: loss 0.058474\n",
      "batch 2723: loss 0.066856\n",
      "batch 2724: loss 0.076118\n",
      "batch 2725: loss 0.274026\n",
      "batch 2726: loss 0.023936\n",
      "batch 2727: loss 0.041329\n",
      "batch 2728: loss 0.104923\n",
      "batch 2729: loss 0.098946\n",
      "batch 2730: loss 0.020841\n",
      "batch 2731: loss 0.053448\n",
      "batch 2732: loss 0.064061\n",
      "batch 2733: loss 0.022403\n",
      "batch 2734: loss 0.341129\n",
      "batch 2735: loss 0.163234\n",
      "batch 2736: loss 0.076372\n",
      "batch 2737: loss 0.109465\n",
      "batch 2738: loss 0.177335\n",
      "batch 2739: loss 0.024294\n",
      "batch 2740: loss 0.194424\n",
      "batch 2741: loss 0.292605\n",
      "batch 2742: loss 0.111955\n",
      "batch 2743: loss 0.177928\n",
      "batch 2744: loss 0.106766\n",
      "batch 2745: loss 0.106391\n",
      "batch 2746: loss 0.043960\n",
      "batch 2747: loss 0.091791\n",
      "batch 2748: loss 0.143104\n",
      "batch 2749: loss 0.189915\n",
      "batch 2750: loss 0.098308\n",
      "batch 2751: loss 0.045723\n",
      "batch 2752: loss 0.065177\n",
      "batch 2753: loss 0.134522\n",
      "batch 2754: loss 0.175534\n",
      "batch 2755: loss 0.024894\n",
      "batch 2756: loss 0.073522\n",
      "batch 2757: loss 0.131418\n",
      "batch 2758: loss 0.224464\n",
      "batch 2759: loss 0.145867\n",
      "batch 2760: loss 0.122759\n",
      "batch 2761: loss 0.020769\n",
      "batch 2762: loss 0.078692\n",
      "batch 2763: loss 0.267698\n",
      "batch 2764: loss 0.079215\n",
      "batch 2765: loss 0.107453\n",
      "batch 2766: loss 0.074182\n",
      "batch 2767: loss 0.091279\n",
      "batch 2768: loss 0.090690\n",
      "batch 2769: loss 0.123418\n",
      "batch 2770: loss 0.103932\n",
      "batch 2771: loss 0.090530\n",
      "batch 2772: loss 0.146034\n",
      "batch 2773: loss 0.061611\n",
      "batch 2774: loss 0.052242\n",
      "batch 2775: loss 0.080992\n",
      "batch 2776: loss 0.238890\n",
      "batch 2777: loss 0.035439\n",
      "batch 2778: loss 0.036415\n",
      "batch 2779: loss 0.081959\n",
      "batch 2780: loss 0.133086\n",
      "batch 2781: loss 0.082933\n",
      "batch 2782: loss 0.046587\n",
      "batch 2783: loss 0.125275\n",
      "batch 2784: loss 0.089474\n",
      "batch 2785: loss 0.030705\n",
      "batch 2786: loss 0.246764\n",
      "batch 2787: loss 0.046874\n",
      "batch 2788: loss 0.031256\n",
      "batch 2789: loss 0.056739\n",
      "batch 2790: loss 0.022142\n",
      "batch 2791: loss 0.192012\n",
      "batch 2792: loss 0.071923\n",
      "batch 2793: loss 0.152040\n",
      "batch 2794: loss 0.045251\n",
      "batch 2795: loss 0.187381\n",
      "batch 2796: loss 0.097615\n",
      "batch 2797: loss 0.094979\n",
      "batch 2798: loss 0.032181\n",
      "batch 2799: loss 0.054289\n",
      "batch 2800: loss 0.018611\n",
      "batch 2801: loss 0.061984\n",
      "batch 2802: loss 0.091195\n",
      "batch 2803: loss 0.012602\n",
      "batch 2804: loss 0.121853\n",
      "batch 2805: loss 0.181506\n",
      "batch 2806: loss 0.136826\n",
      "batch 2807: loss 0.174530\n",
      "batch 2808: loss 0.017280\n",
      "batch 2809: loss 0.081060\n",
      "batch 2810: loss 0.046004\n",
      "batch 2811: loss 0.128691\n",
      "batch 2812: loss 0.037968\n",
      "batch 2813: loss 0.160184\n",
      "batch 2814: loss 0.111755\n",
      "batch 2815: loss 0.022897\n",
      "batch 2816: loss 0.108423\n",
      "batch 2817: loss 0.062621\n",
      "batch 2818: loss 0.161724\n",
      "batch 2819: loss 0.081586\n",
      "batch 2820: loss 0.123428\n",
      "batch 2821: loss 0.037144\n",
      "batch 2822: loss 0.100576\n",
      "batch 2823: loss 0.069187\n",
      "batch 2824: loss 0.129137\n",
      "batch 2825: loss 0.049307\n",
      "batch 2826: loss 0.053929\n",
      "batch 2827: loss 0.035001\n",
      "batch 2828: loss 0.124548\n",
      "batch 2829: loss 0.043910\n",
      "batch 2830: loss 0.184386\n",
      "batch 2831: loss 0.064614\n",
      "batch 2832: loss 0.103725\n",
      "batch 2833: loss 0.100695\n",
      "batch 2834: loss 0.034555\n",
      "batch 2835: loss 0.129585\n",
      "batch 2836: loss 0.238144\n",
      "batch 2837: loss 0.056949\n",
      "batch 2838: loss 0.185070\n",
      "batch 2839: loss 0.028044\n",
      "batch 2840: loss 0.131128\n",
      "batch 2841: loss 0.040406\n",
      "batch 2842: loss 0.052199\n",
      "batch 2843: loss 0.110832\n",
      "batch 2844: loss 0.047633\n",
      "batch 2845: loss 0.063217\n",
      "batch 2846: loss 0.054693\n",
      "batch 2847: loss 0.064168\n",
      "batch 2848: loss 0.150047\n",
      "batch 2849: loss 0.016319\n",
      "batch 2850: loss 0.032689\n",
      "batch 2851: loss 0.069038\n",
      "batch 2852: loss 0.134209\n",
      "batch 2853: loss 0.013508\n",
      "batch 2854: loss 0.083380\n",
      "batch 2855: loss 0.044874\n",
      "batch 2856: loss 0.134463\n",
      "batch 2857: loss 0.067915\n",
      "batch 2858: loss 0.031534\n",
      "batch 2859: loss 0.053058\n",
      "batch 2860: loss 0.015885\n",
      "batch 2861: loss 0.092005\n",
      "batch 2862: loss 0.058716\n",
      "batch 2863: loss 0.104033\n",
      "batch 2864: loss 0.121726\n",
      "batch 2865: loss 0.108677\n",
      "batch 2866: loss 0.109271\n",
      "batch 2867: loss 0.122815\n",
      "batch 2868: loss 0.146261\n",
      "batch 2869: loss 0.067372\n",
      "batch 2870: loss 0.017769\n",
      "batch 2871: loss 0.081633\n",
      "batch 2872: loss 0.299609\n",
      "batch 2873: loss 0.068908\n",
      "batch 2874: loss 0.209716\n",
      "batch 2875: loss 0.087156\n",
      "batch 2876: loss 0.036575\n",
      "batch 2877: loss 0.015468\n",
      "batch 2878: loss 0.180775\n",
      "batch 2879: loss 0.078384\n",
      "batch 2880: loss 0.056910\n",
      "batch 2881: loss 0.107300\n",
      "batch 2882: loss 0.080482\n",
      "batch 2883: loss 0.065817\n",
      "batch 2884: loss 0.103302\n",
      "batch 2885: loss 0.051814\n",
      "batch 2886: loss 0.101211\n",
      "batch 2887: loss 0.047318\n",
      "batch 2888: loss 0.021693\n",
      "batch 2889: loss 0.184898\n",
      "batch 2890: loss 0.036949\n",
      "batch 2891: loss 0.173357\n",
      "batch 2892: loss 0.091004\n",
      "batch 2893: loss 0.028042\n",
      "batch 2894: loss 0.087880\n",
      "batch 2895: loss 0.027891\n",
      "batch 2896: loss 0.254998\n",
      "batch 2897: loss 0.026980\n",
      "batch 2898: loss 0.027777\n",
      "batch 2899: loss 0.053042\n",
      "batch 2900: loss 0.061716\n",
      "batch 2901: loss 0.049234\n",
      "batch 2902: loss 0.157470\n",
      "batch 2903: loss 0.215869\n",
      "batch 2904: loss 0.133424\n",
      "batch 2905: loss 0.023410\n",
      "batch 2906: loss 0.059240\n",
      "batch 2907: loss 0.071580\n",
      "batch 2908: loss 0.033623\n",
      "batch 2909: loss 0.218200\n",
      "batch 2910: loss 0.026829\n",
      "batch 2911: loss 0.078471\n",
      "batch 2912: loss 0.107278\n",
      "batch 2913: loss 0.037836\n",
      "batch 2914: loss 0.340191\n",
      "batch 2915: loss 0.097138\n",
      "batch 2916: loss 0.012319\n",
      "batch 2917: loss 0.063628\n",
      "batch 2918: loss 0.101877\n",
      "batch 2919: loss 0.074094\n",
      "batch 2920: loss 0.127897\n",
      "batch 2921: loss 0.069510\n",
      "batch 2922: loss 0.188485\n",
      "batch 2923: loss 0.120617\n",
      "batch 2924: loss 0.106092\n",
      "batch 2925: loss 0.174962\n",
      "batch 2926: loss 0.120227\n",
      "batch 2927: loss 0.159952\n",
      "batch 2928: loss 0.075609\n",
      "batch 2929: loss 0.047153\n",
      "batch 2930: loss 0.150059\n",
      "batch 2931: loss 0.169879\n",
      "batch 2932: loss 0.029583\n",
      "batch 2933: loss 0.258684\n",
      "batch 2934: loss 0.017778\n",
      "batch 2935: loss 0.019788\n",
      "batch 2936: loss 0.077789\n",
      "batch 2937: loss 0.161868\n",
      "batch 2938: loss 0.024739\n",
      "batch 2939: loss 0.031782\n",
      "batch 2940: loss 0.054252\n",
      "batch 2941: loss 0.011489\n",
      "batch 2942: loss 0.111088\n",
      "batch 2943: loss 0.148860\n",
      "batch 2944: loss 0.101653\n",
      "batch 2945: loss 0.103314\n",
      "batch 2946: loss 0.168958\n",
      "batch 2947: loss 0.041010\n",
      "batch 2948: loss 0.068510\n",
      "batch 2949: loss 0.038651\n",
      "batch 2950: loss 0.114240\n",
      "batch 2951: loss 0.150408\n",
      "batch 2952: loss 0.086269\n",
      "batch 2953: loss 0.136504\n",
      "batch 2954: loss 0.106773\n",
      "batch 2955: loss 0.097116\n",
      "batch 2956: loss 0.084848\n",
      "batch 2957: loss 0.055506\n",
      "batch 2958: loss 0.072577\n",
      "batch 2959: loss 0.030987\n",
      "batch 2960: loss 0.037800\n",
      "batch 2961: loss 0.111945\n",
      "batch 2962: loss 0.198725\n",
      "batch 2963: loss 0.020032\n",
      "batch 2964: loss 0.019461\n",
      "batch 2965: loss 0.060859\n",
      "batch 2966: loss 0.038241\n",
      "batch 2967: loss 0.140450\n",
      "batch 2968: loss 0.053679\n",
      "batch 2969: loss 0.134889\n",
      "batch 2970: loss 0.120697\n",
      "batch 2971: loss 0.038810\n",
      "batch 2972: loss 0.055247\n",
      "batch 2973: loss 0.089065\n",
      "batch 2974: loss 0.046859\n",
      "batch 2975: loss 0.125740\n",
      "batch 2976: loss 0.062555\n",
      "batch 2977: loss 0.033524\n",
      "batch 2978: loss 0.053130\n",
      "batch 2979: loss 0.024765\n",
      "batch 2980: loss 0.045241\n",
      "batch 2981: loss 0.136136\n",
      "batch 2982: loss 0.169675\n",
      "batch 2983: loss 0.083280\n",
      "batch 2984: loss 0.018886\n",
      "batch 2985: loss 0.075015\n",
      "batch 2986: loss 0.038502\n",
      "batch 2987: loss 0.068675\n",
      "batch 2988: loss 0.063178\n",
      "batch 2989: loss 0.044606\n",
      "batch 2990: loss 0.078895\n",
      "batch 2991: loss 0.200234\n",
      "batch 2992: loss 0.131641\n",
      "batch 2993: loss 0.201125\n",
      "batch 2994: loss 0.031441\n",
      "batch 2995: loss 0.108871\n",
      "batch 2996: loss 0.052953\n",
      "batch 2997: loss 0.107330\n",
      "batch 2998: loss 0.057076\n",
      "batch 2999: loss 0.089425\n",
      "batch 3000: loss 0.078513\n",
      "batch 3001: loss 0.134136\n",
      "batch 3002: loss 0.020385\n",
      "batch 3003: loss 0.120567\n",
      "batch 3004: loss 0.186908\n",
      "batch 3005: loss 0.046634\n",
      "batch 3006: loss 0.025753\n",
      "batch 3007: loss 0.115419\n",
      "batch 3008: loss 0.010638\n",
      "batch 3009: loss 0.042646\n",
      "batch 3010: loss 0.241213\n",
      "batch 3011: loss 0.151561\n",
      "batch 3012: loss 0.061441\n",
      "batch 3013: loss 0.077553\n",
      "batch 3014: loss 0.062277\n",
      "batch 3015: loss 0.125118\n",
      "batch 3016: loss 0.070680\n",
      "batch 3017: loss 0.031546\n",
      "batch 3018: loss 0.103952\n",
      "batch 3019: loss 0.113835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3020: loss 0.077873\n",
      "batch 3021: loss 0.155828\n",
      "batch 3022: loss 0.014657\n",
      "batch 3023: loss 0.107585\n",
      "batch 3024: loss 0.056097\n",
      "batch 3025: loss 0.105639\n",
      "batch 3026: loss 0.139832\n",
      "batch 3027: loss 0.170285\n",
      "batch 3028: loss 0.109127\n",
      "batch 3029: loss 0.158520\n",
      "batch 3030: loss 0.057416\n",
      "batch 3031: loss 0.053786\n",
      "batch 3032: loss 0.112596\n",
      "batch 3033: loss 0.068411\n",
      "batch 3034: loss 0.305801\n",
      "batch 3035: loss 0.044172\n",
      "batch 3036: loss 0.016322\n",
      "batch 3037: loss 0.070881\n",
      "batch 3038: loss 0.157743\n",
      "batch 3039: loss 0.210448\n",
      "batch 3040: loss 0.086598\n",
      "batch 3041: loss 0.106504\n",
      "batch 3042: loss 0.224849\n",
      "batch 3043: loss 0.074590\n",
      "batch 3044: loss 0.141114\n",
      "batch 3045: loss 0.039578\n",
      "batch 3046: loss 0.136249\n",
      "batch 3047: loss 0.040294\n",
      "batch 3048: loss 0.057529\n",
      "batch 3049: loss 0.111494\n",
      "batch 3050: loss 0.020595\n",
      "batch 3051: loss 0.105711\n",
      "batch 3052: loss 0.115008\n",
      "batch 3053: loss 0.046849\n",
      "batch 3054: loss 0.082091\n",
      "batch 3055: loss 0.133074\n",
      "batch 3056: loss 0.203819\n",
      "batch 3057: loss 0.034299\n",
      "batch 3058: loss 0.118302\n",
      "batch 3059: loss 0.109491\n",
      "batch 3060: loss 0.084688\n",
      "batch 3061: loss 0.198506\n",
      "batch 3062: loss 0.088984\n",
      "batch 3063: loss 0.062412\n",
      "batch 3064: loss 0.090883\n",
      "batch 3065: loss 0.141846\n",
      "batch 3066: loss 0.038562\n",
      "batch 3067: loss 0.090249\n",
      "batch 3068: loss 0.017233\n",
      "batch 3069: loss 0.034908\n",
      "batch 3070: loss 0.046257\n",
      "batch 3071: loss 0.035857\n",
      "batch 3072: loss 0.091180\n",
      "batch 3073: loss 0.066505\n",
      "batch 3074: loss 0.074312\n",
      "batch 3075: loss 0.195671\n",
      "batch 3076: loss 0.039848\n",
      "batch 3077: loss 0.140351\n",
      "batch 3078: loss 0.038114\n",
      "batch 3079: loss 0.066758\n",
      "batch 3080: loss 0.336012\n",
      "batch 3081: loss 0.038453\n",
      "batch 3082: loss 0.107769\n",
      "batch 3083: loss 0.054106\n",
      "batch 3084: loss 0.092159\n",
      "batch 3085: loss 0.151836\n",
      "batch 3086: loss 0.061215\n",
      "batch 3087: loss 0.046534\n",
      "batch 3088: loss 0.112336\n",
      "batch 3089: loss 0.214482\n",
      "batch 3090: loss 0.032460\n",
      "batch 3091: loss 0.184843\n",
      "batch 3092: loss 0.129218\n",
      "batch 3093: loss 0.054468\n",
      "batch 3094: loss 0.098641\n",
      "batch 3095: loss 0.201192\n",
      "batch 3096: loss 0.134375\n",
      "batch 3097: loss 0.047413\n",
      "batch 3098: loss 0.033176\n",
      "batch 3099: loss 0.172970\n",
      "batch 3100: loss 0.036349\n",
      "batch 3101: loss 0.251411\n",
      "batch 3102: loss 0.140985\n",
      "batch 3103: loss 0.193606\n",
      "batch 3104: loss 0.185067\n",
      "batch 3105: loss 0.181056\n",
      "batch 3106: loss 0.109877\n",
      "batch 3107: loss 0.149185\n",
      "batch 3108: loss 0.119943\n",
      "batch 3109: loss 0.061379\n",
      "batch 3110: loss 0.086574\n",
      "batch 3111: loss 0.066426\n",
      "batch 3112: loss 0.051755\n",
      "batch 3113: loss 0.111531\n",
      "batch 3114: loss 0.078493\n",
      "batch 3115: loss 0.095917\n",
      "batch 3116: loss 0.075956\n",
      "batch 3117: loss 0.220479\n",
      "batch 3118: loss 0.118631\n",
      "batch 3119: loss 0.061189\n",
      "batch 3120: loss 0.070063\n",
      "batch 3121: loss 0.163006\n",
      "batch 3122: loss 0.096940\n",
      "batch 3123: loss 0.051406\n",
      "batch 3124: loss 0.096986\n",
      "batch 3125: loss 0.030846\n",
      "batch 3126: loss 0.020928\n",
      "batch 3127: loss 0.093021\n",
      "batch 3128: loss 0.033599\n",
      "batch 3129: loss 0.165395\n",
      "batch 3130: loss 0.104448\n",
      "batch 3131: loss 0.062019\n",
      "batch 3132: loss 0.022164\n",
      "batch 3133: loss 0.110962\n",
      "batch 3134: loss 0.250155\n",
      "batch 3135: loss 0.117563\n",
      "batch 3136: loss 0.035686\n",
      "batch 3137: loss 0.027305\n",
      "batch 3138: loss 0.057566\n",
      "batch 3139: loss 0.068631\n",
      "batch 3140: loss 0.129458\n",
      "batch 3141: loss 0.073310\n",
      "batch 3142: loss 0.073246\n",
      "batch 3143: loss 0.032140\n",
      "batch 3144: loss 0.128461\n",
      "batch 3145: loss 0.070568\n",
      "batch 3146: loss 0.052128\n",
      "batch 3147: loss 0.056660\n",
      "batch 3148: loss 0.095885\n",
      "batch 3149: loss 0.095958\n",
      "batch 3150: loss 0.142509\n",
      "batch 3151: loss 0.057683\n",
      "batch 3152: loss 0.094025\n",
      "batch 3153: loss 0.072497\n",
      "batch 3154: loss 0.087021\n",
      "batch 3155: loss 0.091562\n",
      "batch 3156: loss 0.111142\n",
      "batch 3157: loss 0.067388\n",
      "batch 3158: loss 0.109676\n",
      "batch 3159: loss 0.045843\n",
      "batch 3160: loss 0.044448\n",
      "batch 3161: loss 0.070810\n",
      "batch 3162: loss 0.060606\n",
      "batch 3163: loss 0.027802\n",
      "batch 3164: loss 0.012056\n",
      "batch 3165: loss 0.037268\n",
      "batch 3166: loss 0.143932\n",
      "batch 3167: loss 0.050913\n",
      "batch 3168: loss 0.096744\n",
      "batch 3169: loss 0.110159\n",
      "batch 3170: loss 0.042718\n",
      "batch 3171: loss 0.076799\n",
      "batch 3172: loss 0.102375\n",
      "batch 3173: loss 0.045624\n",
      "batch 3174: loss 0.102321\n",
      "batch 3175: loss 0.075276\n",
      "batch 3176: loss 0.028277\n",
      "batch 3177: loss 0.023488\n",
      "batch 3178: loss 0.071431\n",
      "batch 3179: loss 0.044318\n",
      "batch 3180: loss 0.043182\n",
      "batch 3181: loss 0.122801\n",
      "batch 3182: loss 0.087089\n",
      "batch 3183: loss 0.014390\n",
      "batch 3184: loss 0.012890\n",
      "batch 3185: loss 0.189817\n",
      "batch 3186: loss 0.029752\n",
      "batch 3187: loss 0.095677\n",
      "batch 3188: loss 0.132766\n",
      "batch 3189: loss 0.073218\n",
      "batch 3190: loss 0.121365\n",
      "batch 3191: loss 0.200760\n",
      "batch 3192: loss 0.017158\n",
      "batch 3193: loss 0.251268\n",
      "batch 3194: loss 0.088734\n",
      "batch 3195: loss 0.114321\n",
      "batch 3196: loss 0.029349\n",
      "batch 3197: loss 0.062968\n",
      "batch 3198: loss 0.020562\n",
      "batch 3199: loss 0.031331\n",
      "batch 3200: loss 0.049938\n",
      "batch 3201: loss 0.038390\n",
      "batch 3202: loss 0.123609\n",
      "batch 3203: loss 0.239850\n",
      "batch 3204: loss 0.127092\n",
      "batch 3205: loss 0.019289\n",
      "batch 3206: loss 0.120116\n",
      "batch 3207: loss 0.191402\n",
      "batch 3208: loss 0.082906\n",
      "batch 3209: loss 0.050889\n",
      "batch 3210: loss 0.072148\n",
      "batch 3211: loss 0.148798\n",
      "batch 3212: loss 0.022480\n",
      "batch 3213: loss 0.074028\n",
      "batch 3214: loss 0.034881\n",
      "batch 3215: loss 0.058871\n",
      "batch 3216: loss 0.086006\n",
      "batch 3217: loss 0.074512\n",
      "batch 3218: loss 0.065433\n",
      "batch 3219: loss 0.052252\n",
      "batch 3220: loss 0.014311\n",
      "batch 3221: loss 0.059817\n",
      "batch 3222: loss 0.032907\n",
      "batch 3223: loss 0.083503\n",
      "batch 3224: loss 0.024967\n",
      "batch 3225: loss 0.196193\n",
      "batch 3226: loss 0.121307\n",
      "batch 3227: loss 0.038290\n",
      "batch 3228: loss 0.123285\n",
      "batch 3229: loss 0.024248\n",
      "batch 3230: loss 0.100401\n",
      "batch 3231: loss 0.188344\n",
      "batch 3232: loss 0.033586\n",
      "batch 3233: loss 0.041929\n",
      "batch 3234: loss 0.123622\n",
      "batch 3235: loss 0.047029\n",
      "batch 3236: loss 0.106421\n",
      "batch 3237: loss 0.079309\n",
      "batch 3238: loss 0.082490\n",
      "batch 3239: loss 0.078759\n",
      "batch 3240: loss 0.100246\n",
      "batch 3241: loss 0.042282\n",
      "batch 3242: loss 0.046158\n",
      "batch 3243: loss 0.203351\n",
      "batch 3244: loss 0.122900\n",
      "batch 3245: loss 0.049708\n",
      "batch 3246: loss 0.022145\n",
      "batch 3247: loss 0.029508\n",
      "batch 3248: loss 0.113121\n",
      "batch 3249: loss 0.060703\n",
      "batch 3250: loss 0.045814\n",
      "batch 3251: loss 0.084831\n",
      "batch 3252: loss 0.098631\n",
      "batch 3253: loss 0.023009\n",
      "batch 3254: loss 0.084304\n",
      "batch 3255: loss 0.049918\n",
      "batch 3256: loss 0.038230\n",
      "batch 3257: loss 0.055667\n",
      "batch 3258: loss 0.145007\n",
      "batch 3259: loss 0.058906\n",
      "batch 3260: loss 0.078007\n",
      "batch 3261: loss 0.036521\n",
      "batch 3262: loss 0.074695\n",
      "batch 3263: loss 0.070152\n",
      "batch 3264: loss 0.058008\n",
      "batch 3265: loss 0.154588\n",
      "batch 3266: loss 0.052251\n",
      "batch 3267: loss 0.106542\n",
      "batch 3268: loss 0.135242\n",
      "batch 3269: loss 0.071259\n",
      "batch 3270: loss 0.028834\n",
      "batch 3271: loss 0.050745\n",
      "batch 3272: loss 0.080047\n",
      "batch 3273: loss 0.096133\n",
      "batch 3274: loss 0.081571\n",
      "batch 3275: loss 0.185998\n",
      "batch 3276: loss 0.029181\n",
      "batch 3277: loss 0.029111\n",
      "batch 3278: loss 0.083460\n",
      "batch 3279: loss 0.252858\n",
      "batch 3280: loss 0.108000\n",
      "batch 3281: loss 0.024498\n",
      "batch 3282: loss 0.142007\n",
      "batch 3283: loss 0.137512\n",
      "batch 3284: loss 0.054634\n",
      "batch 3285: loss 0.092508\n",
      "batch 3286: loss 0.045797\n",
      "batch 3287: loss 0.169285\n",
      "batch 3288: loss 0.025027\n",
      "batch 3289: loss 0.056146\n",
      "batch 3290: loss 0.068898\n",
      "batch 3291: loss 0.094954\n",
      "batch 3292: loss 0.011566\n",
      "batch 3293: loss 0.043625\n",
      "batch 3294: loss 0.023745\n",
      "batch 3295: loss 0.076394\n",
      "batch 3296: loss 0.041657\n",
      "batch 3297: loss 0.034661\n",
      "batch 3298: loss 0.081744\n",
      "batch 3299: loss 0.015850\n",
      "batch 3300: loss 0.115773\n",
      "batch 3301: loss 0.122784\n",
      "batch 3302: loss 0.020028\n",
      "batch 3303: loss 0.023854\n",
      "batch 3304: loss 0.048541\n",
      "batch 3305: loss 0.015188\n",
      "batch 3306: loss 0.025430\n",
      "batch 3307: loss 0.059758\n",
      "batch 3308: loss 0.085833\n",
      "batch 3309: loss 0.052647\n",
      "batch 3310: loss 0.074136\n",
      "batch 3311: loss 0.079935\n",
      "batch 3312: loss 0.073964\n",
      "batch 3313: loss 0.046545\n",
      "batch 3314: loss 0.066058\n",
      "batch 3315: loss 0.154973\n",
      "batch 3316: loss 0.020838\n",
      "batch 3317: loss 0.053227\n",
      "batch 3318: loss 0.066824\n",
      "batch 3319: loss 0.022099\n",
      "batch 3320: loss 0.172437\n",
      "batch 3321: loss 0.053927\n",
      "batch 3322: loss 0.012636\n",
      "batch 3323: loss 0.043928\n",
      "batch 3324: loss 0.116310\n",
      "batch 3325: loss 0.033812\n",
      "batch 3326: loss 0.223486\n",
      "batch 3327: loss 0.125705\n",
      "batch 3328: loss 0.081319\n",
      "batch 3329: loss 0.037129\n",
      "batch 3330: loss 0.040035\n",
      "batch 3331: loss 0.058053\n",
      "batch 3332: loss 0.156377\n",
      "batch 3333: loss 0.070528\n",
      "batch 3334: loss 0.164926\n",
      "batch 3335: loss 0.039185\n",
      "batch 3336: loss 0.117883\n",
      "batch 3337: loss 0.126959\n",
      "batch 3338: loss 0.192675\n",
      "batch 3339: loss 0.022583\n",
      "batch 3340: loss 0.155594\n",
      "batch 3341: loss 0.046508\n",
      "batch 3342: loss 0.035013\n",
      "batch 3343: loss 0.062206\n",
      "batch 3344: loss 0.028776\n",
      "batch 3345: loss 0.058111\n",
      "batch 3346: loss 0.015192\n",
      "batch 3347: loss 0.060894\n",
      "batch 3348: loss 0.029259\n",
      "batch 3349: loss 0.041722\n",
      "batch 3350: loss 0.110309\n",
      "batch 3351: loss 0.120638\n",
      "batch 3352: loss 0.172976\n",
      "batch 3353: loss 0.014858\n",
      "batch 3354: loss 0.139166\n",
      "batch 3355: loss 0.053171\n",
      "batch 3356: loss 0.239578\n",
      "batch 3357: loss 0.022835\n",
      "batch 3358: loss 0.044711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3359: loss 0.105540\n",
      "batch 3360: loss 0.017435\n",
      "batch 3361: loss 0.140355\n",
      "batch 3362: loss 0.131217\n",
      "batch 3363: loss 0.023856\n",
      "batch 3364: loss 0.042953\n",
      "batch 3365: loss 0.255985\n",
      "batch 3366: loss 0.022413\n",
      "batch 3367: loss 0.081400\n",
      "batch 3368: loss 0.172822\n",
      "batch 3369: loss 0.200968\n",
      "batch 3370: loss 0.047161\n",
      "batch 3371: loss 0.143140\n",
      "batch 3372: loss 0.052726\n",
      "batch 3373: loss 0.061457\n",
      "batch 3374: loss 0.052740\n",
      "batch 3375: loss 0.091821\n",
      "batch 3376: loss 0.030775\n",
      "batch 3377: loss 0.058270\n",
      "batch 3378: loss 0.098163\n",
      "batch 3379: loss 0.143585\n",
      "batch 3380: loss 0.116482\n",
      "batch 3381: loss 0.114432\n",
      "batch 3382: loss 0.053491\n",
      "batch 3383: loss 0.185666\n",
      "batch 3384: loss 0.091311\n",
      "batch 3385: loss 0.127679\n",
      "batch 3386: loss 0.022625\n",
      "batch 3387: loss 0.426715\n",
      "batch 3388: loss 0.076241\n",
      "batch 3389: loss 0.018241\n",
      "batch 3390: loss 0.124654\n",
      "batch 3391: loss 0.115805\n",
      "batch 3392: loss 0.133751\n",
      "batch 3393: loss 0.089501\n",
      "batch 3394: loss 0.059743\n",
      "batch 3395: loss 0.070447\n",
      "batch 3396: loss 0.070344\n",
      "batch 3397: loss 0.035350\n",
      "batch 3398: loss 0.060072\n",
      "batch 3399: loss 0.081218\n",
      "batch 3400: loss 0.258124\n",
      "batch 3401: loss 0.151707\n",
      "batch 3402: loss 0.024772\n",
      "batch 3403: loss 0.053870\n",
      "batch 3404: loss 0.018602\n",
      "batch 3405: loss 0.036480\n",
      "batch 3406: loss 0.083064\n",
      "batch 3407: loss 0.169763\n",
      "batch 3408: loss 0.073964\n",
      "batch 3409: loss 0.037402\n",
      "batch 3410: loss 0.061452\n",
      "batch 3411: loss 0.035962\n",
      "batch 3412: loss 0.029923\n",
      "batch 3413: loss 0.134544\n",
      "batch 3414: loss 0.017509\n",
      "batch 3415: loss 0.043042\n",
      "batch 3416: loss 0.091913\n",
      "batch 3417: loss 0.049604\n",
      "batch 3418: loss 0.045337\n",
      "batch 3419: loss 0.219881\n",
      "batch 3420: loss 0.033352\n",
      "batch 3421: loss 0.079009\n",
      "batch 3422: loss 0.149121\n",
      "batch 3423: loss 0.018641\n",
      "batch 3424: loss 0.047435\n",
      "batch 3425: loss 0.155560\n",
      "batch 3426: loss 0.036943\n",
      "batch 3427: loss 0.044237\n",
      "batch 3428: loss 0.073868\n",
      "batch 3429: loss 0.051997\n",
      "batch 3430: loss 0.126040\n",
      "batch 3431: loss 0.049967\n",
      "batch 3432: loss 0.030571\n",
      "batch 3433: loss 0.050100\n",
      "batch 3434: loss 0.042535\n",
      "batch 3435: loss 0.029307\n",
      "batch 3436: loss 0.030990\n",
      "batch 3437: loss 0.055512\n",
      "batch 3438: loss 0.078136\n",
      "batch 3439: loss 0.024987\n",
      "batch 3440: loss 0.251700\n",
      "batch 3441: loss 0.123167\n",
      "batch 3442: loss 0.121824\n",
      "batch 3443: loss 0.074873\n",
      "batch 3444: loss 0.031488\n",
      "batch 3445: loss 0.065440\n",
      "batch 3446: loss 0.008806\n",
      "batch 3447: loss 0.106169\n",
      "batch 3448: loss 0.061984\n",
      "batch 3449: loss 0.021864\n",
      "batch 3450: loss 0.035583\n",
      "batch 3451: loss 0.059396\n",
      "batch 3452: loss 0.037713\n",
      "batch 3453: loss 0.036968\n",
      "batch 3454: loss 0.072350\n",
      "batch 3455: loss 0.049748\n",
      "batch 3456: loss 0.041158\n",
      "batch 3457: loss 0.010696\n",
      "batch 3458: loss 0.044219\n",
      "batch 3459: loss 0.037450\n",
      "batch 3460: loss 0.019946\n",
      "batch 3461: loss 0.020204\n",
      "batch 3462: loss 0.048616\n",
      "batch 3463: loss 0.070083\n",
      "batch 3464: loss 0.021086\n",
      "batch 3465: loss 0.111711\n",
      "batch 3466: loss 0.048473\n",
      "batch 3467: loss 0.023303\n",
      "batch 3468: loss 0.082356\n",
      "batch 3469: loss 0.029578\n",
      "batch 3470: loss 0.122931\n",
      "batch 3471: loss 0.039821\n",
      "batch 3472: loss 0.151008\n",
      "batch 3473: loss 0.079991\n",
      "batch 3474: loss 0.041627\n",
      "batch 3475: loss 0.060185\n",
      "batch 3476: loss 0.022766\n",
      "batch 3477: loss 0.084315\n",
      "batch 3478: loss 0.091749\n",
      "batch 3479: loss 0.064557\n",
      "batch 3480: loss 0.143261\n",
      "batch 3481: loss 0.047208\n",
      "batch 3482: loss 0.132638\n",
      "batch 3483: loss 0.103608\n",
      "batch 3484: loss 0.082417\n",
      "batch 3485: loss 0.229790\n",
      "batch 3486: loss 0.109479\n",
      "batch 3487: loss 0.063737\n",
      "batch 3488: loss 0.020922\n",
      "batch 3489: loss 0.018731\n",
      "batch 3490: loss 0.045249\n",
      "batch 3491: loss 0.050444\n",
      "batch 3492: loss 0.042168\n",
      "batch 3493: loss 0.065626\n",
      "batch 3494: loss 0.082776\n",
      "batch 3495: loss 0.081891\n",
      "batch 3496: loss 0.043776\n",
      "batch 3497: loss 0.040362\n",
      "batch 3498: loss 0.035196\n",
      "batch 3499: loss 0.051908\n",
      "batch 3500: loss 0.182821\n",
      "batch 3501: loss 0.024943\n",
      "batch 3502: loss 0.044085\n",
      "batch 3503: loss 0.162032\n",
      "batch 3504: loss 0.079557\n",
      "batch 3505: loss 0.029818\n",
      "batch 3506: loss 0.263993\n",
      "batch 3507: loss 0.051232\n",
      "batch 3508: loss 0.057446\n",
      "batch 3509: loss 0.026157\n",
      "batch 3510: loss 0.071864\n",
      "batch 3511: loss 0.024286\n",
      "batch 3512: loss 0.069056\n",
      "batch 3513: loss 0.072050\n",
      "batch 3514: loss 0.087164\n",
      "batch 3515: loss 0.034045\n",
      "batch 3516: loss 0.226468\n",
      "batch 3517: loss 0.145152\n",
      "batch 3518: loss 0.135229\n",
      "batch 3519: loss 0.050334\n",
      "batch 3520: loss 0.091848\n",
      "batch 3521: loss 0.038733\n",
      "batch 3522: loss 0.115263\n",
      "batch 3523: loss 0.020157\n",
      "batch 3524: loss 0.240086\n",
      "batch 3525: loss 0.039803\n",
      "batch 3526: loss 0.115819\n",
      "batch 3527: loss 0.042507\n",
      "batch 3528: loss 0.033776\n",
      "batch 3529: loss 0.121623\n",
      "batch 3530: loss 0.122375\n",
      "batch 3531: loss 0.222241\n",
      "batch 3532: loss 0.090066\n",
      "batch 3533: loss 0.062714\n",
      "batch 3534: loss 0.157018\n",
      "batch 3535: loss 0.148194\n",
      "batch 3536: loss 0.011837\n",
      "batch 3537: loss 0.229475\n",
      "batch 3538: loss 0.052130\n",
      "batch 3539: loss 0.106888\n",
      "batch 3540: loss 0.088228\n",
      "batch 3541: loss 0.020638\n",
      "batch 3542: loss 0.176546\n",
      "batch 3543: loss 0.168726\n",
      "batch 3544: loss 0.018118\n",
      "batch 3545: loss 0.069340\n",
      "batch 3546: loss 0.211900\n",
      "batch 3547: loss 0.202351\n",
      "batch 3548: loss 0.098993\n",
      "batch 3549: loss 0.076103\n",
      "batch 3550: loss 0.084861\n",
      "batch 3551: loss 0.113789\n",
      "batch 3552: loss 0.215401\n",
      "batch 3553: loss 0.055211\n",
      "batch 3554: loss 0.039557\n",
      "batch 3555: loss 0.145897\n",
      "batch 3556: loss 0.085616\n",
      "batch 3557: loss 0.032808\n",
      "batch 3558: loss 0.078247\n",
      "batch 3559: loss 0.361139\n",
      "batch 3560: loss 0.081571\n",
      "batch 3561: loss 0.035237\n",
      "batch 3562: loss 0.076133\n",
      "batch 3563: loss 0.057109\n",
      "batch 3564: loss 0.194369\n",
      "batch 3565: loss 0.055961\n",
      "batch 3566: loss 0.176949\n",
      "batch 3567: loss 0.046740\n",
      "batch 3568: loss 0.080311\n",
      "batch 3569: loss 0.041595\n",
      "batch 3570: loss 0.175485\n",
      "batch 3571: loss 0.056999\n",
      "batch 3572: loss 0.069864\n",
      "batch 3573: loss 0.023831\n",
      "batch 3574: loss 0.104739\n",
      "batch 3575: loss 0.027022\n",
      "batch 3576: loss 0.059670\n",
      "batch 3577: loss 0.041078\n",
      "batch 3578: loss 0.066955\n",
      "batch 3579: loss 0.104450\n",
      "batch 3580: loss 0.042786\n",
      "batch 3581: loss 0.022342\n",
      "batch 3582: loss 0.046311\n",
      "batch 3583: loss 0.109891\n",
      "batch 3584: loss 0.049287\n",
      "batch 3585: loss 0.068063\n",
      "batch 3586: loss 0.119979\n",
      "batch 3587: loss 0.033763\n",
      "batch 3588: loss 0.055794\n",
      "batch 3589: loss 0.015425\n",
      "batch 3590: loss 0.133344\n",
      "batch 3591: loss 0.028338\n",
      "batch 3592: loss 0.058301\n",
      "batch 3593: loss 0.143971\n",
      "batch 3594: loss 0.066154\n",
      "batch 3595: loss 0.032729\n",
      "batch 3596: loss 0.071961\n",
      "batch 3597: loss 0.045398\n",
      "batch 3598: loss 0.041457\n",
      "batch 3599: loss 0.024366\n",
      "batch 3600: loss 0.057437\n",
      "batch 3601: loss 0.246279\n",
      "batch 3602: loss 0.080940\n",
      "batch 3603: loss 0.102454\n",
      "batch 3604: loss 0.110892\n",
      "batch 3605: loss 0.040087\n",
      "batch 3606: loss 0.106807\n",
      "batch 3607: loss 0.015776\n",
      "batch 3608: loss 0.067633\n",
      "batch 3609: loss 0.077581\n",
      "batch 3610: loss 0.036625\n",
      "batch 3611: loss 0.019455\n",
      "batch 3612: loss 0.125408\n",
      "batch 3613: loss 0.060032\n",
      "batch 3614: loss 0.093991\n",
      "batch 3615: loss 0.049019\n",
      "batch 3616: loss 0.065395\n",
      "batch 3617: loss 0.044767\n",
      "batch 3618: loss 0.172778\n",
      "batch 3619: loss 0.183563\n",
      "batch 3620: loss 0.187764\n",
      "batch 3621: loss 0.045754\n",
      "batch 3622: loss 0.052711\n",
      "batch 3623: loss 0.081080\n",
      "batch 3624: loss 0.032445\n",
      "batch 3625: loss 0.076141\n",
      "batch 3626: loss 0.144774\n",
      "batch 3627: loss 0.035042\n",
      "batch 3628: loss 0.045751\n",
      "batch 3629: loss 0.026358\n",
      "batch 3630: loss 0.015078\n",
      "batch 3631: loss 0.010646\n",
      "batch 3632: loss 0.091206\n",
      "batch 3633: loss 0.070575\n",
      "batch 3634: loss 0.041349\n",
      "batch 3635: loss 0.094272\n",
      "batch 3636: loss 0.082169\n",
      "batch 3637: loss 0.157542\n",
      "batch 3638: loss 0.036816\n",
      "batch 3639: loss 0.199852\n",
      "batch 3640: loss 0.061851\n",
      "batch 3641: loss 0.101440\n",
      "batch 3642: loss 0.069988\n",
      "batch 3643: loss 0.058305\n",
      "batch 3644: loss 0.028115\n",
      "batch 3645: loss 0.044951\n",
      "batch 3646: loss 0.080539\n",
      "batch 3647: loss 0.073444\n",
      "batch 3648: loss 0.028558\n",
      "batch 3649: loss 0.190725\n",
      "batch 3650: loss 0.092767\n",
      "batch 3651: loss 0.025195\n",
      "batch 3652: loss 0.085466\n",
      "batch 3653: loss 0.023324\n",
      "batch 3654: loss 0.115079\n",
      "batch 3655: loss 0.049887\n",
      "batch 3656: loss 0.121103\n",
      "batch 3657: loss 0.143816\n",
      "batch 3658: loss 0.069438\n",
      "batch 3659: loss 0.098298\n",
      "batch 3660: loss 0.242516\n",
      "batch 3661: loss 0.044087\n",
      "batch 3662: loss 0.018498\n",
      "batch 3663: loss 0.036695\n",
      "batch 3664: loss 0.073038\n",
      "batch 3665: loss 0.044278\n",
      "batch 3666: loss 0.046230\n",
      "batch 3667: loss 0.022081\n",
      "batch 3668: loss 0.061374\n",
      "batch 3669: loss 0.022344\n",
      "batch 3670: loss 0.152192\n",
      "batch 3671: loss 0.039896\n",
      "batch 3672: loss 0.085865\n",
      "batch 3673: loss 0.026016\n",
      "batch 3674: loss 0.037224\n",
      "batch 3675: loss 0.023370\n",
      "batch 3676: loss 0.111110\n",
      "batch 3677: loss 0.152643\n",
      "batch 3678: loss 0.033840\n",
      "batch 3679: loss 0.089983\n",
      "batch 3680: loss 0.202956\n",
      "batch 3681: loss 0.149250\n",
      "batch 3682: loss 0.056797\n",
      "batch 3683: loss 0.021380\n",
      "batch 3684: loss 0.142896\n",
      "batch 3685: loss 0.014744\n",
      "batch 3686: loss 0.046134\n",
      "batch 3687: loss 0.071646\n",
      "batch 3688: loss 0.057326\n",
      "batch 3689: loss 0.064323\n",
      "batch 3690: loss 0.183833\n",
      "batch 3691: loss 0.049340\n",
      "batch 3692: loss 0.031479\n",
      "batch 3693: loss 0.020232\n",
      "batch 3694: loss 0.157777\n",
      "batch 3695: loss 0.164673\n",
      "batch 3696: loss 0.142982\n",
      "batch 3697: loss 0.038415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3698: loss 0.074212\n",
      "batch 3699: loss 0.021574\n",
      "batch 3700: loss 0.076546\n",
      "batch 3701: loss 0.085733\n",
      "batch 3702: loss 0.016000\n",
      "batch 3703: loss 0.160426\n",
      "batch 3704: loss 0.108519\n",
      "batch 3705: loss 0.275406\n",
      "batch 3706: loss 0.084754\n",
      "batch 3707: loss 0.196894\n",
      "batch 3708: loss 0.089914\n",
      "batch 3709: loss 0.143554\n",
      "batch 3710: loss 0.065484\n",
      "batch 3711: loss 0.036847\n",
      "batch 3712: loss 0.131308\n",
      "batch 3713: loss 0.005070\n",
      "batch 3714: loss 0.043243\n",
      "batch 3715: loss 0.080142\n",
      "batch 3716: loss 0.184699\n",
      "batch 3717: loss 0.085642\n",
      "batch 3718: loss 0.191736\n",
      "batch 3719: loss 0.019275\n",
      "batch 3720: loss 0.031902\n",
      "batch 3721: loss 0.105319\n",
      "batch 3722: loss 0.101683\n",
      "batch 3723: loss 0.140294\n",
      "batch 3724: loss 0.025922\n",
      "batch 3725: loss 0.120470\n",
      "batch 3726: loss 0.165678\n",
      "batch 3727: loss 0.015648\n",
      "batch 3728: loss 0.128222\n",
      "batch 3729: loss 0.063549\n",
      "batch 3730: loss 0.162487\n",
      "batch 3731: loss 0.020553\n",
      "batch 3732: loss 0.135446\n",
      "batch 3733: loss 0.095988\n",
      "batch 3734: loss 0.008094\n",
      "batch 3735: loss 0.077960\n",
      "batch 3736: loss 0.056271\n",
      "batch 3737: loss 0.117283\n",
      "batch 3738: loss 0.088492\n",
      "batch 3739: loss 0.208422\n",
      "batch 3740: loss 0.066701\n",
      "batch 3741: loss 0.129656\n",
      "batch 3742: loss 0.172356\n",
      "batch 3743: loss 0.029075\n",
      "batch 3744: loss 0.074864\n",
      "batch 3745: loss 0.103714\n",
      "batch 3746: loss 0.042889\n",
      "batch 3747: loss 0.155824\n",
      "batch 3748: loss 0.017577\n",
      "batch 3749: loss 0.155253\n",
      "batch 3750: loss 0.047763\n",
      "batch 3751: loss 0.120747\n",
      "batch 3752: loss 0.029010\n",
      "batch 3753: loss 0.065174\n",
      "batch 3754: loss 0.093409\n",
      "batch 3755: loss 0.044366\n",
      "batch 3756: loss 0.103251\n",
      "batch 3757: loss 0.056375\n",
      "batch 3758: loss 0.039899\n",
      "batch 3759: loss 0.096570\n",
      "batch 3760: loss 0.027007\n",
      "batch 3761: loss 0.087561\n",
      "batch 3762: loss 0.058143\n",
      "batch 3763: loss 0.056210\n",
      "batch 3764: loss 0.082440\n",
      "batch 3765: loss 0.052883\n",
      "batch 3766: loss 0.055530\n",
      "batch 3767: loss 0.015519\n",
      "batch 3768: loss 0.030371\n",
      "batch 3769: loss 0.054930\n",
      "batch 3770: loss 0.034345\n",
      "batch 3771: loss 0.016908\n",
      "batch 3772: loss 0.143832\n",
      "batch 3773: loss 0.115431\n",
      "batch 3774: loss 0.016987\n",
      "batch 3775: loss 0.141667\n",
      "batch 3776: loss 0.243323\n",
      "batch 3777: loss 0.059097\n",
      "batch 3778: loss 0.010147\n",
      "batch 3779: loss 0.078774\n",
      "batch 3780: loss 0.026310\n",
      "batch 3781: loss 0.148811\n",
      "batch 3782: loss 0.115352\n",
      "batch 3783: loss 0.095824\n",
      "batch 3784: loss 0.080525\n",
      "batch 3785: loss 0.059889\n",
      "batch 3786: loss 0.095967\n",
      "batch 3787: loss 0.057332\n",
      "batch 3788: loss 0.063498\n",
      "batch 3789: loss 0.247479\n",
      "batch 3790: loss 0.120959\n",
      "batch 3791: loss 0.048402\n",
      "batch 3792: loss 0.022548\n",
      "batch 3793: loss 0.111491\n",
      "batch 3794: loss 0.119135\n",
      "batch 3795: loss 0.071866\n",
      "batch 3796: loss 0.225417\n",
      "batch 3797: loss 0.077270\n",
      "batch 3798: loss 0.044276\n",
      "batch 3799: loss 0.126517\n",
      "batch 3800: loss 0.047265\n",
      "batch 3801: loss 0.110147\n",
      "batch 3802: loss 0.115197\n",
      "batch 3803: loss 0.100424\n",
      "batch 3804: loss 0.093750\n",
      "batch 3805: loss 0.124421\n",
      "batch 3806: loss 0.071277\n",
      "batch 3807: loss 0.034111\n",
      "batch 3808: loss 0.108952\n",
      "batch 3809: loss 0.155365\n",
      "batch 3810: loss 0.091483\n",
      "batch 3811: loss 0.135117\n",
      "batch 3812: loss 0.039271\n",
      "batch 3813: loss 0.022509\n",
      "batch 3814: loss 0.036840\n",
      "batch 3815: loss 0.025865\n",
      "batch 3816: loss 0.249117\n",
      "batch 3817: loss 0.108418\n",
      "batch 3818: loss 0.031992\n",
      "batch 3819: loss 0.102759\n",
      "batch 3820: loss 0.084912\n",
      "batch 3821: loss 0.076421\n",
      "batch 3822: loss 0.064727\n",
      "batch 3823: loss 0.230431\n",
      "batch 3824: loss 0.073414\n",
      "batch 3825: loss 0.183643\n",
      "batch 3826: loss 0.016023\n",
      "batch 3827: loss 0.038110\n",
      "batch 3828: loss 0.098917\n",
      "batch 3829: loss 0.092737\n",
      "batch 3830: loss 0.048628\n",
      "batch 3831: loss 0.049602\n",
      "batch 3832: loss 0.159073\n",
      "batch 3833: loss 0.169418\n",
      "batch 3834: loss 0.023300\n",
      "batch 3835: loss 0.016140\n",
      "batch 3836: loss 0.085339\n",
      "batch 3837: loss 0.020616\n",
      "batch 3838: loss 0.186784\n",
      "batch 3839: loss 0.048941\n",
      "batch 3840: loss 0.038080\n",
      "batch 3841: loss 0.025198\n",
      "batch 3842: loss 0.186448\n",
      "batch 3843: loss 0.098057\n",
      "batch 3844: loss 0.120590\n",
      "batch 3845: loss 0.062139\n",
      "batch 3846: loss 0.033204\n",
      "batch 3847: loss 0.036060\n",
      "batch 3848: loss 0.020077\n",
      "batch 3849: loss 0.019818\n",
      "batch 3850: loss 0.082091\n",
      "batch 3851: loss 0.098931\n",
      "batch 3852: loss 0.035930\n",
      "batch 3853: loss 0.029418\n",
      "batch 3854: loss 0.151929\n",
      "batch 3855: loss 0.011632\n",
      "batch 3856: loss 0.039196\n",
      "batch 3857: loss 0.093559\n",
      "batch 3858: loss 0.132030\n",
      "batch 3859: loss 0.217343\n",
      "batch 3860: loss 0.095134\n",
      "batch 3861: loss 0.085706\n",
      "batch 3862: loss 0.042050\n",
      "batch 3863: loss 0.028681\n",
      "batch 3864: loss 0.069376\n",
      "batch 3865: loss 0.169687\n",
      "batch 3866: loss 0.051991\n",
      "batch 3867: loss 0.019947\n",
      "batch 3868: loss 0.095396\n",
      "batch 3869: loss 0.046155\n",
      "batch 3870: loss 0.062409\n",
      "batch 3871: loss 0.209101\n",
      "batch 3872: loss 0.049190\n",
      "batch 3873: loss 0.073837\n",
      "batch 3874: loss 0.106382\n",
      "batch 3875: loss 0.040807\n",
      "batch 3876: loss 0.104173\n",
      "batch 3877: loss 0.029711\n",
      "batch 3878: loss 0.041722\n",
      "batch 3879: loss 0.031243\n",
      "batch 3880: loss 0.033938\n",
      "batch 3881: loss 0.099826\n",
      "batch 3882: loss 0.150907\n",
      "batch 3883: loss 0.048657\n",
      "batch 3884: loss 0.020091\n",
      "batch 3885: loss 0.304085\n",
      "batch 3886: loss 0.110372\n",
      "batch 3887: loss 0.066395\n",
      "batch 3888: loss 0.096427\n",
      "batch 3889: loss 0.034853\n",
      "batch 3890: loss 0.091264\n",
      "batch 3891: loss 0.159372\n",
      "batch 3892: loss 0.059654\n",
      "batch 3893: loss 0.211926\n",
      "batch 3894: loss 0.035626\n",
      "batch 3895: loss 0.117935\n",
      "batch 3896: loss 0.077826\n",
      "batch 3897: loss 0.193593\n",
      "batch 3898: loss 0.130318\n",
      "batch 3899: loss 0.201223\n",
      "batch 3900: loss 0.083146\n",
      "batch 3901: loss 0.185411\n",
      "batch 3902: loss 0.272478\n",
      "batch 3903: loss 0.050929\n",
      "batch 3904: loss 0.112210\n",
      "batch 3905: loss 0.037794\n",
      "batch 3906: loss 0.055085\n",
      "batch 3907: loss 0.074719\n",
      "batch 3908: loss 0.071670\n",
      "batch 3909: loss 0.361404\n",
      "batch 3910: loss 0.030745\n",
      "batch 3911: loss 0.104050\n",
      "batch 3912: loss 0.160961\n",
      "batch 3913: loss 0.143975\n",
      "batch 3914: loss 0.130937\n",
      "batch 3915: loss 0.097265\n",
      "batch 3916: loss 0.065267\n",
      "batch 3917: loss 0.086631\n",
      "batch 3918: loss 0.124672\n",
      "batch 3919: loss 0.030296\n",
      "batch 3920: loss 0.161301\n",
      "batch 3921: loss 0.109106\n",
      "batch 3922: loss 0.052858\n",
      "batch 3923: loss 0.168302\n",
      "batch 3924: loss 0.016738\n",
      "batch 3925: loss 0.042565\n",
      "batch 3926: loss 0.087661\n",
      "batch 3927: loss 0.051779\n",
      "batch 3928: loss 0.024688\n",
      "batch 3929: loss 0.031071\n",
      "batch 3930: loss 0.035878\n",
      "batch 3931: loss 0.100929\n",
      "batch 3932: loss 0.062676\n",
      "batch 3933: loss 0.104763\n",
      "batch 3934: loss 0.023221\n",
      "batch 3935: loss 0.054712\n",
      "batch 3936: loss 0.024385\n",
      "batch 3937: loss 0.132090\n",
      "batch 3938: loss 0.029692\n",
      "batch 3939: loss 0.094501\n",
      "batch 3940: loss 0.030697\n",
      "batch 3941: loss 0.022106\n",
      "batch 3942: loss 0.240440\n",
      "batch 3943: loss 0.013672\n",
      "batch 3944: loss 0.014916\n",
      "batch 3945: loss 0.067928\n",
      "batch 3946: loss 0.103103\n",
      "batch 3947: loss 0.038128\n",
      "batch 3948: loss 0.040854\n",
      "batch 3949: loss 0.044508\n",
      "batch 3950: loss 0.100137\n",
      "batch 3951: loss 0.099080\n",
      "batch 3952: loss 0.108025\n",
      "batch 3953: loss 0.079085\n",
      "batch 3954: loss 0.049930\n",
      "batch 3955: loss 0.054516\n",
      "batch 3956: loss 0.149655\n",
      "batch 3957: loss 0.115696\n",
      "batch 3958: loss 0.133938\n",
      "batch 3959: loss 0.016647\n",
      "batch 3960: loss 0.050572\n",
      "batch 3961: loss 0.023232\n",
      "batch 3962: loss 0.020767\n",
      "batch 3963: loss 0.062797\n",
      "batch 3964: loss 0.122110\n",
      "batch 3965: loss 0.018898\n",
      "batch 3966: loss 0.085729\n",
      "batch 3967: loss 0.011618\n",
      "batch 3968: loss 0.079852\n",
      "batch 3969: loss 0.062139\n",
      "batch 3970: loss 0.051565\n",
      "batch 3971: loss 0.034766\n",
      "batch 3972: loss 0.086354\n",
      "batch 3973: loss 0.073527\n",
      "batch 3974: loss 0.123830\n",
      "batch 3975: loss 0.039630\n",
      "batch 3976: loss 0.151343\n",
      "batch 3977: loss 0.086996\n",
      "batch 3978: loss 0.014444\n",
      "batch 3979: loss 0.131533\n",
      "batch 3980: loss 0.069812\n",
      "batch 3981: loss 0.027248\n",
      "batch 3982: loss 0.098380\n",
      "batch 3983: loss 0.045224\n",
      "batch 3984: loss 0.033461\n",
      "batch 3985: loss 0.174713\n",
      "batch 3986: loss 0.074578\n",
      "batch 3987: loss 0.045522\n",
      "batch 3988: loss 0.031487\n",
      "batch 3989: loss 0.160691\n",
      "batch 3990: loss 0.109078\n",
      "batch 3991: loss 0.019542\n",
      "batch 3992: loss 0.074310\n",
      "batch 3993: loss 0.031094\n",
      "batch 3994: loss 0.063248\n",
      "batch 3995: loss 0.016936\n",
      "batch 3996: loss 0.047572\n",
      "batch 3997: loss 0.070703\n",
      "batch 3998: loss 0.096925\n",
      "batch 3999: loss 0.031249\n",
      "batch 4000: loss 0.047752\n",
      "batch 4001: loss 0.027615\n",
      "batch 4002: loss 0.039630\n",
      "batch 4003: loss 0.050663\n",
      "batch 4004: loss 0.078373\n",
      "batch 4005: loss 0.062650\n",
      "batch 4006: loss 0.023222\n",
      "batch 4007: loss 0.026366\n",
      "batch 4008: loss 0.022237\n",
      "batch 4009: loss 0.040552\n",
      "batch 4010: loss 0.048296\n",
      "batch 4011: loss 0.030820\n",
      "batch 4012: loss 0.034872\n",
      "batch 4013: loss 0.121590\n",
      "batch 4014: loss 0.094753\n",
      "batch 4015: loss 0.121604\n",
      "batch 4016: loss 0.103520\n",
      "batch 4017: loss 0.029560\n",
      "batch 4018: loss 0.054424\n",
      "batch 4019: loss 0.130197\n",
      "batch 4020: loss 0.063126\n",
      "batch 4021: loss 0.063358\n",
      "batch 4022: loss 0.103037\n",
      "batch 4023: loss 0.033204\n",
      "batch 4024: loss 0.016735\n",
      "batch 4025: loss 0.039010\n",
      "batch 4026: loss 0.058719\n",
      "batch 4027: loss 0.047961\n",
      "batch 4028: loss 0.075600\n",
      "batch 4029: loss 0.025498\n",
      "batch 4030: loss 0.028381\n",
      "batch 4031: loss 0.057411\n",
      "batch 4032: loss 0.100973\n",
      "batch 4033: loss 0.065812\n",
      "batch 4034: loss 0.018322\n",
      "batch 4035: loss 0.100406\n",
      "batch 4036: loss 0.060686\n",
      "batch 4037: loss 0.086391\n",
      "batch 4038: loss 0.010899\n",
      "batch 4039: loss 0.110620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4040: loss 0.072249\n",
      "batch 4041: loss 0.091931\n",
      "batch 4042: loss 0.028185\n",
      "batch 4043: loss 0.116460\n",
      "batch 4044: loss 0.027178\n",
      "batch 4045: loss 0.149237\n",
      "batch 4046: loss 0.024256\n",
      "batch 4047: loss 0.114092\n",
      "batch 4048: loss 0.077570\n",
      "batch 4049: loss 0.050464\n",
      "batch 4050: loss 0.071449\n",
      "batch 4051: loss 0.046450\n",
      "batch 4052: loss 0.034529\n",
      "batch 4053: loss 0.090841\n",
      "batch 4054: loss 0.072922\n",
      "batch 4055: loss 0.112073\n",
      "batch 4056: loss 0.059751\n",
      "batch 4057: loss 0.126895\n",
      "batch 4058: loss 0.060096\n",
      "batch 4059: loss 0.031818\n",
      "batch 4060: loss 0.052398\n",
      "batch 4061: loss 0.036490\n",
      "batch 4062: loss 0.012176\n",
      "batch 4063: loss 0.098178\n",
      "batch 4064: loss 0.035308\n",
      "batch 4065: loss 0.179858\n",
      "batch 4066: loss 0.056316\n",
      "batch 4067: loss 0.039370\n",
      "batch 4068: loss 0.174071\n",
      "batch 4069: loss 0.030910\n",
      "batch 4070: loss 0.019627\n",
      "batch 4071: loss 0.023283\n",
      "batch 4072: loss 0.096282\n",
      "batch 4073: loss 0.194965\n",
      "batch 4074: loss 0.177297\n",
      "batch 4075: loss 0.025663\n",
      "batch 4076: loss 0.051847\n",
      "batch 4077: loss 0.057345\n",
      "batch 4078: loss 0.016228\n",
      "batch 4079: loss 0.051865\n",
      "batch 4080: loss 0.049028\n",
      "batch 4081: loss 0.408728\n",
      "batch 4082: loss 0.032659\n",
      "batch 4083: loss 0.029197\n",
      "batch 4084: loss 0.059197\n",
      "batch 4085: loss 0.096833\n",
      "batch 4086: loss 0.095402\n",
      "batch 4087: loss 0.168145\n",
      "batch 4088: loss 0.076669\n",
      "batch 4089: loss 0.122903\n",
      "batch 4090: loss 0.052885\n",
      "batch 4091: loss 0.019548\n",
      "batch 4092: loss 0.098553\n",
      "batch 4093: loss 0.085769\n",
      "batch 4094: loss 0.026857\n",
      "batch 4095: loss 0.025374\n",
      "batch 4096: loss 0.071411\n",
      "batch 4097: loss 0.123562\n",
      "batch 4098: loss 0.084938\n",
      "batch 4099: loss 0.032062\n",
      "batch 4100: loss 0.139922\n",
      "batch 4101: loss 0.053784\n",
      "batch 4102: loss 0.052970\n",
      "batch 4103: loss 0.107286\n",
      "batch 4104: loss 0.039521\n",
      "batch 4105: loss 0.160216\n",
      "batch 4106: loss 0.124649\n",
      "batch 4107: loss 0.180455\n",
      "batch 4108: loss 0.051325\n",
      "batch 4109: loss 0.108849\n",
      "batch 4110: loss 0.019924\n",
      "batch 4111: loss 0.086788\n",
      "batch 4112: loss 0.022207\n",
      "batch 4113: loss 0.078934\n",
      "batch 4114: loss 0.038511\n",
      "batch 4115: loss 0.036846\n",
      "batch 4116: loss 0.223065\n",
      "batch 4117: loss 0.125434\n",
      "batch 4118: loss 0.018980\n",
      "batch 4119: loss 0.034085\n",
      "batch 4120: loss 0.020614\n",
      "batch 4121: loss 0.034200\n",
      "batch 4122: loss 0.015114\n",
      "batch 4123: loss 0.245512\n",
      "batch 4124: loss 0.075703\n",
      "batch 4125: loss 0.035528\n",
      "batch 4126: loss 0.048405\n",
      "batch 4127: loss 0.065236\n",
      "batch 4128: loss 0.053230\n",
      "batch 4129: loss 0.084828\n",
      "batch 4130: loss 0.081186\n",
      "batch 4131: loss 0.049939\n",
      "batch 4132: loss 0.097900\n",
      "batch 4133: loss 0.048182\n",
      "batch 4134: loss 0.070049\n",
      "batch 4135: loss 0.012441\n",
      "batch 4136: loss 0.198090\n",
      "batch 4137: loss 0.030731\n",
      "batch 4138: loss 0.025367\n",
      "batch 4139: loss 0.134257\n",
      "batch 4140: loss 0.104880\n",
      "batch 4141: loss 0.220126\n",
      "batch 4142: loss 0.082859\n",
      "batch 4143: loss 0.033531\n",
      "batch 4144: loss 0.035423\n",
      "batch 4145: loss 0.126378\n",
      "batch 4146: loss 0.065617\n",
      "batch 4147: loss 0.074264\n",
      "batch 4148: loss 0.039531\n",
      "batch 4149: loss 0.067301\n",
      "batch 4150: loss 0.133755\n",
      "batch 4151: loss 0.047659\n",
      "batch 4152: loss 0.024541\n",
      "batch 4153: loss 0.082811\n",
      "batch 4154: loss 0.037771\n",
      "batch 4155: loss 0.059361\n",
      "batch 4156: loss 0.099975\n",
      "batch 4157: loss 0.030034\n",
      "batch 4158: loss 0.020698\n",
      "batch 4159: loss 0.037976\n",
      "batch 4160: loss 0.023264\n",
      "batch 4161: loss 0.059996\n",
      "batch 4162: loss 0.043559\n",
      "batch 4163: loss 0.074210\n",
      "batch 4164: loss 0.018331\n",
      "batch 4165: loss 0.018889\n",
      "batch 4166: loss 0.105794\n",
      "batch 4167: loss 0.097982\n",
      "batch 4168: loss 0.045297\n",
      "batch 4169: loss 0.114253\n",
      "batch 4170: loss 0.029420\n",
      "batch 4171: loss 0.029923\n",
      "batch 4172: loss 0.043008\n",
      "batch 4173: loss 0.042726\n",
      "batch 4174: loss 0.014523\n",
      "batch 4175: loss 0.077205\n",
      "batch 4176: loss 0.069114\n",
      "batch 4177: loss 0.102524\n",
      "batch 4178: loss 0.030442\n",
      "batch 4179: loss 0.155511\n",
      "batch 4180: loss 0.070904\n",
      "batch 4181: loss 0.024983\n",
      "batch 4182: loss 0.047334\n",
      "batch 4183: loss 0.175798\n",
      "batch 4184: loss 0.044594\n",
      "batch 4185: loss 0.020907\n",
      "batch 4186: loss 0.052398\n",
      "batch 4187: loss 0.158459\n",
      "batch 4188: loss 0.025426\n",
      "batch 4189: loss 0.073973\n",
      "batch 4190: loss 0.174999\n",
      "batch 4191: loss 0.016112\n",
      "batch 4192: loss 0.064360\n",
      "batch 4193: loss 0.010244\n",
      "batch 4194: loss 0.106253\n",
      "batch 4195: loss 0.062077\n",
      "batch 4196: loss 0.065185\n",
      "batch 4197: loss 0.066706\n",
      "batch 4198: loss 0.077505\n",
      "batch 4199: loss 0.063081\n",
      "batch 4200: loss 0.131357\n",
      "batch 4201: loss 0.008650\n",
      "batch 4202: loss 0.017196\n",
      "batch 4203: loss 0.050214\n",
      "batch 4204: loss 0.021841\n",
      "batch 4205: loss 0.115818\n",
      "batch 4206: loss 0.041675\n",
      "batch 4207: loss 0.063381\n",
      "batch 4208: loss 0.098487\n",
      "batch 4209: loss 0.032536\n",
      "batch 4210: loss 0.013249\n",
      "batch 4211: loss 0.050102\n",
      "batch 4212: loss 0.037426\n",
      "batch 4213: loss 0.018336\n",
      "batch 4214: loss 0.020566\n",
      "batch 4215: loss 0.087004\n",
      "batch 4216: loss 0.119316\n",
      "batch 4217: loss 0.045929\n",
      "batch 4218: loss 0.093386\n",
      "batch 4219: loss 0.072348\n",
      "batch 4220: loss 0.172940\n",
      "batch 4221: loss 0.074047\n",
      "batch 4222: loss 0.042867\n",
      "batch 4223: loss 0.021109\n",
      "batch 4224: loss 0.065872\n",
      "batch 4225: loss 0.124872\n",
      "batch 4226: loss 0.127914\n",
      "batch 4227: loss 0.043871\n",
      "batch 4228: loss 0.050764\n",
      "batch 4229: loss 0.048446\n",
      "batch 4230: loss 0.041806\n",
      "batch 4231: loss 0.023260\n",
      "batch 4232: loss 0.022233\n",
      "batch 4233: loss 0.072910\n",
      "batch 4234: loss 0.094787\n",
      "batch 4235: loss 0.052769\n",
      "batch 4236: loss 0.032704\n",
      "batch 4237: loss 0.005052\n",
      "batch 4238: loss 0.023476\n",
      "batch 4239: loss 0.172936\n",
      "batch 4240: loss 0.056018\n",
      "batch 4241: loss 0.029941\n",
      "batch 4242: loss 0.031308\n",
      "batch 4243: loss 0.052689\n",
      "batch 4244: loss 0.056610\n",
      "batch 4245: loss 0.065672\n",
      "batch 4246: loss 0.065345\n",
      "batch 4247: loss 0.028683\n",
      "batch 4248: loss 0.028800\n",
      "batch 4249: loss 0.075010\n",
      "batch 4250: loss 0.083985\n",
      "batch 4251: loss 0.006040\n",
      "batch 4252: loss 0.071166\n",
      "batch 4253: loss 0.055021\n",
      "batch 4254: loss 0.015067\n",
      "batch 4255: loss 0.026873\n",
      "batch 4256: loss 0.088705\n",
      "batch 4257: loss 0.023237\n",
      "batch 4258: loss 0.023684\n",
      "batch 4259: loss 0.054771\n",
      "batch 4260: loss 0.096037\n",
      "batch 4261: loss 0.031032\n",
      "batch 4262: loss 0.048216\n",
      "batch 4263: loss 0.125697\n",
      "batch 4264: loss 0.021480\n",
      "batch 4265: loss 0.060123\n",
      "batch 4266: loss 0.119857\n",
      "batch 4267: loss 0.110185\n",
      "batch 4268: loss 0.065323\n",
      "batch 4269: loss 0.118349\n",
      "batch 4270: loss 0.021481\n",
      "batch 4271: loss 0.021296\n",
      "batch 4272: loss 0.132265\n",
      "batch 4273: loss 0.029940\n",
      "batch 4274: loss 0.111824\n",
      "batch 4275: loss 0.038627\n",
      "batch 4276: loss 0.135016\n",
      "batch 4277: loss 0.048771\n",
      "batch 4278: loss 0.205622\n",
      "batch 4279: loss 0.041442\n",
      "batch 4280: loss 0.062588\n",
      "batch 4281: loss 0.039413\n",
      "batch 4282: loss 0.061925\n",
      "batch 4283: loss 0.030869\n",
      "batch 4284: loss 0.109249\n",
      "batch 4285: loss 0.113417\n",
      "batch 4286: loss 0.057000\n",
      "batch 4287: loss 0.081464\n",
      "batch 4288: loss 0.082422\n",
      "batch 4289: loss 0.042697\n",
      "batch 4290: loss 0.039332\n",
      "batch 4291: loss 0.036859\n",
      "batch 4292: loss 0.142343\n",
      "batch 4293: loss 0.079530\n",
      "batch 4294: loss 0.024813\n",
      "batch 4295: loss 0.014083\n",
      "batch 4296: loss 0.075245\n",
      "batch 4297: loss 0.032084\n",
      "batch 4298: loss 0.108626\n",
      "batch 4299: loss 0.036923\n",
      "batch 4300: loss 0.019105\n",
      "batch 4301: loss 0.023370\n",
      "batch 4302: loss 0.019466\n",
      "batch 4303: loss 0.021928\n",
      "batch 4304: loss 0.043522\n",
      "batch 4305: loss 0.141175\n",
      "batch 4306: loss 0.037769\n",
      "batch 4307: loss 0.109041\n",
      "batch 4308: loss 0.089900\n",
      "batch 4309: loss 0.059890\n",
      "batch 4310: loss 0.025513\n",
      "batch 4311: loss 0.022374\n",
      "batch 4312: loss 0.066835\n",
      "batch 4313: loss 0.013427\n",
      "batch 4314: loss 0.111894\n",
      "batch 4315: loss 0.126920\n",
      "batch 4316: loss 0.016184\n",
      "batch 4317: loss 0.090760\n",
      "batch 4318: loss 0.053419\n",
      "batch 4319: loss 0.033879\n",
      "batch 4320: loss 0.020699\n",
      "batch 4321: loss 0.012063\n",
      "batch 4322: loss 0.024581\n",
      "batch 4323: loss 0.044148\n",
      "batch 4324: loss 0.182660\n",
      "batch 4325: loss 0.025333\n",
      "batch 4326: loss 0.065329\n",
      "batch 4327: loss 0.069638\n",
      "batch 4328: loss 0.219931\n",
      "batch 4329: loss 0.128443\n",
      "batch 4330: loss 0.104734\n",
      "batch 4331: loss 0.027387\n",
      "batch 4332: loss 0.012877\n",
      "batch 4333: loss 0.015608\n",
      "batch 4334: loss 0.104279\n",
      "batch 4335: loss 0.076073\n",
      "batch 4336: loss 0.187091\n",
      "batch 4337: loss 0.010722\n",
      "batch 4338: loss 0.013976\n",
      "batch 4339: loss 0.157570\n",
      "batch 4340: loss 0.014203\n",
      "batch 4341: loss 0.126112\n",
      "batch 4342: loss 0.210817\n",
      "batch 4343: loss 0.067686\n",
      "batch 4344: loss 0.047625\n",
      "batch 4345: loss 0.071143\n",
      "batch 4346: loss 0.080203\n",
      "batch 4347: loss 0.103861\n",
      "batch 4348: loss 0.100385\n",
      "batch 4349: loss 0.215600\n",
      "batch 4350: loss 0.041374\n",
      "batch 4351: loss 0.016293\n",
      "batch 4352: loss 0.079035\n",
      "batch 4353: loss 0.119861\n",
      "batch 4354: loss 0.029369\n",
      "batch 4355: loss 0.047627\n",
      "batch 4356: loss 0.072805\n",
      "batch 4357: loss 0.032521\n",
      "batch 4358: loss 0.031639\n",
      "batch 4359: loss 0.068361\n",
      "batch 4360: loss 0.297694\n",
      "batch 4361: loss 0.025462\n",
      "batch 4362: loss 0.015993\n",
      "batch 4363: loss 0.050640\n",
      "batch 4364: loss 0.060710\n",
      "batch 4365: loss 0.034011\n",
      "batch 4366: loss 0.075227\n",
      "batch 4367: loss 0.067428\n",
      "batch 4368: loss 0.112652\n",
      "batch 4369: loss 0.135786\n",
      "batch 4370: loss 0.059232\n",
      "batch 4371: loss 0.035298\n",
      "batch 4372: loss 0.054068\n",
      "batch 4373: loss 0.318498\n",
      "batch 4374: loss 0.081796\n",
      "batch 4375: loss 0.141698\n",
      "batch 4376: loss 0.026090\n",
      "batch 4377: loss 0.130965\n",
      "batch 4378: loss 0.020757\n",
      "batch 4379: loss 0.015663\n",
      "batch 4380: loss 0.041980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4381: loss 0.029183\n",
      "batch 4382: loss 0.028607\n",
      "batch 4383: loss 0.026518\n",
      "batch 4384: loss 0.062160\n",
      "batch 4385: loss 0.008079\n",
      "batch 4386: loss 0.079679\n",
      "batch 4387: loss 0.157912\n",
      "batch 4388: loss 0.049998\n",
      "batch 4389: loss 0.054488\n",
      "batch 4390: loss 0.092487\n",
      "batch 4391: loss 0.019647\n",
      "batch 4392: loss 0.037965\n",
      "batch 4393: loss 0.059613\n",
      "batch 4394: loss 0.041037\n",
      "batch 4395: loss 0.056484\n",
      "batch 4396: loss 0.120272\n",
      "batch 4397: loss 0.075093\n",
      "batch 4398: loss 0.130533\n",
      "batch 4399: loss 0.082249\n",
      "batch 4400: loss 0.037358\n",
      "batch 4401: loss 0.124255\n",
      "batch 4402: loss 0.220542\n",
      "batch 4403: loss 0.042931\n",
      "batch 4404: loss 0.047431\n",
      "batch 4405: loss 0.099772\n",
      "batch 4406: loss 0.053369\n",
      "batch 4407: loss 0.030118\n",
      "batch 4408: loss 0.057212\n",
      "batch 4409: loss 0.044214\n",
      "batch 4410: loss 0.027357\n",
      "batch 4411: loss 0.046567\n",
      "batch 4412: loss 0.045217\n",
      "batch 4413: loss 0.031394\n",
      "batch 4414: loss 0.136500\n",
      "batch 4415: loss 0.036946\n",
      "batch 4416: loss 0.030478\n",
      "batch 4417: loss 0.050636\n",
      "batch 4418: loss 0.024017\n",
      "batch 4419: loss 0.088286\n",
      "batch 4420: loss 0.018874\n",
      "batch 4421: loss 0.077129\n",
      "batch 4422: loss 0.007330\n",
      "batch 4423: loss 0.043320\n",
      "batch 4424: loss 0.021258\n",
      "batch 4425: loss 0.023737\n",
      "batch 4426: loss 0.016871\n",
      "batch 4427: loss 0.106833\n",
      "batch 4428: loss 0.074169\n",
      "batch 4429: loss 0.084807\n",
      "batch 4430: loss 0.046715\n",
      "batch 4431: loss 0.075984\n",
      "batch 4432: loss 0.037267\n",
      "batch 4433: loss 0.136811\n",
      "batch 4434: loss 0.064716\n",
      "batch 4435: loss 0.013136\n",
      "batch 4436: loss 0.033340\n",
      "batch 4437: loss 0.041977\n",
      "batch 4438: loss 0.020135\n",
      "batch 4439: loss 0.030957\n",
      "batch 4440: loss 0.018136\n",
      "batch 4441: loss 0.016266\n",
      "batch 4442: loss 0.018840\n",
      "batch 4443: loss 0.037412\n",
      "batch 4444: loss 0.017098\n",
      "batch 4445: loss 0.070590\n",
      "batch 4446: loss 0.083172\n",
      "batch 4447: loss 0.038669\n",
      "batch 4448: loss 0.037480\n",
      "batch 4449: loss 0.173835\n",
      "batch 4450: loss 0.019788\n",
      "batch 4451: loss 0.318623\n",
      "batch 4452: loss 0.047047\n",
      "batch 4453: loss 0.037882\n",
      "batch 4454: loss 0.096763\n",
      "batch 4455: loss 0.030199\n",
      "batch 4456: loss 0.047915\n",
      "batch 4457: loss 0.030999\n",
      "batch 4458: loss 0.087030\n",
      "batch 4459: loss 0.065498\n",
      "batch 4460: loss 0.041639\n",
      "batch 4461: loss 0.022950\n",
      "batch 4462: loss 0.017098\n",
      "batch 4463: loss 0.046695\n",
      "batch 4464: loss 0.079985\n",
      "batch 4465: loss 0.047916\n",
      "batch 4466: loss 0.050093\n",
      "batch 4467: loss 0.106155\n",
      "batch 4468: loss 0.061077\n",
      "batch 4469: loss 0.019664\n",
      "batch 4470: loss 0.063605\n",
      "batch 4471: loss 0.012270\n",
      "batch 4472: loss 0.153206\n",
      "batch 4473: loss 0.053511\n",
      "batch 4474: loss 0.027170\n",
      "batch 4475: loss 0.050780\n",
      "batch 4476: loss 0.020693\n",
      "batch 4477: loss 0.092705\n",
      "batch 4478: loss 0.023330\n",
      "batch 4479: loss 0.054272\n",
      "batch 4480: loss 0.044224\n",
      "batch 4481: loss 0.125233\n",
      "batch 4482: loss 0.011450\n",
      "batch 4483: loss 0.014213\n",
      "batch 4484: loss 0.051522\n",
      "batch 4485: loss 0.032607\n",
      "batch 4486: loss 0.008414\n",
      "batch 4487: loss 0.159375\n",
      "batch 4488: loss 0.044754\n",
      "batch 4489: loss 0.182871\n",
      "batch 4490: loss 0.033633\n",
      "batch 4491: loss 0.022657\n",
      "batch 4492: loss 0.038882\n",
      "batch 4493: loss 0.036868\n",
      "batch 4494: loss 0.073487\n",
      "batch 4495: loss 0.045048\n",
      "batch 4496: loss 0.096304\n",
      "batch 4497: loss 0.044208\n",
      "batch 4498: loss 0.014004\n",
      "batch 4499: loss 0.116560\n",
      "batch 4500: loss 0.031366\n",
      "batch 4501: loss 0.152465\n",
      "batch 4502: loss 0.099311\n",
      "batch 4503: loss 0.028263\n",
      "batch 4504: loss 0.014602\n",
      "batch 4505: loss 0.040105\n",
      "batch 4506: loss 0.050765\n",
      "batch 4507: loss 0.108120\n",
      "batch 4508: loss 0.115092\n",
      "batch 4509: loss 0.027000\n",
      "batch 4510: loss 0.099012\n",
      "batch 4511: loss 0.135279\n",
      "batch 4512: loss 0.032631\n",
      "batch 4513: loss 0.048602\n",
      "batch 4514: loss 0.100938\n",
      "batch 4515: loss 0.026336\n",
      "batch 4516: loss 0.025630\n",
      "batch 4517: loss 0.020815\n",
      "batch 4518: loss 0.052018\n",
      "batch 4519: loss 0.037119\n",
      "batch 4520: loss 0.039576\n",
      "batch 4521: loss 0.073334\n",
      "batch 4522: loss 0.050805\n",
      "batch 4523: loss 0.222892\n",
      "batch 4524: loss 0.114516\n",
      "batch 4525: loss 0.180294\n",
      "batch 4526: loss 0.187905\n",
      "batch 4527: loss 0.165887\n",
      "batch 4528: loss 0.125390\n",
      "batch 4529: loss 0.066491\n",
      "batch 4530: loss 0.048017\n",
      "batch 4531: loss 0.027449\n",
      "batch 4532: loss 0.015664\n",
      "batch 4533: loss 0.019022\n",
      "batch 4534: loss 0.102975\n",
      "batch 4535: loss 0.085614\n",
      "batch 4536: loss 0.077116\n",
      "batch 4537: loss 0.019322\n",
      "batch 4538: loss 0.049746\n",
      "batch 4539: loss 0.044874\n",
      "batch 4540: loss 0.010900\n",
      "batch 4541: loss 0.058432\n",
      "batch 4542: loss 0.086785\n",
      "batch 4543: loss 0.033183\n",
      "batch 4544: loss 0.021610\n",
      "batch 4545: loss 0.021119\n",
      "batch 4546: loss 0.036507\n",
      "batch 4547: loss 0.099328\n",
      "batch 4548: loss 0.031523\n",
      "batch 4549: loss 0.053910\n",
      "batch 4550: loss 0.332497\n",
      "batch 4551: loss 0.012205\n",
      "batch 4552: loss 0.072790\n",
      "batch 4553: loss 0.010824\n",
      "batch 4554: loss 0.091216\n",
      "batch 4555: loss 0.197374\n",
      "batch 4556: loss 0.028817\n",
      "batch 4557: loss 0.227614\n",
      "batch 4558: loss 0.005296\n",
      "batch 4559: loss 0.095425\n",
      "batch 4560: loss 0.035307\n",
      "batch 4561: loss 0.037346\n",
      "batch 4562: loss 0.023887\n",
      "batch 4563: loss 0.020271\n",
      "batch 4564: loss 0.023627\n",
      "batch 4565: loss 0.086581\n",
      "batch 4566: loss 0.102796\n",
      "batch 4567: loss 0.024520\n",
      "batch 4568: loss 0.038335\n",
      "batch 4569: loss 0.071505\n",
      "batch 4570: loss 0.049894\n",
      "batch 4571: loss 0.051439\n",
      "batch 4572: loss 0.117726\n",
      "batch 4573: loss 0.013454\n",
      "batch 4574: loss 0.154955\n",
      "batch 4575: loss 0.028676\n",
      "batch 4576: loss 0.100182\n",
      "batch 4577: loss 0.054421\n",
      "batch 4578: loss 0.005974\n",
      "batch 4579: loss 0.040806\n",
      "batch 4580: loss 0.031573\n",
      "batch 4581: loss 0.020003\n",
      "batch 4582: loss 0.035066\n",
      "batch 4583: loss 0.037493\n",
      "batch 4584: loss 0.008302\n",
      "batch 4585: loss 0.109988\n",
      "batch 4586: loss 0.057262\n",
      "batch 4587: loss 0.027894\n",
      "batch 4588: loss 0.138498\n",
      "batch 4589: loss 0.068122\n",
      "batch 4590: loss 0.009201\n",
      "batch 4591: loss 0.028526\n",
      "batch 4592: loss 0.046205\n",
      "batch 4593: loss 0.007614\n",
      "batch 4594: loss 0.114475\n",
      "batch 4595: loss 0.013207\n",
      "batch 4596: loss 0.013678\n",
      "batch 4597: loss 0.052804\n",
      "batch 4598: loss 0.048726\n",
      "batch 4599: loss 0.015636\n",
      "batch 4600: loss 0.056556\n",
      "batch 4601: loss 0.014835\n",
      "batch 4602: loss 0.015361\n",
      "batch 4603: loss 0.087292\n",
      "batch 4604: loss 0.169127\n",
      "batch 4605: loss 0.199785\n",
      "batch 4606: loss 0.037929\n",
      "batch 4607: loss 0.100685\n",
      "batch 4608: loss 0.088991\n",
      "batch 4609: loss 0.029001\n",
      "batch 4610: loss 0.041336\n",
      "batch 4611: loss 0.012894\n",
      "batch 4612: loss 0.124536\n",
      "batch 4613: loss 0.093988\n",
      "batch 4614: loss 0.029137\n",
      "batch 4615: loss 0.038960\n",
      "batch 4616: loss 0.106527\n",
      "batch 4617: loss 0.096495\n",
      "batch 4618: loss 0.018235\n",
      "batch 4619: loss 0.182751\n",
      "batch 4620: loss 0.054156\n",
      "batch 4621: loss 0.098552\n",
      "batch 4622: loss 0.056638\n",
      "batch 4623: loss 0.108260\n",
      "batch 4624: loss 0.134391\n",
      "batch 4625: loss 0.019694\n",
      "batch 4626: loss 0.053886\n",
      "batch 4627: loss 0.125045\n",
      "batch 4628: loss 0.013057\n",
      "batch 4629: loss 0.013612\n",
      "batch 4630: loss 0.159484\n",
      "batch 4631: loss 0.028785\n",
      "batch 4632: loss 0.060971\n",
      "batch 4633: loss 0.202213\n",
      "batch 4634: loss 0.080424\n",
      "batch 4635: loss 0.064086\n",
      "batch 4636: loss 0.109483\n",
      "batch 4637: loss 0.144981\n",
      "batch 4638: loss 0.030901\n",
      "batch 4639: loss 0.073968\n",
      "batch 4640: loss 0.055667\n",
      "batch 4641: loss 0.042253\n",
      "batch 4642: loss 0.170565\n",
      "batch 4643: loss 0.114901\n",
      "batch 4644: loss 0.032627\n",
      "batch 4645: loss 0.079373\n",
      "batch 4646: loss 0.036618\n",
      "batch 4647: loss 0.074219\n",
      "batch 4648: loss 0.011713\n",
      "batch 4649: loss 0.060424\n",
      "batch 4650: loss 0.018051\n",
      "batch 4651: loss 0.267462\n",
      "batch 4652: loss 0.029296\n",
      "batch 4653: loss 0.054535\n",
      "batch 4654: loss 0.010865\n",
      "batch 4655: loss 0.060800\n",
      "batch 4656: loss 0.065109\n",
      "batch 4657: loss 0.027242\n",
      "batch 4658: loss 0.093573\n",
      "batch 4659: loss 0.053211\n",
      "batch 4660: loss 0.063830\n",
      "batch 4661: loss 0.051040\n",
      "batch 4662: loss 0.093939\n",
      "batch 4663: loss 0.048267\n",
      "batch 4664: loss 0.058297\n",
      "batch 4665: loss 0.043949\n",
      "batch 4666: loss 0.036756\n",
      "batch 4667: loss 0.014885\n",
      "batch 4668: loss 0.024117\n",
      "batch 4669: loss 0.063321\n",
      "batch 4670: loss 0.052945\n",
      "batch 4671: loss 0.066601\n",
      "batch 4672: loss 0.031969\n",
      "batch 4673: loss 0.094003\n",
      "batch 4674: loss 0.014531\n",
      "batch 4675: loss 0.014790\n",
      "batch 4676: loss 0.072583\n",
      "batch 4677: loss 0.123948\n",
      "batch 4678: loss 0.100475\n",
      "batch 4679: loss 0.040541\n",
      "batch 4680: loss 0.016785\n",
      "batch 4681: loss 0.056361\n",
      "batch 4682: loss 0.051118\n",
      "batch 4683: loss 0.041441\n",
      "batch 4684: loss 0.017454\n",
      "batch 4685: loss 0.086092\n",
      "batch 4686: loss 0.004284\n",
      "batch 4687: loss 0.037141\n",
      "batch 4688: loss 0.012607\n",
      "batch 4689: loss 0.046210\n",
      "batch 4690: loss 0.027141\n",
      "batch 4691: loss 0.040098\n",
      "batch 4692: loss 0.155101\n",
      "batch 4693: loss 0.113060\n",
      "batch 4694: loss 0.035686\n",
      "batch 4695: loss 0.034172\n",
      "batch 4696: loss 0.031619\n",
      "batch 4697: loss 0.012714\n",
      "batch 4698: loss 0.059868\n",
      "batch 4699: loss 0.019010\n",
      "batch 4700: loss 0.012365\n",
      "batch 4701: loss 0.014805\n",
      "batch 4702: loss 0.057253\n",
      "batch 4703: loss 0.051628\n",
      "batch 4704: loss 0.018862\n",
      "batch 4705: loss 0.083285\n",
      "batch 4706: loss 0.066533\n",
      "batch 4707: loss 0.029872\n",
      "batch 4708: loss 0.012126\n",
      "batch 4709: loss 0.075489\n",
      "batch 4710: loss 0.043938\n",
      "batch 4711: loss 0.008347\n",
      "batch 4712: loss 0.075166\n",
      "batch 4713: loss 0.005549\n",
      "batch 4714: loss 0.040808\n",
      "batch 4715: loss 0.082383\n",
      "batch 4716: loss 0.067088\n",
      "batch 4717: loss 0.011104\n",
      "batch 4718: loss 0.043485\n",
      "batch 4719: loss 0.054740\n",
      "batch 4720: loss 0.035677\n",
      "batch 4721: loss 0.034756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4722: loss 0.093903\n",
      "batch 4723: loss 0.011096\n",
      "batch 4724: loss 0.041609\n",
      "batch 4725: loss 0.055827\n",
      "batch 4726: loss 0.074875\n",
      "batch 4727: loss 0.075745\n",
      "batch 4728: loss 0.097463\n",
      "batch 4729: loss 0.007652\n",
      "batch 4730: loss 0.063148\n",
      "batch 4731: loss 0.024279\n",
      "batch 4732: loss 0.067345\n",
      "batch 4733: loss 0.022485\n",
      "batch 4734: loss 0.024651\n",
      "batch 4735: loss 0.066455\n",
      "batch 4736: loss 0.098375\n",
      "batch 4737: loss 0.076060\n",
      "batch 4738: loss 0.014577\n",
      "batch 4739: loss 0.035120\n",
      "batch 4740: loss 0.089022\n",
      "batch 4741: loss 0.022179\n",
      "batch 4742: loss 0.011320\n",
      "batch 4743: loss 0.045622\n",
      "batch 4744: loss 0.052889\n",
      "batch 4745: loss 0.026092\n",
      "batch 4746: loss 0.095596\n",
      "batch 4747: loss 0.055879\n",
      "batch 4748: loss 0.067991\n",
      "batch 4749: loss 0.060729\n",
      "batch 4750: loss 0.035595\n",
      "batch 4751: loss 0.103296\n",
      "batch 4752: loss 0.138553\n",
      "batch 4753: loss 0.072969\n",
      "batch 4754: loss 0.092223\n",
      "batch 4755: loss 0.112830\n",
      "batch 4756: loss 0.066137\n",
      "batch 4757: loss 0.119887\n",
      "batch 4758: loss 0.067026\n",
      "batch 4759: loss 0.010911\n",
      "batch 4760: loss 0.095227\n",
      "batch 4761: loss 0.007133\n",
      "batch 4762: loss 0.029245\n",
      "batch 4763: loss 0.038601\n",
      "batch 4764: loss 0.179187\n",
      "batch 4765: loss 0.135379\n",
      "batch 4766: loss 0.075058\n",
      "batch 4767: loss 0.012222\n",
      "batch 4768: loss 0.135080\n",
      "batch 4769: loss 0.029357\n",
      "batch 4770: loss 0.041633\n",
      "batch 4771: loss 0.056226\n",
      "batch 4772: loss 0.016543\n",
      "batch 4773: loss 0.045249\n",
      "batch 4774: loss 0.036790\n",
      "batch 4775: loss 0.012229\n",
      "batch 4776: loss 0.023619\n",
      "batch 4777: loss 0.087704\n",
      "batch 4778: loss 0.086603\n",
      "batch 4779: loss 0.203719\n",
      "batch 4780: loss 0.072244\n",
      "batch 4781: loss 0.020862\n",
      "batch 4782: loss 0.022186\n",
      "batch 4783: loss 0.037534\n",
      "batch 4784: loss 0.157244\n",
      "batch 4785: loss 0.205472\n",
      "batch 4786: loss 0.048994\n",
      "batch 4787: loss 0.026357\n",
      "batch 4788: loss 0.019978\n",
      "batch 4789: loss 0.135594\n",
      "batch 4790: loss 0.009648\n",
      "batch 4791: loss 0.089290\n",
      "batch 4792: loss 0.028922\n",
      "batch 4793: loss 0.181239\n",
      "batch 4794: loss 0.023799\n",
      "batch 4795: loss 0.051216\n",
      "batch 4796: loss 0.031877\n",
      "batch 4797: loss 0.130072\n",
      "batch 4798: loss 0.101695\n",
      "batch 4799: loss 0.020856\n",
      "batch 4800: loss 0.053967\n",
      "batch 4801: loss 0.118352\n",
      "batch 4802: loss 0.023138\n",
      "batch 4803: loss 0.040674\n",
      "batch 4804: loss 0.015849\n",
      "batch 4805: loss 0.015219\n",
      "batch 4806: loss 0.099832\n",
      "batch 4807: loss 0.024460\n",
      "batch 4808: loss 0.136559\n",
      "batch 4809: loss 0.028729\n",
      "batch 4810: loss 0.031436\n",
      "batch 4811: loss 0.032265\n",
      "batch 4812: loss 0.050469\n",
      "batch 4813: loss 0.053944\n",
      "batch 4814: loss 0.027937\n",
      "batch 4815: loss 0.065756\n",
      "batch 4816: loss 0.115654\n",
      "batch 4817: loss 0.040875\n",
      "batch 4818: loss 0.048614\n",
      "batch 4819: loss 0.094016\n",
      "batch 4820: loss 0.015336\n",
      "batch 4821: loss 0.052704\n",
      "batch 4822: loss 0.036932\n",
      "batch 4823: loss 0.082263\n",
      "batch 4824: loss 0.012234\n",
      "batch 4825: loss 0.038450\n",
      "batch 4826: loss 0.054003\n",
      "batch 4827: loss 0.194266\n",
      "batch 4828: loss 0.052788\n",
      "batch 4829: loss 0.116938\n",
      "batch 4830: loss 0.025935\n",
      "batch 4831: loss 0.051121\n",
      "batch 4832: loss 0.036192\n",
      "batch 4833: loss 0.166788\n",
      "batch 4834: loss 0.054066\n",
      "batch 4835: loss 0.021026\n",
      "batch 4836: loss 0.056498\n",
      "batch 4837: loss 0.010845\n",
      "batch 4838: loss 0.055905\n",
      "batch 4839: loss 0.038700\n",
      "batch 4840: loss 0.045096\n",
      "batch 4841: loss 0.050153\n",
      "batch 4842: loss 0.084259\n",
      "batch 4843: loss 0.056962\n",
      "batch 4844: loss 0.033430\n",
      "batch 4845: loss 0.013749\n",
      "batch 4846: loss 0.025867\n",
      "batch 4847: loss 0.006242\n",
      "batch 4848: loss 0.078103\n",
      "batch 4849: loss 0.031460\n",
      "batch 4850: loss 0.043095\n",
      "batch 4851: loss 0.018531\n",
      "batch 4852: loss 0.062565\n",
      "batch 4853: loss 0.030397\n",
      "batch 4854: loss 0.055755\n",
      "batch 4855: loss 0.025271\n",
      "batch 4856: loss 0.144903\n",
      "batch 4857: loss 0.063682\n",
      "batch 4858: loss 0.087663\n",
      "batch 4859: loss 0.032854\n",
      "batch 4860: loss 0.035409\n",
      "batch 4861: loss 0.077481\n",
      "batch 4862: loss 0.024619\n",
      "batch 4863: loss 0.022851\n",
      "batch 4864: loss 0.032575\n",
      "batch 4865: loss 0.015262\n",
      "batch 4866: loss 0.013806\n",
      "batch 4867: loss 0.028511\n",
      "batch 4868: loss 0.020310\n",
      "batch 4869: loss 0.125285\n",
      "batch 4870: loss 0.019632\n",
      "batch 4871: loss 0.056276\n",
      "batch 4872: loss 0.051905\n",
      "batch 4873: loss 0.094934\n",
      "batch 4874: loss 0.016189\n",
      "batch 4875: loss 0.023861\n",
      "batch 4876: loss 0.090347\n",
      "batch 4877: loss 0.051085\n",
      "batch 4878: loss 0.112788\n",
      "batch 4879: loss 0.102371\n",
      "batch 4880: loss 0.038032\n",
      "batch 4881: loss 0.082909\n",
      "batch 4882: loss 0.103266\n",
      "batch 4883: loss 0.014904\n",
      "batch 4884: loss 0.019919\n",
      "batch 4885: loss 0.131210\n",
      "batch 4886: loss 0.075598\n",
      "batch 4887: loss 0.104168\n",
      "batch 4888: loss 0.004790\n",
      "batch 4889: loss 0.153813\n",
      "batch 4890: loss 0.030396\n",
      "batch 4891: loss 0.036103\n",
      "batch 4892: loss 0.026831\n",
      "batch 4893: loss 0.147310\n",
      "batch 4894: loss 0.040663\n",
      "batch 4895: loss 0.112826\n",
      "batch 4896: loss 0.047327\n",
      "batch 4897: loss 0.090141\n",
      "batch 4898: loss 0.026096\n",
      "batch 4899: loss 0.211537\n",
      "batch 4900: loss 0.057449\n",
      "batch 4901: loss 0.063886\n",
      "batch 4902: loss 0.004624\n",
      "batch 4903: loss 0.009710\n",
      "batch 4904: loss 0.042328\n",
      "batch 4905: loss 0.053861\n",
      "batch 4906: loss 0.098908\n",
      "batch 4907: loss 0.108987\n",
      "batch 4908: loss 0.167524\n",
      "batch 4909: loss 0.025485\n",
      "batch 4910: loss 0.045400\n",
      "batch 4911: loss 0.143376\n",
      "batch 4912: loss 0.113175\n",
      "batch 4913: loss 0.044895\n",
      "batch 4914: loss 0.034596\n",
      "batch 4915: loss 0.088317\n",
      "batch 4916: loss 0.093943\n",
      "batch 4917: loss 0.050951\n",
      "batch 4918: loss 0.066947\n",
      "batch 4919: loss 0.020362\n",
      "batch 4920: loss 0.152743\n",
      "batch 4921: loss 0.106122\n",
      "batch 4922: loss 0.228032\n",
      "batch 4923: loss 0.099697\n",
      "batch 4924: loss 0.074520\n",
      "batch 4925: loss 0.027056\n",
      "batch 4926: loss 0.120437\n",
      "batch 4927: loss 0.020037\n",
      "batch 4928: loss 0.032773\n",
      "batch 4929: loss 0.110564\n",
      "batch 4930: loss 0.060522\n",
      "batch 4931: loss 0.168669\n",
      "batch 4932: loss 0.024598\n",
      "batch 4933: loss 0.149127\n",
      "batch 4934: loss 0.024420\n",
      "batch 4935: loss 0.147562\n",
      "batch 4936: loss 0.075535\n",
      "batch 4937: loss 0.067938\n",
      "batch 4938: loss 0.126013\n",
      "batch 4939: loss 0.198323\n",
      "batch 4940: loss 0.090321\n",
      "batch 4941: loss 0.030249\n",
      "batch 4942: loss 0.087588\n",
      "batch 4943: loss 0.069447\n",
      "batch 4944: loss 0.010043\n",
      "batch 4945: loss 0.129690\n",
      "batch 4946: loss 0.029224\n",
      "batch 4947: loss 0.077385\n",
      "batch 4948: loss 0.026985\n",
      "batch 4949: loss 0.082839\n",
      "batch 4950: loss 0.079744\n",
      "batch 4951: loss 0.021112\n",
      "batch 4952: loss 0.019607\n",
      "batch 4953: loss 0.012924\n",
      "batch 4954: loss 0.049351\n",
      "batch 4955: loss 0.062286\n",
      "batch 4956: loss 0.024495\n",
      "batch 4957: loss 0.011036\n",
      "batch 4958: loss 0.025546\n",
      "batch 4959: loss 0.088235\n",
      "batch 4960: loss 0.115652\n",
      "batch 4961: loss 0.199825\n",
      "batch 4962: loss 0.018380\n",
      "batch 4963: loss 0.127273\n",
      "batch 4964: loss 0.018142\n",
      "batch 4965: loss 0.091423\n",
      "batch 4966: loss 0.014112\n",
      "batch 4967: loss 0.084463\n",
      "batch 4968: loss 0.068166\n",
      "batch 4969: loss 0.027031\n",
      "batch 4970: loss 0.019328\n",
      "batch 4971: loss 0.024733\n",
      "batch 4972: loss 0.045711\n",
      "batch 4973: loss 0.111087\n",
      "batch 4974: loss 0.069847\n",
      "batch 4975: loss 0.062529\n",
      "batch 4976: loss 0.129836\n",
      "batch 4977: loss 0.024456\n",
      "batch 4978: loss 0.089471\n",
      "batch 4979: loss 0.054801\n",
      "batch 4980: loss 0.058964\n",
      "batch 4981: loss 0.056185\n",
      "batch 4982: loss 0.012479\n",
      "batch 4983: loss 0.022930\n",
      "batch 4984: loss 0.032711\n",
      "batch 4985: loss 0.014977\n",
      "batch 4986: loss 0.013011\n",
      "batch 4987: loss 0.032503\n",
      "batch 4988: loss 0.086945\n",
      "batch 4989: loss 0.019183\n",
      "batch 4990: loss 0.150670\n",
      "batch 4991: loss 0.054590\n",
      "batch 4992: loss 0.095129\n",
      "batch 4993: loss 0.004464\n",
      "batch 4994: loss 0.047478\n",
      "batch 4995: loss 0.158018\n",
      "batch 4996: loss 0.030338\n",
      "batch 4997: loss 0.074216\n",
      "batch 4998: loss 0.073473\n",
      "batch 4999: loss 0.096760\n",
      "batch 5000: loss 0.066059\n",
      "batch 5001: loss 0.029665\n",
      "batch 5002: loss 0.110955\n",
      "batch 5003: loss 0.053174\n",
      "batch 5004: loss 0.018004\n",
      "batch 5005: loss 0.082765\n",
      "batch 5006: loss 0.033367\n",
      "batch 5007: loss 0.030558\n",
      "batch 5008: loss 0.030464\n",
      "batch 5009: loss 0.196939\n",
      "batch 5010: loss 0.073319\n",
      "batch 5011: loss 0.034562\n",
      "batch 5012: loss 0.040653\n",
      "batch 5013: loss 0.095626\n",
      "batch 5014: loss 0.064597\n",
      "batch 5015: loss 0.056801\n",
      "batch 5016: loss 0.141737\n",
      "batch 5017: loss 0.043678\n",
      "batch 5018: loss 0.064066\n",
      "batch 5019: loss 0.072201\n",
      "batch 5020: loss 0.043446\n",
      "batch 5021: loss 0.020699\n",
      "batch 5022: loss 0.062376\n",
      "batch 5023: loss 0.115845\n",
      "batch 5024: loss 0.057423\n",
      "batch 5025: loss 0.021452\n",
      "batch 5026: loss 0.027779\n",
      "batch 5027: loss 0.070053\n",
      "batch 5028: loss 0.008311\n",
      "batch 5029: loss 0.023257\n",
      "batch 5030: loss 0.070300\n",
      "batch 5031: loss 0.096931\n",
      "batch 5032: loss 0.035840\n",
      "batch 5033: loss 0.104695\n",
      "batch 5034: loss 0.012745\n",
      "batch 5035: loss 0.020579\n",
      "batch 5036: loss 0.153590\n",
      "batch 5037: loss 0.066370\n",
      "batch 5038: loss 0.024735\n",
      "batch 5039: loss 0.014158\n",
      "batch 5040: loss 0.114533\n",
      "batch 5041: loss 0.008330\n",
      "batch 5042: loss 0.029134\n",
      "batch 5043: loss 0.082956\n",
      "batch 5044: loss 0.063236\n",
      "batch 5045: loss 0.101363\n",
      "batch 5046: loss 0.028611\n",
      "batch 5047: loss 0.037595\n",
      "batch 5048: loss 0.057908\n",
      "batch 5049: loss 0.020775\n",
      "batch 5050: loss 0.039711\n",
      "batch 5051: loss 0.009664\n",
      "batch 5052: loss 0.065468\n",
      "batch 5053: loss 0.120425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5054: loss 0.024231\n",
      "batch 5055: loss 0.060392\n",
      "batch 5056: loss 0.063589\n",
      "batch 5057: loss 0.007975\n",
      "batch 5058: loss 0.046136\n",
      "batch 5059: loss 0.008734\n",
      "batch 5060: loss 0.100550\n",
      "batch 5061: loss 0.069121\n",
      "batch 5062: loss 0.058437\n",
      "batch 5063: loss 0.048394\n",
      "batch 5064: loss 0.055730\n",
      "batch 5065: loss 0.046472\n",
      "batch 5066: loss 0.017050\n",
      "batch 5067: loss 0.143175\n",
      "batch 5068: loss 0.166556\n",
      "batch 5069: loss 0.024362\n",
      "batch 5070: loss 0.059877\n",
      "batch 5071: loss 0.058309\n",
      "batch 5072: loss 0.027666\n",
      "batch 5073: loss 0.095333\n",
      "batch 5074: loss 0.043421\n",
      "batch 5075: loss 0.037905\n",
      "batch 5076: loss 0.031751\n",
      "batch 5077: loss 0.025664\n",
      "batch 5078: loss 0.049571\n",
      "batch 5079: loss 0.058766\n",
      "batch 5080: loss 0.029005\n",
      "batch 5081: loss 0.044393\n",
      "batch 5082: loss 0.026949\n",
      "batch 5083: loss 0.043574\n",
      "batch 5084: loss 0.029485\n",
      "batch 5085: loss 0.043897\n",
      "batch 5086: loss 0.276486\n",
      "batch 5087: loss 0.032624\n",
      "batch 5088: loss 0.042376\n",
      "batch 5089: loss 0.036515\n",
      "batch 5090: loss 0.121533\n",
      "batch 5091: loss 0.084589\n",
      "batch 5092: loss 0.041063\n",
      "batch 5093: loss 0.191782\n",
      "batch 5094: loss 0.008368\n",
      "batch 5095: loss 0.026096\n",
      "batch 5096: loss 0.046922\n",
      "batch 5097: loss 0.254793\n",
      "batch 5098: loss 0.082392\n",
      "batch 5099: loss 0.040938\n",
      "batch 5100: loss 0.164131\n",
      "batch 5101: loss 0.019471\n",
      "batch 5102: loss 0.052040\n",
      "batch 5103: loss 0.114317\n",
      "batch 5104: loss 0.075569\n",
      "batch 5105: loss 0.018591\n",
      "batch 5106: loss 0.025084\n",
      "batch 5107: loss 0.133179\n",
      "batch 5108: loss 0.036810\n",
      "batch 5109: loss 0.075403\n",
      "batch 5110: loss 0.046917\n",
      "batch 5111: loss 0.028561\n",
      "batch 5112: loss 0.020416\n",
      "batch 5113: loss 0.027192\n",
      "batch 5114: loss 0.007413\n",
      "batch 5115: loss 0.055800\n",
      "batch 5116: loss 0.012736\n",
      "batch 5117: loss 0.031617\n",
      "batch 5118: loss 0.065145\n",
      "batch 5119: loss 0.008418\n",
      "batch 5120: loss 0.014179\n",
      "batch 5121: loss 0.028022\n",
      "batch 5122: loss 0.022315\n",
      "batch 5123: loss 0.102501\n",
      "batch 5124: loss 0.082941\n",
      "batch 5125: loss 0.017004\n",
      "batch 5126: loss 0.121012\n",
      "batch 5127: loss 0.031349\n",
      "batch 5128: loss 0.013427\n",
      "batch 5129: loss 0.045670\n",
      "batch 5130: loss 0.039242\n",
      "batch 5131: loss 0.052216\n",
      "batch 5132: loss 0.008814\n",
      "batch 5133: loss 0.014038\n",
      "batch 5134: loss 0.060304\n",
      "batch 5135: loss 0.045661\n",
      "batch 5136: loss 0.079893\n",
      "batch 5137: loss 0.023841\n",
      "batch 5138: loss 0.042122\n",
      "batch 5139: loss 0.013218\n",
      "batch 5140: loss 0.113896\n",
      "batch 5141: loss 0.039489\n",
      "batch 5142: loss 0.158119\n",
      "batch 5143: loss 0.123366\n",
      "batch 5144: loss 0.076642\n",
      "batch 5145: loss 0.022639\n",
      "batch 5146: loss 0.012965\n",
      "batch 5147: loss 0.050285\n",
      "batch 5148: loss 0.112857\n",
      "batch 5149: loss 0.078731\n",
      "batch 5150: loss 0.071160\n",
      "batch 5151: loss 0.026914\n",
      "batch 5152: loss 0.053346\n",
      "batch 5153: loss 0.014382\n",
      "batch 5154: loss 0.035224\n",
      "batch 5155: loss 0.056829\n",
      "batch 5156: loss 0.007552\n",
      "batch 5157: loss 0.044755\n",
      "batch 5158: loss 0.015043\n",
      "batch 5159: loss 0.026816\n",
      "batch 5160: loss 0.099332\n",
      "batch 5161: loss 0.127328\n",
      "batch 5162: loss 0.008145\n",
      "batch 5163: loss 0.145245\n",
      "batch 5164: loss 0.021643\n",
      "batch 5165: loss 0.050790\n",
      "batch 5166: loss 0.180199\n",
      "batch 5167: loss 0.028515\n",
      "batch 5168: loss 0.063466\n",
      "batch 5169: loss 0.016467\n",
      "batch 5170: loss 0.015696\n",
      "batch 5171: loss 0.061191\n",
      "batch 5172: loss 0.040302\n",
      "batch 5173: loss 0.017797\n",
      "batch 5174: loss 0.053841\n",
      "batch 5175: loss 0.008009\n",
      "batch 5176: loss 0.034767\n",
      "batch 5177: loss 0.258875\n",
      "batch 5178: loss 0.038006\n",
      "batch 5179: loss 0.016300\n",
      "batch 5180: loss 0.067793\n",
      "batch 5181: loss 0.052247\n",
      "batch 5182: loss 0.026078\n",
      "batch 5183: loss 0.007022\n",
      "batch 5184: loss 0.033952\n",
      "batch 5185: loss 0.157690\n",
      "batch 5186: loss 0.010755\n",
      "batch 5187: loss 0.051563\n",
      "batch 5188: loss 0.061908\n",
      "batch 5189: loss 0.076133\n",
      "batch 5190: loss 0.008227\n",
      "batch 5191: loss 0.035417\n",
      "batch 5192: loss 0.068446\n",
      "batch 5193: loss 0.072263\n",
      "batch 5194: loss 0.046388\n",
      "batch 5195: loss 0.014753\n",
      "batch 5196: loss 0.023752\n",
      "batch 5197: loss 0.082473\n",
      "batch 5198: loss 0.075509\n",
      "batch 5199: loss 0.068450\n",
      "batch 5200: loss 0.042997\n",
      "batch 5201: loss 0.052250\n",
      "batch 5202: loss 0.106605\n",
      "batch 5203: loss 0.007883\n",
      "batch 5204: loss 0.029345\n",
      "batch 5205: loss 0.112854\n",
      "batch 5206: loss 0.120527\n",
      "batch 5207: loss 0.032825\n",
      "batch 5208: loss 0.137389\n",
      "batch 5209: loss 0.043723\n",
      "batch 5210: loss 0.021712\n",
      "batch 5211: loss 0.033438\n",
      "batch 5212: loss 0.048188\n",
      "batch 5213: loss 0.016113\n",
      "batch 5214: loss 0.041075\n",
      "batch 5215: loss 0.204633\n",
      "batch 5216: loss 0.008604\n",
      "batch 5217: loss 0.020262\n",
      "batch 5218: loss 0.107649\n",
      "batch 5219: loss 0.052796\n",
      "batch 5220: loss 0.030640\n",
      "batch 5221: loss 0.057925\n",
      "batch 5222: loss 0.027260\n",
      "batch 5223: loss 0.006218\n",
      "batch 5224: loss 0.070863\n",
      "batch 5225: loss 0.044092\n",
      "batch 5226: loss 0.016244\n",
      "batch 5227: loss 0.092508\n",
      "batch 5228: loss 0.020926\n",
      "batch 5229: loss 0.037865\n",
      "batch 5230: loss 0.021664\n",
      "batch 5231: loss 0.039370\n",
      "batch 5232: loss 0.013447\n",
      "batch 5233: loss 0.108634\n",
      "batch 5234: loss 0.181211\n",
      "batch 5235: loss 0.019521\n",
      "batch 5236: loss 0.014374\n",
      "batch 5237: loss 0.071384\n",
      "batch 5238: loss 0.070133\n",
      "batch 5239: loss 0.117264\n",
      "batch 5240: loss 0.056382\n",
      "batch 5241: loss 0.055706\n",
      "batch 5242: loss 0.093407\n",
      "batch 5243: loss 0.078827\n",
      "batch 5244: loss 0.027790\n",
      "batch 5245: loss 0.028575\n",
      "batch 5246: loss 0.104165\n",
      "batch 5247: loss 0.014587\n",
      "batch 5248: loss 0.022609\n",
      "batch 5249: loss 0.037476\n",
      "batch 5250: loss 0.008057\n",
      "batch 5251: loss 0.008422\n",
      "batch 5252: loss 0.007391\n",
      "batch 5253: loss 0.090758\n",
      "batch 5254: loss 0.049972\n",
      "batch 5255: loss 0.090852\n",
      "batch 5256: loss 0.021220\n",
      "batch 5257: loss 0.045401\n",
      "batch 5258: loss 0.012186\n",
      "batch 5259: loss 0.062311\n",
      "batch 5260: loss 0.109114\n",
      "batch 5261: loss 0.024781\n",
      "batch 5262: loss 0.031398\n",
      "batch 5263: loss 0.094951\n",
      "batch 5264: loss 0.025148\n",
      "batch 5265: loss 0.074932\n",
      "batch 5266: loss 0.028520\n",
      "batch 5267: loss 0.088949\n",
      "batch 5268: loss 0.019778\n",
      "batch 5269: loss 0.115067\n",
      "batch 5270: loss 0.038170\n",
      "batch 5271: loss 0.041959\n",
      "batch 5272: loss 0.071137\n",
      "batch 5273: loss 0.116419\n",
      "batch 5274: loss 0.086165\n",
      "batch 5275: loss 0.285075\n",
      "batch 5276: loss 0.074599\n",
      "batch 5277: loss 0.025323\n",
      "batch 5278: loss 0.140386\n",
      "batch 5279: loss 0.031106\n",
      "batch 5280: loss 0.002741\n",
      "batch 5281: loss 0.031586\n",
      "batch 5282: loss 0.097708\n",
      "batch 5283: loss 0.035794\n",
      "batch 5284: loss 0.091879\n",
      "batch 5285: loss 0.018005\n",
      "batch 5286: loss 0.079280\n",
      "batch 5287: loss 0.011020\n",
      "batch 5288: loss 0.023684\n",
      "batch 5289: loss 0.076000\n",
      "batch 5290: loss 0.015621\n",
      "batch 5291: loss 0.073337\n",
      "batch 5292: loss 0.019827\n",
      "batch 5293: loss 0.122570\n",
      "batch 5294: loss 0.031432\n",
      "batch 5295: loss 0.032926\n",
      "batch 5296: loss 0.016548\n",
      "batch 5297: loss 0.071308\n",
      "batch 5298: loss 0.028163\n",
      "batch 5299: loss 0.084648\n",
      "batch 5300: loss 0.027256\n",
      "batch 5301: loss 0.038654\n",
      "batch 5302: loss 0.039306\n",
      "batch 5303: loss 0.023472\n",
      "batch 5304: loss 0.008164\n",
      "batch 5305: loss 0.006584\n",
      "batch 5306: loss 0.021480\n",
      "batch 5307: loss 0.017572\n",
      "batch 5308: loss 0.010564\n",
      "batch 5309: loss 0.016716\n",
      "batch 5310: loss 0.039850\n",
      "batch 5311: loss 0.015024\n",
      "batch 5312: loss 0.113044\n",
      "batch 5313: loss 0.097295\n",
      "batch 5314: loss 0.045582\n",
      "batch 5315: loss 0.129347\n",
      "batch 5316: loss 0.021350\n",
      "batch 5317: loss 0.138255\n",
      "batch 5318: loss 0.056761\n",
      "batch 5319: loss 0.013668\n",
      "batch 5320: loss 0.040204\n",
      "batch 5321: loss 0.016238\n",
      "batch 5322: loss 0.050045\n",
      "batch 5323: loss 0.055677\n",
      "batch 5324: loss 0.030862\n",
      "batch 5325: loss 0.029780\n",
      "batch 5326: loss 0.064894\n",
      "batch 5327: loss 0.044588\n",
      "batch 5328: loss 0.137812\n",
      "batch 5329: loss 0.024035\n",
      "batch 5330: loss 0.060249\n",
      "batch 5331: loss 0.158774\n",
      "batch 5332: loss 0.069173\n",
      "batch 5333: loss 0.092010\n",
      "batch 5334: loss 0.016457\n",
      "batch 5335: loss 0.009953\n",
      "batch 5336: loss 0.037034\n",
      "batch 5337: loss 0.057166\n",
      "batch 5338: loss 0.008491\n",
      "batch 5339: loss 0.016997\n",
      "batch 5340: loss 0.064743\n",
      "batch 5341: loss 0.044515\n",
      "batch 5342: loss 0.025541\n",
      "batch 5343: loss 0.047960\n",
      "batch 5344: loss 0.034475\n",
      "batch 5345: loss 0.044411\n",
      "batch 5346: loss 0.026793\n",
      "batch 5347: loss 0.012850\n",
      "batch 5348: loss 0.044562\n",
      "batch 5349: loss 0.079723\n",
      "batch 5350: loss 0.009263\n",
      "batch 5351: loss 0.054045\n",
      "batch 5352: loss 0.078369\n",
      "batch 5353: loss 0.047996\n",
      "batch 5354: loss 0.020311\n",
      "batch 5355: loss 0.063255\n",
      "batch 5356: loss 0.032280\n",
      "batch 5357: loss 0.031376\n",
      "batch 5358: loss 0.009855\n",
      "batch 5359: loss 0.078338\n",
      "batch 5360: loss 0.005802\n",
      "batch 5361: loss 0.142664\n",
      "batch 5362: loss 0.029830\n",
      "batch 5363: loss 0.120379\n",
      "batch 5364: loss 0.049798\n",
      "batch 5365: loss 0.067319\n",
      "batch 5366: loss 0.025792\n",
      "batch 5367: loss 0.039793\n",
      "batch 5368: loss 0.022047\n",
      "batch 5369: loss 0.020115\n",
      "batch 5370: loss 0.042498\n",
      "batch 5371: loss 0.039744\n",
      "batch 5372: loss 0.018524\n",
      "batch 5373: loss 0.059744\n",
      "batch 5374: loss 0.176538\n",
      "batch 5375: loss 0.037727\n",
      "batch 5376: loss 0.026299\n",
      "batch 5377: loss 0.108593\n",
      "batch 5378: loss 0.068946\n",
      "batch 5379: loss 0.141062\n",
      "batch 5380: loss 0.113772\n",
      "batch 5381: loss 0.075297\n",
      "batch 5382: loss 0.081519\n",
      "batch 5383: loss 0.043228\n",
      "batch 5384: loss 0.032614\n",
      "batch 5385: loss 0.012006\n",
      "batch 5386: loss 0.023892\n",
      "batch 5387: loss 0.029806\n",
      "batch 5388: loss 0.031700\n",
      "batch 5389: loss 0.033809\n",
      "batch 5390: loss 0.012144\n",
      "batch 5391: loss 0.012712\n",
      "batch 5392: loss 0.081606\n",
      "batch 5393: loss 0.046991\n",
      "batch 5394: loss 0.148215\n",
      "batch 5395: loss 0.064011\n",
      "batch 5396: loss 0.046970\n",
      "batch 5397: loss 0.037967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5398: loss 0.054161\n",
      "batch 5399: loss 0.007547\n",
      "batch 5400: loss 0.006234\n",
      "batch 5401: loss 0.160426\n",
      "batch 5402: loss 0.032967\n",
      "batch 5403: loss 0.116467\n",
      "batch 5404: loss 0.042949\n",
      "batch 5405: loss 0.041698\n",
      "batch 5406: loss 0.026382\n",
      "batch 5407: loss 0.044358\n",
      "batch 5408: loss 0.073422\n",
      "batch 5409: loss 0.092524\n",
      "batch 5410: loss 0.055302\n",
      "batch 5411: loss 0.024991\n",
      "batch 5412: loss 0.223779\n",
      "batch 5413: loss 0.019264\n",
      "batch 5414: loss 0.387550\n",
      "batch 5415: loss 0.135067\n",
      "batch 5416: loss 0.013767\n",
      "batch 5417: loss 0.024681\n",
      "batch 5418: loss 0.162643\n",
      "batch 5419: loss 0.025067\n",
      "batch 5420: loss 0.025076\n",
      "batch 5421: loss 0.048527\n",
      "batch 5422: loss 0.019485\n",
      "batch 5423: loss 0.134592\n",
      "batch 5424: loss 0.052995\n",
      "batch 5425: loss 0.028899\n",
      "batch 5426: loss 0.006011\n",
      "batch 5427: loss 0.046829\n",
      "batch 5428: loss 0.040654\n",
      "batch 5429: loss 0.008383\n",
      "batch 5430: loss 0.060415\n",
      "batch 5431: loss 0.010276\n",
      "batch 5432: loss 0.042624\n",
      "batch 5433: loss 0.114477\n",
      "batch 5434: loss 0.049449\n",
      "batch 5435: loss 0.028644\n",
      "batch 5436: loss 0.109512\n",
      "batch 5437: loss 0.048653\n",
      "batch 5438: loss 0.015675\n",
      "batch 5439: loss 0.146595\n",
      "batch 5440: loss 0.018295\n",
      "batch 5441: loss 0.013363\n",
      "batch 5442: loss 0.020968\n",
      "batch 5443: loss 0.060847\n",
      "batch 5444: loss 0.047593\n",
      "batch 5445: loss 0.026083\n",
      "batch 5446: loss 0.094406\n",
      "batch 5447: loss 0.144764\n",
      "batch 5448: loss 0.132575\n",
      "batch 5449: loss 0.017424\n",
      "batch 5450: loss 0.022399\n",
      "batch 5451: loss 0.025048\n",
      "batch 5452: loss 0.045948\n",
      "batch 5453: loss 0.037886\n",
      "batch 5454: loss 0.050303\n",
      "batch 5455: loss 0.028973\n",
      "batch 5456: loss 0.053962\n",
      "batch 5457: loss 0.018273\n",
      "batch 5458: loss 0.036960\n",
      "batch 5459: loss 0.037785\n",
      "batch 5460: loss 0.010814\n",
      "batch 5461: loss 0.068571\n",
      "batch 5462: loss 0.128102\n",
      "batch 5463: loss 0.077454\n",
      "batch 5464: loss 0.244562\n",
      "batch 5465: loss 0.032331\n",
      "batch 5466: loss 0.104615\n",
      "batch 5467: loss 0.061818\n",
      "batch 5468: loss 0.019827\n",
      "batch 5469: loss 0.085391\n",
      "batch 5470: loss 0.016526\n",
      "batch 5471: loss 0.125992\n",
      "batch 5472: loss 0.040063\n",
      "batch 5473: loss 0.077113\n",
      "batch 5474: loss 0.030879\n",
      "batch 5475: loss 0.053459\n",
      "batch 5476: loss 0.027345\n",
      "batch 5477: loss 0.013075\n",
      "batch 5478: loss 0.024200\n",
      "batch 5479: loss 0.151997\n",
      "batch 5480: loss 0.040808\n",
      "batch 5481: loss 0.041033\n",
      "batch 5482: loss 0.047286\n",
      "batch 5483: loss 0.024868\n",
      "batch 5484: loss 0.052948\n",
      "batch 5485: loss 0.077527\n",
      "batch 5486: loss 0.125800\n",
      "batch 5487: loss 0.062449\n",
      "batch 5488: loss 0.052933\n",
      "batch 5489: loss 0.098354\n",
      "batch 5490: loss 0.024857\n",
      "batch 5491: loss 0.019616\n",
      "batch 5492: loss 0.045751\n",
      "batch 5493: loss 0.112686\n",
      "batch 5494: loss 0.044722\n",
      "batch 5495: loss 0.047496\n",
      "batch 5496: loss 0.144995\n",
      "batch 5497: loss 0.017923\n",
      "batch 5498: loss 0.030676\n",
      "batch 5499: loss 0.083003\n",
      "batch 5500: loss 0.122988\n",
      "batch 5501: loss 0.017771\n",
      "batch 5502: loss 0.049071\n",
      "batch 5503: loss 0.028676\n",
      "batch 5504: loss 0.030003\n",
      "batch 5505: loss 0.019131\n",
      "batch 5506: loss 0.035070\n",
      "batch 5507: loss 0.099992\n",
      "batch 5508: loss 0.019504\n",
      "batch 5509: loss 0.120865\n",
      "batch 5510: loss 0.051579\n",
      "batch 5511: loss 0.046772\n",
      "batch 5512: loss 0.010514\n",
      "batch 5513: loss 0.038471\n",
      "batch 5514: loss 0.023850\n",
      "batch 5515: loss 0.049399\n",
      "batch 5516: loss 0.085261\n",
      "batch 5517: loss 0.031866\n",
      "batch 5518: loss 0.063632\n",
      "batch 5519: loss 0.016271\n",
      "batch 5520: loss 0.026565\n",
      "batch 5521: loss 0.009412\n",
      "batch 5522: loss 0.024770\n",
      "batch 5523: loss 0.007299\n",
      "batch 5524: loss 0.024317\n",
      "batch 5525: loss 0.006234\n",
      "batch 5526: loss 0.085598\n",
      "batch 5527: loss 0.009493\n",
      "batch 5528: loss 0.095085\n",
      "batch 5529: loss 0.013591\n",
      "batch 5530: loss 0.014056\n",
      "batch 5531: loss 0.015890\n",
      "batch 5532: loss 0.070655\n",
      "batch 5533: loss 0.023678\n",
      "batch 5534: loss 0.026929\n",
      "batch 5535: loss 0.022142\n",
      "batch 5536: loss 0.093570\n",
      "batch 5537: loss 0.111071\n",
      "batch 5538: loss 0.059557\n",
      "batch 5539: loss 0.072768\n",
      "batch 5540: loss 0.015500\n",
      "batch 5541: loss 0.172759\n",
      "batch 5542: loss 0.059080\n",
      "batch 5543: loss 0.113721\n",
      "batch 5544: loss 0.012696\n",
      "batch 5545: loss 0.015437\n",
      "batch 5546: loss 0.045414\n",
      "batch 5547: loss 0.055943\n",
      "batch 5548: loss 0.141321\n",
      "batch 5549: loss 0.010841\n",
      "batch 5550: loss 0.125426\n",
      "batch 5551: loss 0.013407\n",
      "batch 5552: loss 0.026462\n",
      "batch 5553: loss 0.102084\n",
      "batch 5554: loss 0.072141\n",
      "batch 5555: loss 0.045267\n",
      "batch 5556: loss 0.034824\n",
      "batch 5557: loss 0.036985\n",
      "batch 5558: loss 0.335114\n",
      "batch 5559: loss 0.015081\n",
      "batch 5560: loss 0.006800\n",
      "batch 5561: loss 0.070518\n",
      "batch 5562: loss 0.006976\n",
      "batch 5563: loss 0.031759\n",
      "batch 5564: loss 0.089326\n",
      "batch 5565: loss 0.021372\n",
      "batch 5566: loss 0.052953\n",
      "batch 5567: loss 0.010808\n",
      "batch 5568: loss 0.065616\n",
      "batch 5569: loss 0.037495\n",
      "batch 5570: loss 0.045353\n",
      "batch 5571: loss 0.127447\n",
      "batch 5572: loss 0.049056\n",
      "batch 5573: loss 0.012362\n",
      "batch 5574: loss 0.008779\n",
      "batch 5575: loss 0.020758\n",
      "batch 5576: loss 0.018791\n",
      "batch 5577: loss 0.057146\n",
      "batch 5578: loss 0.024034\n",
      "batch 5579: loss 0.037592\n",
      "batch 5580: loss 0.013465\n",
      "batch 5581: loss 0.015925\n",
      "batch 5582: loss 0.012673\n",
      "batch 5583: loss 0.023566\n",
      "batch 5584: loss 0.116111\n",
      "batch 5585: loss 0.099433\n",
      "batch 5586: loss 0.064540\n",
      "batch 5587: loss 0.072597\n",
      "batch 5588: loss 0.085588\n",
      "batch 5589: loss 0.048064\n",
      "batch 5590: loss 0.035258\n",
      "batch 5591: loss 0.008885\n",
      "batch 5592: loss 0.048913\n",
      "batch 5593: loss 0.027277\n",
      "batch 5594: loss 0.041216\n",
      "batch 5595: loss 0.279567\n",
      "batch 5596: loss 0.017248\n",
      "batch 5597: loss 0.034107\n",
      "batch 5598: loss 0.028406\n",
      "batch 5599: loss 0.041400\n",
      "batch 5600: loss 0.049599\n",
      "batch 5601: loss 0.068374\n",
      "batch 5602: loss 0.033368\n",
      "batch 5603: loss 0.052490\n",
      "batch 5604: loss 0.054554\n",
      "batch 5605: loss 0.017925\n",
      "batch 5606: loss 0.076806\n",
      "batch 5607: loss 0.002421\n",
      "batch 5608: loss 0.021977\n",
      "batch 5609: loss 0.036204\n",
      "batch 5610: loss 0.021811\n",
      "batch 5611: loss 0.078839\n",
      "batch 5612: loss 0.028167\n",
      "batch 5613: loss 0.066965\n",
      "batch 5614: loss 0.191144\n",
      "batch 5615: loss 0.021141\n",
      "batch 5616: loss 0.005425\n",
      "batch 5617: loss 0.053590\n",
      "batch 5618: loss 0.096327\n",
      "batch 5619: loss 0.057145\n",
      "batch 5620: loss 0.020267\n",
      "batch 5621: loss 0.012379\n",
      "batch 5622: loss 0.009368\n",
      "batch 5623: loss 0.143747\n",
      "batch 5624: loss 0.041388\n",
      "batch 5625: loss 0.144532\n",
      "batch 5626: loss 0.024011\n",
      "batch 5627: loss 0.157702\n",
      "batch 5628: loss 0.087743\n",
      "batch 5629: loss 0.024537\n",
      "batch 5630: loss 0.122844\n",
      "batch 5631: loss 0.041613\n",
      "batch 5632: loss 0.032862\n",
      "batch 5633: loss 0.020117\n",
      "batch 5634: loss 0.046044\n",
      "batch 5635: loss 0.124791\n",
      "batch 5636: loss 0.015364\n",
      "batch 5637: loss 0.008285\n",
      "batch 5638: loss 0.026108\n",
      "batch 5639: loss 0.109588\n",
      "batch 5640: loss 0.069666\n",
      "batch 5641: loss 0.021627\n",
      "batch 5642: loss 0.013530\n",
      "batch 5643: loss 0.029450\n",
      "batch 5644: loss 0.014631\n",
      "batch 5645: loss 0.016549\n",
      "batch 5646: loss 0.030472\n",
      "batch 5647: loss 0.014725\n",
      "batch 5648: loss 0.069043\n",
      "batch 5649: loss 0.030512\n",
      "batch 5650: loss 0.057180\n",
      "batch 5651: loss 0.083611\n",
      "batch 5652: loss 0.041653\n",
      "batch 5653: loss 0.034380\n",
      "batch 5654: loss 0.163346\n",
      "batch 5655: loss 0.017650\n",
      "batch 5656: loss 0.016292\n",
      "batch 5657: loss 0.057768\n",
      "batch 5658: loss 0.009196\n",
      "batch 5659: loss 0.004616\n",
      "batch 5660: loss 0.093888\n",
      "batch 5661: loss 0.090937\n",
      "batch 5662: loss 0.055106\n",
      "batch 5663: loss 0.004707\n",
      "batch 5664: loss 0.057812\n",
      "batch 5665: loss 0.045574\n",
      "batch 5666: loss 0.062600\n",
      "batch 5667: loss 0.095572\n",
      "batch 5668: loss 0.071357\n",
      "batch 5669: loss 0.049932\n",
      "batch 5670: loss 0.144129\n",
      "batch 5671: loss 0.013531\n",
      "batch 5672: loss 0.139006\n",
      "batch 5673: loss 0.018976\n",
      "batch 5674: loss 0.022661\n",
      "batch 5675: loss 0.063429\n",
      "batch 5676: loss 0.011888\n",
      "batch 5677: loss 0.045723\n",
      "batch 5678: loss 0.010452\n",
      "batch 5679: loss 0.149795\n",
      "batch 5680: loss 0.051377\n",
      "batch 5681: loss 0.031023\n",
      "batch 5682: loss 0.028822\n",
      "batch 5683: loss 0.080504\n",
      "batch 5684: loss 0.007643\n",
      "batch 5685: loss 0.042693\n",
      "batch 5686: loss 0.010044\n",
      "batch 5687: loss 0.061538\n",
      "batch 5688: loss 0.021258\n",
      "batch 5689: loss 0.105404\n",
      "batch 5690: loss 0.044688\n",
      "batch 5691: loss 0.008612\n",
      "batch 5692: loss 0.029852\n",
      "batch 5693: loss 0.151365\n",
      "batch 5694: loss 0.036996\n",
      "batch 5695: loss 0.189914\n",
      "batch 5696: loss 0.070401\n",
      "batch 5697: loss 0.057502\n",
      "batch 5698: loss 0.009877\n",
      "batch 5699: loss 0.101847\n",
      "batch 5700: loss 0.027999\n",
      "batch 5701: loss 0.036374\n",
      "batch 5702: loss 0.024746\n",
      "batch 5703: loss 0.010775\n",
      "batch 5704: loss 0.027565\n",
      "batch 5705: loss 0.087438\n",
      "batch 5706: loss 0.126485\n",
      "batch 5707: loss 0.074371\n",
      "batch 5708: loss 0.054039\n",
      "batch 5709: loss 0.015804\n",
      "batch 5710: loss 0.016239\n",
      "batch 5711: loss 0.048072\n",
      "batch 5712: loss 0.083681\n",
      "batch 5713: loss 0.015499\n",
      "batch 5714: loss 0.060153\n",
      "batch 5715: loss 0.008477\n",
      "batch 5716: loss 0.020343\n",
      "batch 5717: loss 0.066658\n",
      "batch 5718: loss 0.128912\n",
      "batch 5719: loss 0.020553\n",
      "batch 5720: loss 0.106431\n",
      "batch 5721: loss 0.106772\n",
      "batch 5722: loss 0.046387\n",
      "batch 5723: loss 0.018964\n",
      "batch 5724: loss 0.051522\n",
      "batch 5725: loss 0.043211\n",
      "batch 5726: loss 0.009693\n",
      "batch 5727: loss 0.049036\n",
      "batch 5728: loss 0.055210\n",
      "batch 5729: loss 0.036725\n",
      "batch 5730: loss 0.044698\n",
      "batch 5731: loss 0.012958\n",
      "batch 5732: loss 0.025310\n",
      "batch 5733: loss 0.016908\n",
      "batch 5734: loss 0.073435\n",
      "batch 5735: loss 0.032735\n",
      "batch 5736: loss 0.029647\n",
      "batch 5737: loss 0.041602\n",
      "batch 5738: loss 0.031416\n",
      "batch 5739: loss 0.040388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5740: loss 0.039588\n",
      "batch 5741: loss 0.013281\n",
      "batch 5742: loss 0.055334\n",
      "batch 5743: loss 0.097276\n",
      "batch 5744: loss 0.071569\n",
      "batch 5745: loss 0.017326\n",
      "batch 5746: loss 0.003502\n",
      "batch 5747: loss 0.027420\n",
      "batch 5748: loss 0.026941\n",
      "batch 5749: loss 0.036586\n",
      "batch 5750: loss 0.018612\n",
      "batch 5751: loss 0.072531\n",
      "batch 5752: loss 0.009556\n",
      "batch 5753: loss 0.026269\n",
      "batch 5754: loss 0.021206\n",
      "batch 5755: loss 0.063031\n",
      "batch 5756: loss 0.051354\n",
      "batch 5757: loss 0.066381\n",
      "batch 5758: loss 0.140855\n",
      "batch 5759: loss 0.023639\n",
      "batch 5760: loss 0.016897\n",
      "batch 5761: loss 0.009292\n",
      "batch 5762: loss 0.005251\n",
      "batch 5763: loss 0.018382\n",
      "batch 5764: loss 0.093803\n",
      "batch 5765: loss 0.028754\n",
      "batch 5766: loss 0.019885\n",
      "batch 5767: loss 0.019958\n",
      "batch 5768: loss 0.036867\n",
      "batch 5769: loss 0.089943\n",
      "batch 5770: loss 0.098732\n",
      "batch 5771: loss 0.036460\n",
      "batch 5772: loss 0.104822\n",
      "batch 5773: loss 0.047763\n",
      "batch 5774: loss 0.008732\n",
      "batch 5775: loss 0.113346\n",
      "batch 5776: loss 0.126947\n",
      "batch 5777: loss 0.019885\n",
      "batch 5778: loss 0.026153\n",
      "batch 5779: loss 0.057791\n",
      "batch 5780: loss 0.105530\n",
      "batch 5781: loss 0.054225\n",
      "batch 5782: loss 0.066219\n",
      "batch 5783: loss 0.076601\n",
      "batch 5784: loss 0.027029\n",
      "batch 5785: loss 0.023044\n",
      "batch 5786: loss 0.022131\n",
      "batch 5787: loss 0.069248\n",
      "batch 5788: loss 0.151636\n",
      "batch 5789: loss 0.014578\n",
      "batch 5790: loss 0.006888\n",
      "batch 5791: loss 0.072875\n",
      "batch 5792: loss 0.035272\n",
      "batch 5793: loss 0.012224\n",
      "batch 5794: loss 0.040670\n",
      "batch 5795: loss 0.083149\n",
      "batch 5796: loss 0.029332\n",
      "batch 5797: loss 0.031205\n",
      "batch 5798: loss 0.036516\n",
      "batch 5799: loss 0.005426\n",
      "batch 5800: loss 0.059757\n",
      "batch 5801: loss 0.020685\n",
      "batch 5802: loss 0.057611\n",
      "batch 5803: loss 0.118784\n",
      "batch 5804: loss 0.080171\n",
      "batch 5805: loss 0.054583\n",
      "batch 5806: loss 0.044328\n",
      "batch 5807: loss 0.010563\n",
      "batch 5808: loss 0.042481\n",
      "batch 5809: loss 0.003572\n",
      "batch 5810: loss 0.012182\n",
      "batch 5811: loss 0.034246\n",
      "batch 5812: loss 0.012606\n",
      "batch 5813: loss 0.018044\n",
      "batch 5814: loss 0.129921\n",
      "batch 5815: loss 0.055906\n",
      "batch 5816: loss 0.025477\n",
      "batch 5817: loss 0.032957\n",
      "batch 5818: loss 0.030993\n",
      "batch 5819: loss 0.017554\n",
      "batch 5820: loss 0.080042\n",
      "batch 5821: loss 0.081642\n",
      "batch 5822: loss 0.044006\n",
      "batch 5823: loss 0.034977\n",
      "batch 5824: loss 0.065259\n",
      "batch 5825: loss 0.012801\n",
      "batch 5826: loss 0.024578\n",
      "batch 5827: loss 0.017696\n",
      "batch 5828: loss 0.107342\n",
      "batch 5829: loss 0.030335\n",
      "batch 5830: loss 0.173664\n",
      "batch 5831: loss 0.012976\n",
      "batch 5832: loss 0.021560\n",
      "batch 5833: loss 0.020185\n",
      "batch 5834: loss 0.027376\n",
      "batch 5835: loss 0.022900\n",
      "batch 5836: loss 0.040722\n",
      "batch 5837: loss 0.348185\n",
      "batch 5838: loss 0.008252\n",
      "batch 5839: loss 0.118116\n",
      "batch 5840: loss 0.013334\n",
      "batch 5841: loss 0.017300\n",
      "batch 5842: loss 0.044932\n",
      "batch 5843: loss 0.079755\n",
      "batch 5844: loss 0.013439\n",
      "batch 5845: loss 0.104976\n",
      "batch 5846: loss 0.012037\n",
      "batch 5847: loss 0.118409\n",
      "batch 5848: loss 0.004916\n",
      "batch 5849: loss 0.022086\n",
      "batch 5850: loss 0.028969\n",
      "batch 5851: loss 0.078440\n",
      "batch 5852: loss 0.021985\n",
      "batch 5853: loss 0.008475\n",
      "batch 5854: loss 0.076035\n",
      "batch 5855: loss 0.050721\n",
      "batch 5856: loss 0.011187\n",
      "batch 5857: loss 0.015442\n",
      "batch 5858: loss 0.039215\n",
      "batch 5859: loss 0.009764\n",
      "batch 5860: loss 0.087288\n",
      "batch 5861: loss 0.043854\n",
      "batch 5862: loss 0.008793\n",
      "batch 5863: loss 0.092280\n",
      "batch 5864: loss 0.048395\n",
      "batch 5865: loss 0.088610\n",
      "batch 5866: loss 0.033717\n",
      "batch 5867: loss 0.073849\n",
      "batch 5868: loss 0.051688\n",
      "batch 5869: loss 0.027651\n",
      "batch 5870: loss 0.067358\n",
      "batch 5871: loss 0.010002\n",
      "batch 5872: loss 0.186400\n",
      "batch 5873: loss 0.032749\n",
      "batch 5874: loss 0.092050\n",
      "batch 5875: loss 0.040270\n",
      "batch 5876: loss 0.010499\n",
      "batch 5877: loss 0.064783\n",
      "batch 5878: loss 0.121062\n",
      "batch 5879: loss 0.154182\n",
      "batch 5880: loss 0.020454\n",
      "batch 5881: loss 0.066420\n",
      "batch 5882: loss 0.084432\n",
      "batch 5883: loss 0.089883\n",
      "batch 5884: loss 0.039453\n",
      "batch 5885: loss 0.026230\n",
      "batch 5886: loss 0.016847\n",
      "batch 5887: loss 0.027504\n",
      "batch 5888: loss 0.015630\n",
      "batch 5889: loss 0.025657\n",
      "batch 5890: loss 0.037582\n",
      "batch 5891: loss 0.068635\n",
      "batch 5892: loss 0.041139\n",
      "batch 5893: loss 0.059587\n",
      "batch 5894: loss 0.059485\n",
      "batch 5895: loss 0.044649\n",
      "batch 5896: loss 0.071384\n",
      "batch 5897: loss 0.074662\n",
      "batch 5898: loss 0.038491\n",
      "batch 5899: loss 0.035830\n",
      "batch 5900: loss 0.029357\n",
      "batch 5901: loss 0.097372\n",
      "batch 5902: loss 0.053891\n",
      "batch 5903: loss 0.013667\n",
      "batch 5904: loss 0.063406\n",
      "batch 5905: loss 0.028912\n",
      "batch 5906: loss 0.007485\n",
      "batch 5907: loss 0.081723\n",
      "batch 5908: loss 0.023882\n",
      "batch 5909: loss 0.033160\n",
      "batch 5910: loss 0.010430\n",
      "batch 5911: loss 0.023739\n",
      "batch 5912: loss 0.024429\n",
      "batch 5913: loss 0.062201\n",
      "batch 5914: loss 0.053809\n",
      "batch 5915: loss 0.006608\n",
      "batch 5916: loss 0.074658\n",
      "batch 5917: loss 0.006600\n",
      "batch 5918: loss 0.021632\n",
      "batch 5919: loss 0.098369\n",
      "batch 5920: loss 0.099631\n",
      "batch 5921: loss 0.156771\n",
      "batch 5922: loss 0.018193\n",
      "batch 5923: loss 0.021239\n",
      "batch 5924: loss 0.003201\n",
      "batch 5925: loss 0.013046\n",
      "batch 5926: loss 0.036122\n",
      "batch 5927: loss 0.098589\n",
      "batch 5928: loss 0.042391\n",
      "batch 5929: loss 0.024115\n",
      "batch 5930: loss 0.047796\n",
      "batch 5931: loss 0.065202\n",
      "batch 5932: loss 0.095012\n",
      "batch 5933: loss 0.067121\n",
      "batch 5934: loss 0.021445\n",
      "batch 5935: loss 0.066227\n",
      "batch 5936: loss 0.201691\n",
      "batch 5937: loss 0.017070\n",
      "batch 5938: loss 0.018009\n",
      "batch 5939: loss 0.067829\n",
      "batch 5940: loss 0.004089\n",
      "batch 5941: loss 0.093986\n",
      "batch 5942: loss 0.019672\n",
      "batch 5943: loss 0.010820\n",
      "batch 5944: loss 0.171793\n",
      "batch 5945: loss 0.009072\n",
      "batch 5946: loss 0.011369\n",
      "batch 5947: loss 0.033328\n",
      "batch 5948: loss 0.023648\n",
      "batch 5949: loss 0.024522\n",
      "batch 5950: loss 0.036005\n",
      "batch 5951: loss 0.049211\n",
      "batch 5952: loss 0.019511\n",
      "batch 5953: loss 0.037799\n",
      "batch 5954: loss 0.063215\n",
      "batch 5955: loss 0.047914\n",
      "batch 5956: loss 0.099545\n",
      "batch 5957: loss 0.021343\n",
      "batch 5958: loss 0.017691\n",
      "batch 5959: loss 0.005320\n",
      "batch 5960: loss 0.060487\n",
      "batch 5961: loss 0.007344\n",
      "batch 5962: loss 0.052408\n",
      "batch 5963: loss 0.032182\n",
      "batch 5964: loss 0.054073\n",
      "batch 5965: loss 0.012890\n",
      "batch 5966: loss 0.082657\n",
      "batch 5967: loss 0.049334\n",
      "batch 5968: loss 0.021574\n",
      "batch 5969: loss 0.004924\n",
      "batch 5970: loss 0.008399\n",
      "batch 5971: loss 0.117848\n",
      "batch 5972: loss 0.054117\n",
      "batch 5973: loss 0.039170\n",
      "batch 5974: loss 0.062234\n",
      "batch 5975: loss 0.082125\n",
      "batch 5976: loss 0.032777\n",
      "batch 5977: loss 0.006099\n",
      "batch 5978: loss 0.062374\n",
      "batch 5979: loss 0.027063\n",
      "batch 5980: loss 0.025947\n",
      "batch 5981: loss 0.035080\n",
      "batch 5982: loss 0.008119\n",
      "batch 5983: loss 0.014522\n",
      "batch 5984: loss 0.030778\n",
      "batch 5985: loss 0.014907\n",
      "batch 5986: loss 0.014731\n",
      "batch 5987: loss 0.014151\n",
      "batch 5988: loss 0.104898\n",
      "batch 5989: loss 0.128062\n",
      "batch 5990: loss 0.092359\n",
      "batch 5991: loss 0.024250\n",
      "batch 5992: loss 0.038023\n",
      "batch 5993: loss 0.027688\n",
      "batch 5994: loss 0.013625\n",
      "batch 5995: loss 0.015889\n",
      "batch 5996: loss 0.012296\n",
      "batch 5997: loss 0.011263\n",
      "batch 5998: loss 0.014109\n",
      "batch 5999: loss 0.075544\n"
     ]
    }
   ],
   "source": [
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型评估  tf.keras.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is: 0.972900\n"
     ]
    }
   ],
   "source": [
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model.predict(data_loader.test_data[start_index: end_index])\n",
    "    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index],y_pred=y_pred)\n",
    "print(\"test accuracy is: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积神经网络 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.connv1 = tf.keras.layers.Conv2D(\n",
    "            filters=32,             # 卷积层神经元（卷积核）数目\n",
    "            kernel_size=[5, 5],     # 感受野大小\n",
    "            padding='same',         # padding策略（vaild 或 same）\n",
    "            activation=tf.nn.relu   # 激活函数\n",
    "        )\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[5, 5],\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.flatten = tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,))\n",
    "        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)                  # [batch_size, 28, 28, 32]\n",
    "        x = self.pool1(x)                       # [batch_size, 14, 14, 32]\n",
    "        x = self.conv2(x)                       # [batch_size, 14, 14, 64]\n",
    "        x = self.pool2(x)                       # [batch_size, 7, 7, 64]\n",
    "        x = self.flatten(x)                     # [batch_size, 7 * 7 * 64]\n",
    "        x = self.dense1(x)                      # [batch_size, 1024]\n",
    "        x = self.dense2(x)                      # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "data_loader = MNISTLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 2.396172\n",
      "batch 1: loss 2.301820\n",
      "batch 2: loss 2.206160\n",
      "batch 3: loss 2.165649\n",
      "batch 4: loss 2.141267\n",
      "batch 5: loss 2.086282\n",
      "batch 6: loss 1.957843\n",
      "batch 7: loss 1.949489\n",
      "batch 8: loss 1.818043\n",
      "batch 9: loss 1.704629\n",
      "batch 10: loss 1.711488\n",
      "batch 11: loss 1.727079\n",
      "batch 12: loss 1.677685\n",
      "batch 13: loss 1.547471\n",
      "batch 14: loss 1.432473\n",
      "batch 15: loss 1.546335\n",
      "batch 16: loss 1.529451\n",
      "batch 17: loss 1.452398\n",
      "batch 18: loss 1.457676\n",
      "batch 19: loss 1.323920\n",
      "batch 20: loss 1.156933\n",
      "batch 21: loss 1.253210\n",
      "batch 22: loss 1.163003\n",
      "batch 23: loss 1.329647\n",
      "batch 24: loss 1.223069\n",
      "batch 25: loss 1.077659\n",
      "batch 26: loss 1.068201\n",
      "batch 27: loss 1.015373\n",
      "batch 28: loss 1.052594\n",
      "batch 29: loss 1.028634\n",
      "batch 30: loss 0.971218\n",
      "batch 31: loss 0.986218\n",
      "batch 32: loss 0.970325\n",
      "batch 33: loss 0.892468\n",
      "batch 34: loss 0.880930\n",
      "batch 35: loss 0.805289\n",
      "batch 36: loss 0.876451\n",
      "batch 37: loss 0.856156\n",
      "batch 38: loss 0.920523\n",
      "batch 39: loss 0.928826\n",
      "batch 40: loss 0.807605\n",
      "batch 41: loss 0.598919\n",
      "batch 42: loss 0.750415\n",
      "batch 43: loss 0.760216\n",
      "batch 44: loss 0.881324\n",
      "batch 45: loss 0.818220\n",
      "batch 46: loss 0.538166\n",
      "batch 47: loss 0.623387\n",
      "batch 48: loss 0.707098\n",
      "batch 49: loss 0.710437\n",
      "batch 50: loss 0.639578\n",
      "batch 51: loss 0.594888\n",
      "batch 52: loss 0.618722\n",
      "batch 53: loss 0.576610\n",
      "batch 54: loss 0.583995\n",
      "batch 55: loss 0.768467\n",
      "batch 56: loss 0.538231\n",
      "batch 57: loss 0.569469\n",
      "batch 58: loss 0.772293\n",
      "batch 59: loss 0.578213\n",
      "batch 60: loss 0.565652\n",
      "batch 61: loss 0.477029\n",
      "batch 62: loss 0.653772\n",
      "batch 63: loss 0.733154\n",
      "batch 64: loss 0.699445\n",
      "batch 65: loss 0.746436\n",
      "batch 66: loss 0.481386\n",
      "batch 67: loss 0.426413\n",
      "batch 68: loss 0.422492\n",
      "batch 69: loss 0.627227\n",
      "batch 70: loss 0.510049\n",
      "batch 71: loss 0.369542\n",
      "batch 72: loss 0.575024\n",
      "batch 73: loss 0.593976\n",
      "batch 74: loss 0.699829\n",
      "batch 75: loss 0.420581\n",
      "batch 76: loss 0.578011\n",
      "batch 77: loss 0.511461\n",
      "batch 78: loss 0.514989\n",
      "batch 79: loss 0.640332\n",
      "batch 80: loss 0.511752\n",
      "batch 81: loss 0.671655\n",
      "batch 82: loss 0.430377\n",
      "batch 83: loss 0.685545\n",
      "batch 84: loss 0.506982\n",
      "batch 85: loss 0.435223\n",
      "batch 86: loss 0.587922\n",
      "batch 87: loss 0.573551\n",
      "batch 88: loss 0.602517\n",
      "batch 89: loss 0.385605\n",
      "batch 90: loss 0.552945\n",
      "batch 91: loss 0.476630\n",
      "batch 92: loss 0.332186\n",
      "batch 93: loss 0.406219\n",
      "batch 94: loss 0.417250\n",
      "batch 95: loss 0.298095\n",
      "batch 96: loss 0.354988\n",
      "batch 97: loss 0.393435\n",
      "batch 98: loss 0.404743\n",
      "batch 99: loss 0.435283\n",
      "batch 100: loss 0.517625\n",
      "batch 101: loss 0.335680\n",
      "batch 102: loss 0.436815\n",
      "batch 103: loss 0.388490\n",
      "batch 104: loss 0.651666\n",
      "batch 105: loss 0.384504\n",
      "batch 106: loss 0.417985\n",
      "batch 107: loss 0.456996\n",
      "batch 108: loss 0.655543\n",
      "batch 109: loss 0.354791\n",
      "batch 110: loss 0.299797\n",
      "batch 111: loss 0.462232\n",
      "batch 112: loss 0.359669\n",
      "batch 113: loss 0.274793\n",
      "batch 114: loss 0.422142\n",
      "batch 115: loss 0.270521\n",
      "batch 116: loss 0.336723\n",
      "batch 117: loss 0.407524\n",
      "batch 118: loss 0.387774\n",
      "batch 119: loss 0.430601\n",
      "batch 120: loss 0.359729\n",
      "batch 121: loss 0.710712\n",
      "batch 122: loss 0.426216\n",
      "batch 123: loss 0.442875\n",
      "batch 124: loss 0.356680\n",
      "batch 125: loss 0.282698\n",
      "batch 126: loss 0.413269\n",
      "batch 127: loss 0.524163\n",
      "batch 128: loss 0.379392\n",
      "batch 129: loss 0.627145\n",
      "batch 130: loss 0.510695\n",
      "batch 131: loss 0.404532\n",
      "batch 132: loss 0.413272\n",
      "batch 133: loss 0.429665\n",
      "batch 134: loss 0.269818\n",
      "batch 135: loss 0.247245\n",
      "batch 136: loss 0.273828\n",
      "batch 137: loss 0.516069\n",
      "batch 138: loss 0.281420\n",
      "batch 139: loss 0.210872\n",
      "batch 140: loss 0.500382\n",
      "batch 141: loss 0.401217\n",
      "batch 142: loss 0.309109\n",
      "batch 143: loss 0.365852\n",
      "batch 144: loss 0.500959\n",
      "batch 145: loss 0.356960\n",
      "batch 146: loss 0.322176\n",
      "batch 147: loss 0.292056\n",
      "batch 148: loss 0.420881\n",
      "batch 149: loss 0.363967\n",
      "batch 150: loss 0.373895\n",
      "batch 151: loss 0.450176\n",
      "batch 152: loss 0.506811\n",
      "batch 153: loss 0.320346\n",
      "batch 154: loss 0.407116\n",
      "batch 155: loss 0.376640\n",
      "batch 156: loss 0.386174\n",
      "batch 157: loss 0.504531\n",
      "batch 158: loss 0.439946\n",
      "batch 159: loss 0.362640\n",
      "batch 160: loss 0.520761\n",
      "batch 161: loss 0.585442\n",
      "batch 162: loss 0.216617\n",
      "batch 163: loss 0.467084\n",
      "batch 164: loss 0.322681\n",
      "batch 165: loss 0.439149\n",
      "batch 166: loss 0.422111\n",
      "batch 167: loss 0.436620\n",
      "batch 168: loss 0.298980\n",
      "batch 169: loss 0.278135\n",
      "batch 170: loss 0.432246\n",
      "batch 171: loss 0.518517\n",
      "batch 172: loss 0.278295\n",
      "batch 173: loss 0.555209\n",
      "batch 174: loss 0.221935\n",
      "batch 175: loss 0.344980\n",
      "batch 176: loss 0.244762\n",
      "batch 177: loss 0.481714\n",
      "batch 178: loss 0.316403\n",
      "batch 179: loss 0.524384\n",
      "batch 180: loss 0.604779\n",
      "batch 181: loss 0.179357\n",
      "batch 182: loss 0.436520\n",
      "batch 183: loss 0.391960\n",
      "batch 184: loss 0.212732\n",
      "batch 185: loss 0.353532\n",
      "batch 186: loss 0.200752\n",
      "batch 187: loss 0.235641\n",
      "batch 188: loss 0.232057\n",
      "batch 189: loss 0.409329\n",
      "batch 190: loss 0.363092\n",
      "batch 191: loss 0.430063\n",
      "batch 192: loss 0.331828\n",
      "batch 193: loss 0.316735\n",
      "batch 194: loss 0.291392\n",
      "batch 195: loss 0.252800\n",
      "batch 196: loss 0.350846\n",
      "batch 197: loss 0.252756\n",
      "batch 198: loss 0.201231\n",
      "batch 199: loss 0.331250\n",
      "batch 200: loss 0.352833\n",
      "batch 201: loss 0.329306\n",
      "batch 202: loss 0.635709\n",
      "batch 203: loss 0.257135\n",
      "batch 204: loss 0.132608\n",
      "batch 205: loss 0.263053\n",
      "batch 206: loss 0.467698\n",
      "batch 207: loss 0.347899\n",
      "batch 208: loss 0.340978\n",
      "batch 209: loss 0.259852\n",
      "batch 210: loss 0.166018\n",
      "batch 211: loss 0.390114\n",
      "batch 212: loss 0.247342\n",
      "batch 213: loss 0.358877\n",
      "batch 214: loss 0.321389\n",
      "batch 215: loss 0.323406\n",
      "batch 216: loss 0.324027\n",
      "batch 217: loss 0.324455\n",
      "batch 218: loss 0.293947\n",
      "batch 219: loss 0.267032\n",
      "batch 220: loss 0.414761\n",
      "batch 221: loss 0.226865\n",
      "batch 222: loss 0.296278\n",
      "batch 223: loss 0.339830\n",
      "batch 224: loss 0.383459\n",
      "batch 225: loss 0.156240\n",
      "batch 226: loss 0.247641\n",
      "batch 227: loss 0.289314\n",
      "batch 228: loss 0.376908\n",
      "batch 229: loss 0.441211\n",
      "batch 230: loss 0.343163\n",
      "batch 231: loss 0.315576\n",
      "batch 232: loss 0.308498\n",
      "batch 233: loss 0.396308\n",
      "batch 234: loss 0.195428\n",
      "batch 235: loss 0.351874\n",
      "batch 236: loss 0.452016\n",
      "batch 237: loss 0.217713\n",
      "batch 238: loss 0.268614\n",
      "batch 239: loss 0.295094\n",
      "batch 240: loss 0.261599\n",
      "batch 241: loss 0.616542\n",
      "batch 242: loss 0.283995\n",
      "batch 243: loss 0.309216\n",
      "batch 244: loss 0.480846\n",
      "batch 245: loss 0.239266\n",
      "batch 246: loss 0.243921\n",
      "batch 247: loss 0.664860\n",
      "batch 248: loss 0.398693\n",
      "batch 249: loss 0.507066\n",
      "batch 250: loss 0.334573\n",
      "batch 251: loss 0.462493\n",
      "batch 252: loss 0.406023\n",
      "batch 253: loss 0.347392\n",
      "batch 254: loss 0.181478\n",
      "batch 255: loss 0.411048\n",
      "batch 256: loss 0.271772\n",
      "batch 257: loss 0.299003\n",
      "batch 258: loss 0.272768\n",
      "batch 259: loss 0.303009\n",
      "batch 260: loss 0.490036\n",
      "batch 261: loss 0.102378\n",
      "batch 262: loss 0.337086\n",
      "batch 263: loss 0.330986\n",
      "batch 264: loss 0.337957\n",
      "batch 265: loss 0.325687\n",
      "batch 266: loss 0.257918\n",
      "batch 267: loss 0.499901\n",
      "batch 268: loss 0.241947\n",
      "batch 269: loss 0.352521\n",
      "batch 270: loss 0.437339\n",
      "batch 271: loss 0.356571\n",
      "batch 272: loss 0.200989\n",
      "batch 273: loss 0.500281\n",
      "batch 274: loss 0.128323\n",
      "batch 275: loss 0.270128\n",
      "batch 276: loss 0.359916\n",
      "batch 277: loss 0.307645\n",
      "batch 278: loss 0.345253\n",
      "batch 279: loss 0.373365\n",
      "batch 280: loss 0.449266\n",
      "batch 281: loss 0.362554\n",
      "batch 282: loss 0.334568\n",
      "batch 283: loss 0.194182\n",
      "batch 284: loss 0.335650\n",
      "batch 285: loss 0.361081\n",
      "batch 286: loss 0.472809\n",
      "batch 287: loss 0.421275\n",
      "batch 288: loss 0.289627\n",
      "batch 289: loss 0.366863\n",
      "batch 290: loss 0.167004\n",
      "batch 291: loss 0.312311\n",
      "batch 292: loss 0.314269\n",
      "batch 293: loss 0.427021\n",
      "batch 294: loss 0.295391\n",
      "batch 295: loss 0.385567\n",
      "batch 296: loss 0.540954\n",
      "batch 297: loss 0.255626\n",
      "batch 298: loss 0.472868\n",
      "batch 299: loss 0.396355\n",
      "batch 300: loss 0.476362\n",
      "batch 301: loss 0.179887\n",
      "batch 302: loss 0.409161\n",
      "batch 303: loss 0.344896\n",
      "batch 304: loss 0.345411\n",
      "batch 305: loss 0.417929\n",
      "batch 306: loss 0.229100\n",
      "batch 307: loss 0.330755\n",
      "batch 308: loss 0.416884\n",
      "batch 309: loss 0.424580\n",
      "batch 310: loss 0.229964\n",
      "batch 311: loss 0.281890\n",
      "batch 312: loss 0.232286\n",
      "batch 313: loss 0.386431\n",
      "batch 314: loss 0.339745\n",
      "batch 315: loss 0.230619\n",
      "batch 316: loss 0.179693\n",
      "batch 317: loss 0.217940\n",
      "batch 318: loss 0.166609\n",
      "batch 319: loss 0.208553\n",
      "batch 320: loss 0.146573\n",
      "batch 321: loss 0.291595\n",
      "batch 322: loss 0.151963\n",
      "batch 323: loss 0.228351\n",
      "batch 324: loss 0.261640\n",
      "batch 325: loss 0.223452\n",
      "batch 326: loss 0.316041\n",
      "batch 327: loss 0.440495\n",
      "batch 328: loss 0.403447\n",
      "batch 329: loss 0.275076\n",
      "batch 330: loss 0.307749\n",
      "batch 331: loss 0.290232\n",
      "batch 332: loss 0.260484\n",
      "batch 333: loss 0.179572\n",
      "batch 334: loss 0.353577\n",
      "batch 335: loss 0.359961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 336: loss 0.219123\n",
      "batch 337: loss 0.188114\n",
      "batch 338: loss 0.116074\n",
      "batch 339: loss 0.175368\n",
      "batch 340: loss 0.474938\n",
      "batch 341: loss 0.178944\n",
      "batch 342: loss 0.429519\n",
      "batch 343: loss 0.332504\n",
      "batch 344: loss 0.191827\n",
      "batch 345: loss 0.514219\n",
      "batch 346: loss 0.498515\n",
      "batch 347: loss 0.475369\n",
      "batch 348: loss 0.223633\n",
      "batch 349: loss 0.351792\n",
      "batch 350: loss 0.299564\n",
      "batch 351: loss 0.277855\n",
      "batch 352: loss 0.243060\n",
      "batch 353: loss 0.407063\n",
      "batch 354: loss 0.294628\n",
      "batch 355: loss 0.267463\n",
      "batch 356: loss 0.457696\n",
      "batch 357: loss 0.329360\n",
      "batch 358: loss 0.512212\n",
      "batch 359: loss 0.316043\n",
      "batch 360: loss 0.174431\n",
      "batch 361: loss 0.225253\n",
      "batch 362: loss 0.138698\n",
      "batch 363: loss 0.256407\n",
      "batch 364: loss 0.237275\n",
      "batch 365: loss 0.223827\n",
      "batch 366: loss 0.138545\n",
      "batch 367: loss 0.153996\n",
      "batch 368: loss 0.213599\n",
      "batch 369: loss 0.297388\n",
      "batch 370: loss 0.261974\n",
      "batch 371: loss 0.227705\n",
      "batch 372: loss 0.317586\n",
      "batch 373: loss 0.288888\n",
      "batch 374: loss 0.176673\n",
      "batch 375: loss 0.370153\n",
      "batch 376: loss 0.479167\n",
      "batch 377: loss 0.166989\n",
      "batch 378: loss 0.256416\n",
      "batch 379: loss 0.233948\n",
      "batch 380: loss 0.330646\n",
      "batch 381: loss 0.205928\n",
      "batch 382: loss 0.405338\n",
      "batch 383: loss 0.213716\n",
      "batch 384: loss 0.135536\n",
      "batch 385: loss 0.417827\n",
      "batch 386: loss 0.427282\n",
      "batch 387: loss 0.403125\n",
      "batch 388: loss 0.242752\n",
      "batch 389: loss 0.377855\n",
      "batch 390: loss 0.442845\n",
      "batch 391: loss 0.202443\n",
      "batch 392: loss 0.242742\n",
      "batch 393: loss 0.467208\n",
      "batch 394: loss 0.404511\n",
      "batch 395: loss 0.122104\n",
      "batch 396: loss 0.266771\n",
      "batch 397: loss 0.296208\n",
      "batch 398: loss 0.286747\n",
      "batch 399: loss 0.229240\n",
      "batch 400: loss 0.181990\n",
      "batch 401: loss 0.339910\n",
      "batch 402: loss 0.104715\n",
      "batch 403: loss 0.461109\n",
      "batch 404: loss 0.165658\n",
      "batch 405: loss 0.234845\n",
      "batch 406: loss 0.216740\n",
      "batch 407: loss 0.315979\n",
      "batch 408: loss 0.467955\n",
      "batch 409: loss 0.452290\n",
      "batch 410: loss 0.312441\n",
      "batch 411: loss 0.591320\n",
      "batch 412: loss 0.198182\n",
      "batch 413: loss 0.244091\n",
      "batch 414: loss 0.145286\n",
      "batch 415: loss 0.209054\n",
      "batch 416: loss 0.389643\n",
      "batch 417: loss 0.091126\n",
      "batch 418: loss 0.403217\n",
      "batch 419: loss 0.251940\n",
      "batch 420: loss 0.408500\n",
      "batch 421: loss 0.247437\n",
      "batch 422: loss 0.240658\n",
      "batch 423: loss 0.223474\n",
      "batch 424: loss 0.125497\n",
      "batch 425: loss 0.345196\n",
      "batch 426: loss 0.219439\n",
      "batch 427: loss 0.180573\n",
      "batch 428: loss 0.363146\n",
      "batch 429: loss 0.326737\n",
      "batch 430: loss 0.395104\n",
      "batch 431: loss 0.216474\n",
      "batch 432: loss 0.393034\n",
      "batch 433: loss 0.125040\n",
      "batch 434: loss 0.218165\n",
      "batch 435: loss 0.288735\n",
      "batch 436: loss 0.285797\n",
      "batch 437: loss 0.310113\n",
      "batch 438: loss 0.267273\n",
      "batch 439: loss 0.269235\n",
      "batch 440: loss 0.217972\n",
      "batch 441: loss 0.209117\n",
      "batch 442: loss 0.296524\n",
      "batch 443: loss 0.437615\n",
      "batch 444: loss 0.192412\n",
      "batch 445: loss 0.276335\n",
      "batch 446: loss 0.118203\n",
      "batch 447: loss 0.331622\n",
      "batch 448: loss 0.296168\n",
      "batch 449: loss 0.247827\n",
      "batch 450: loss 0.361512\n",
      "batch 451: loss 0.104883\n",
      "batch 452: loss 0.207603\n",
      "batch 453: loss 0.177332\n",
      "batch 454: loss 0.153749\n",
      "batch 455: loss 0.181786\n",
      "batch 456: loss 0.369721\n",
      "batch 457: loss 0.209697\n",
      "batch 458: loss 0.236134\n",
      "batch 459: loss 0.267932\n",
      "batch 460: loss 0.384862\n",
      "batch 461: loss 0.655160\n",
      "batch 462: loss 0.208918\n",
      "batch 463: loss 0.359656\n",
      "batch 464: loss 0.345161\n",
      "batch 465: loss 0.244030\n",
      "batch 466: loss 0.281573\n",
      "batch 467: loss 0.137096\n",
      "batch 468: loss 0.159120\n",
      "batch 469: loss 0.098056\n",
      "batch 470: loss 0.199941\n",
      "batch 471: loss 0.184378\n",
      "batch 472: loss 0.339297\n",
      "batch 473: loss 0.195576\n",
      "batch 474: loss 0.170180\n",
      "batch 475: loss 0.253862\n",
      "batch 476: loss 0.260182\n",
      "batch 477: loss 0.218758\n",
      "batch 478: loss 0.084663\n",
      "batch 479: loss 0.147320\n",
      "batch 480: loss 0.210233\n",
      "batch 481: loss 0.166454\n",
      "batch 482: loss 0.224061\n",
      "batch 483: loss 0.165088\n",
      "batch 484: loss 0.140352\n",
      "batch 485: loss 0.178322\n",
      "batch 486: loss 0.170020\n",
      "batch 487: loss 0.206567\n",
      "batch 488: loss 0.117776\n",
      "batch 489: loss 0.214037\n",
      "batch 490: loss 0.128871\n",
      "batch 491: loss 0.322663\n",
      "batch 492: loss 0.262703\n",
      "batch 493: loss 0.238811\n",
      "batch 494: loss 0.169398\n",
      "batch 495: loss 0.219800\n",
      "batch 496: loss 0.277783\n",
      "batch 497: loss 0.156420\n",
      "batch 498: loss 0.155309\n",
      "batch 499: loss 0.305836\n",
      "batch 500: loss 0.209701\n",
      "batch 501: loss 0.143323\n",
      "batch 502: loss 0.420439\n",
      "batch 503: loss 0.219189\n",
      "batch 504: loss 0.178114\n",
      "batch 505: loss 0.325402\n",
      "batch 506: loss 0.132404\n",
      "batch 507: loss 0.098771\n",
      "batch 508: loss 0.136706\n",
      "batch 509: loss 0.395697\n",
      "batch 510: loss 0.117119\n",
      "batch 511: loss 0.223085\n",
      "batch 512: loss 0.421405\n",
      "batch 513: loss 0.236465\n",
      "batch 514: loss 0.233012\n",
      "batch 515: loss 0.210865\n",
      "batch 516: loss 0.116776\n",
      "batch 517: loss 0.232940\n",
      "batch 518: loss 0.326654\n",
      "batch 519: loss 0.085250\n",
      "batch 520: loss 0.149688\n",
      "batch 521: loss 0.474696\n",
      "batch 522: loss 0.364527\n",
      "batch 523: loss 0.314337\n",
      "batch 524: loss 0.434056\n",
      "batch 525: loss 0.299541\n",
      "batch 526: loss 0.430453\n",
      "batch 527: loss 0.217472\n",
      "batch 528: loss 0.217657\n",
      "batch 529: loss 0.337401\n",
      "batch 530: loss 0.312577\n",
      "batch 531: loss 0.113605\n",
      "batch 532: loss 0.321081\n",
      "batch 533: loss 0.173188\n",
      "batch 534: loss 0.202827\n",
      "batch 535: loss 0.341837\n",
      "batch 536: loss 0.209724\n",
      "batch 537: loss 0.265369\n",
      "batch 538: loss 0.176205\n",
      "batch 539: loss 0.127806\n",
      "batch 540: loss 0.188911\n",
      "batch 541: loss 0.247549\n",
      "batch 542: loss 0.235818\n",
      "batch 543: loss 0.126963\n",
      "batch 544: loss 0.248548\n",
      "batch 545: loss 0.136972\n",
      "batch 546: loss 0.119970\n",
      "batch 547: loss 0.455689\n",
      "batch 548: loss 0.089179\n",
      "batch 549: loss 0.318541\n",
      "batch 550: loss 0.146963\n",
      "batch 551: loss 0.237308\n",
      "batch 552: loss 0.305992\n",
      "batch 553: loss 0.232921\n",
      "batch 554: loss 0.261818\n",
      "batch 555: loss 0.185253\n",
      "batch 556: loss 0.126635\n",
      "batch 557: loss 0.158212\n",
      "batch 558: loss 0.312684\n",
      "batch 559: loss 0.470886\n",
      "batch 560: loss 0.301306\n",
      "batch 561: loss 0.297191\n",
      "batch 562: loss 0.324600\n",
      "batch 563: loss 0.154052\n",
      "batch 564: loss 0.339745\n",
      "batch 565: loss 0.397916\n",
      "batch 566: loss 0.360127\n",
      "batch 567: loss 0.307580\n",
      "batch 568: loss 0.075407\n",
      "batch 569: loss 0.427767\n",
      "batch 570: loss 0.216229\n",
      "batch 571: loss 0.234601\n",
      "batch 572: loss 0.396729\n",
      "batch 573: loss 0.243933\n",
      "batch 574: loss 0.089854\n",
      "batch 575: loss 0.337424\n",
      "batch 576: loss 0.397574\n",
      "batch 577: loss 0.308589\n",
      "batch 578: loss 0.239022\n",
      "batch 579: loss 0.087463\n",
      "batch 580: loss 0.238458\n",
      "batch 581: loss 0.280002\n",
      "batch 582: loss 0.286164\n",
      "batch 583: loss 0.274954\n",
      "batch 584: loss 0.286264\n",
      "batch 585: loss 0.089950\n",
      "batch 586: loss 0.260198\n",
      "batch 587: loss 0.258064\n",
      "batch 588: loss 0.179966\n",
      "batch 589: loss 0.461319\n",
      "batch 590: loss 0.098134\n",
      "batch 591: loss 0.208626\n",
      "batch 592: loss 0.176743\n",
      "batch 593: loss 0.120252\n",
      "batch 594: loss 0.398675\n",
      "batch 595: loss 0.098207\n",
      "batch 596: loss 0.084264\n",
      "batch 597: loss 0.172048\n",
      "batch 598: loss 0.207830\n",
      "batch 599: loss 0.123704\n",
      "batch 600: loss 0.305900\n",
      "batch 601: loss 0.365755\n",
      "batch 602: loss 0.151994\n",
      "batch 603: loss 0.227120\n",
      "batch 604: loss 0.243736\n",
      "batch 605: loss 0.201558\n",
      "batch 606: loss 0.366467\n",
      "batch 607: loss 0.234862\n",
      "batch 608: loss 0.333688\n",
      "batch 609: loss 0.143682\n",
      "batch 610: loss 0.216838\n",
      "batch 611: loss 0.372999\n",
      "batch 612: loss 0.315772\n",
      "batch 613: loss 0.246573\n",
      "batch 614: loss 0.121755\n",
      "batch 615: loss 0.290676\n",
      "batch 616: loss 0.216416\n",
      "batch 617: loss 0.289227\n",
      "batch 618: loss 0.218388\n",
      "batch 619: loss 0.237258\n",
      "batch 620: loss 0.274387\n",
      "batch 621: loss 0.408234\n",
      "batch 622: loss 0.100686\n",
      "batch 623: loss 0.511172\n",
      "batch 624: loss 0.292095\n",
      "batch 625: loss 0.179562\n",
      "batch 626: loss 0.204520\n",
      "batch 627: loss 0.197821\n",
      "batch 628: loss 0.425102\n",
      "batch 629: loss 0.121444\n",
      "batch 630: loss 0.210814\n",
      "batch 631: loss 0.304829\n",
      "batch 632: loss 0.155052\n",
      "batch 633: loss 0.229880\n",
      "batch 634: loss 0.195111\n",
      "batch 635: loss 0.139776\n",
      "batch 636: loss 0.049947\n",
      "batch 637: loss 0.210984\n",
      "batch 638: loss 0.188506\n",
      "batch 639: loss 0.167562\n",
      "batch 640: loss 0.189650\n",
      "batch 641: loss 0.144967\n",
      "batch 642: loss 0.155910\n",
      "batch 643: loss 0.116029\n",
      "batch 644: loss 0.105494\n",
      "batch 645: loss 0.365807\n",
      "batch 646: loss 0.077889\n",
      "batch 647: loss 0.446740\n",
      "batch 648: loss 0.208974\n",
      "batch 649: loss 0.254675\n",
      "batch 650: loss 0.135553\n",
      "batch 651: loss 0.385073\n",
      "batch 652: loss 0.222493\n",
      "batch 653: loss 0.434455\n",
      "batch 654: loss 0.160054\n",
      "batch 655: loss 0.184220\n",
      "batch 656: loss 0.301490\n",
      "batch 657: loss 0.114137\n",
      "batch 658: loss 0.460368\n",
      "batch 659: loss 0.094430\n",
      "batch 660: loss 0.156415\n",
      "batch 661: loss 0.166431\n",
      "batch 662: loss 0.222839\n",
      "batch 663: loss 0.183047\n",
      "batch 664: loss 0.380047\n",
      "batch 665: loss 0.118691\n",
      "batch 666: loss 0.134816\n",
      "batch 667: loss 0.199725\n",
      "batch 668: loss 0.153970\n",
      "batch 669: loss 0.345127\n",
      "batch 670: loss 0.397939\n",
      "batch 671: loss 0.129379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 672: loss 0.083702\n",
      "batch 673: loss 0.062046\n",
      "batch 674: loss 0.157105\n",
      "batch 675: loss 0.176974\n",
      "batch 676: loss 0.257782\n",
      "batch 677: loss 0.186977\n",
      "batch 678: loss 0.144210\n",
      "batch 679: loss 0.170667\n",
      "batch 680: loss 0.154602\n",
      "batch 681: loss 0.109601\n",
      "batch 682: loss 0.498901\n",
      "batch 683: loss 0.140099\n",
      "batch 684: loss 0.114049\n",
      "batch 685: loss 0.182271\n",
      "batch 686: loss 0.339528\n",
      "batch 687: loss 0.193452\n",
      "batch 688: loss 0.138961\n",
      "batch 689: loss 0.215980\n",
      "batch 690: loss 0.251689\n",
      "batch 691: loss 0.118931\n",
      "batch 692: loss 0.221623\n",
      "batch 693: loss 0.275397\n",
      "batch 694: loss 0.202496\n",
      "batch 695: loss 0.373201\n",
      "batch 696: loss 0.124747\n",
      "batch 697: loss 0.338553\n",
      "batch 698: loss 0.335709\n",
      "batch 699: loss 0.251377\n",
      "batch 700: loss 0.140034\n",
      "batch 701: loss 0.247119\n",
      "batch 702: loss 0.111636\n",
      "batch 703: loss 0.137635\n",
      "batch 704: loss 0.248955\n",
      "batch 705: loss 0.158482\n",
      "batch 706: loss 0.166410\n",
      "batch 707: loss 0.180451\n",
      "batch 708: loss 0.062551\n",
      "batch 709: loss 0.373578\n",
      "batch 710: loss 0.080802\n",
      "batch 711: loss 0.068056\n",
      "batch 712: loss 0.266170\n",
      "batch 713: loss 0.106341\n",
      "batch 714: loss 0.127576\n",
      "batch 715: loss 0.109682\n",
      "batch 716: loss 0.126893\n",
      "batch 717: loss 0.143617\n",
      "batch 718: loss 0.120711\n",
      "batch 719: loss 0.155098\n",
      "batch 720: loss 0.296005\n",
      "batch 721: loss 0.401833\n",
      "batch 722: loss 0.115031\n",
      "batch 723: loss 0.212555\n",
      "batch 724: loss 0.142394\n",
      "batch 725: loss 0.131235\n",
      "batch 726: loss 0.180544\n",
      "batch 727: loss 0.294813\n",
      "batch 728: loss 0.151243\n",
      "batch 729: loss 0.277585\n",
      "batch 730: loss 0.168141\n",
      "batch 731: loss 0.225558\n",
      "batch 732: loss 0.455506\n",
      "batch 733: loss 0.089866\n",
      "batch 734: loss 0.440797\n",
      "batch 735: loss 0.175672\n",
      "batch 736: loss 0.092703\n",
      "batch 737: loss 0.166792\n",
      "batch 738: loss 0.046617\n",
      "batch 739: loss 0.102824\n",
      "batch 740: loss 0.172571\n",
      "batch 741: loss 0.413423\n",
      "batch 742: loss 0.316871\n",
      "batch 743: loss 0.179256\n",
      "batch 744: loss 0.190343\n",
      "batch 745: loss 0.195144\n",
      "batch 746: loss 0.260044\n",
      "batch 747: loss 0.091172\n",
      "batch 748: loss 0.184497\n",
      "batch 749: loss 0.157538\n",
      "batch 750: loss 0.287127\n",
      "batch 751: loss 0.323725\n",
      "batch 752: loss 0.271260\n",
      "batch 753: loss 0.226308\n",
      "batch 754: loss 0.188904\n",
      "batch 755: loss 0.161147\n",
      "batch 756: loss 0.490945\n",
      "batch 757: loss 0.174066\n",
      "batch 758: loss 0.228250\n",
      "batch 759: loss 0.068914\n",
      "batch 760: loss 0.206481\n",
      "batch 761: loss 0.178166\n",
      "batch 762: loss 0.147358\n",
      "batch 763: loss 0.071826\n",
      "batch 764: loss 0.117756\n",
      "batch 765: loss 0.270308\n",
      "batch 766: loss 0.158429\n",
      "batch 767: loss 0.038272\n",
      "batch 768: loss 0.260916\n",
      "batch 769: loss 0.127076\n",
      "batch 770: loss 0.174613\n",
      "batch 771: loss 0.119755\n",
      "batch 772: loss 0.175578\n",
      "batch 773: loss 0.188119\n",
      "batch 774: loss 0.344157\n",
      "batch 775: loss 0.214953\n",
      "batch 776: loss 0.242924\n",
      "batch 777: loss 0.102633\n",
      "batch 778: loss 0.184157\n",
      "batch 779: loss 0.229018\n",
      "batch 780: loss 0.222488\n",
      "batch 781: loss 0.144475\n",
      "batch 782: loss 0.053349\n",
      "batch 783: loss 0.190767\n",
      "batch 784: loss 0.088821\n",
      "batch 785: loss 0.423592\n",
      "batch 786: loss 0.187105\n",
      "batch 787: loss 0.233446\n",
      "batch 788: loss 0.265533\n",
      "batch 789: loss 0.342132\n",
      "batch 790: loss 0.213973\n",
      "batch 791: loss 0.279979\n",
      "batch 792: loss 0.274682\n",
      "batch 793: loss 0.162507\n",
      "batch 794: loss 0.114767\n",
      "batch 795: loss 0.131957\n",
      "batch 796: loss 0.099637\n",
      "batch 797: loss 0.305637\n",
      "batch 798: loss 0.199185\n",
      "batch 799: loss 0.547233\n",
      "batch 800: loss 0.274969\n",
      "batch 801: loss 0.245627\n",
      "batch 802: loss 0.401192\n",
      "batch 803: loss 0.064428\n",
      "batch 804: loss 0.145173\n",
      "batch 805: loss 0.226298\n",
      "batch 806: loss 0.221218\n",
      "batch 807: loss 0.215577\n",
      "batch 808: loss 0.235173\n",
      "batch 809: loss 0.139037\n",
      "batch 810: loss 0.220890\n",
      "batch 811: loss 0.370294\n",
      "batch 812: loss 0.298514\n",
      "batch 813: loss 0.142856\n",
      "batch 814: loss 0.189750\n",
      "batch 815: loss 0.177601\n",
      "batch 816: loss 0.301695\n",
      "batch 817: loss 0.291005\n",
      "batch 818: loss 0.128868\n",
      "batch 819: loss 0.113568\n",
      "batch 820: loss 0.168853\n",
      "batch 821: loss 0.070693\n",
      "batch 822: loss 0.074956\n",
      "batch 823: loss 0.187881\n",
      "batch 824: loss 0.322817\n",
      "batch 825: loss 0.081341\n",
      "batch 826: loss 0.161173\n",
      "batch 827: loss 0.078187\n",
      "batch 828: loss 0.215580\n",
      "batch 829: loss 0.222193\n",
      "batch 830: loss 0.267500\n",
      "batch 831: loss 0.217836\n",
      "batch 832: loss 0.169325\n",
      "batch 833: loss 0.181679\n",
      "batch 834: loss 0.348841\n",
      "batch 835: loss 0.127448\n",
      "batch 836: loss 0.150273\n",
      "batch 837: loss 0.232031\n",
      "batch 838: loss 0.095172\n",
      "batch 839: loss 0.259532\n",
      "batch 840: loss 0.212146\n",
      "batch 841: loss 0.161288\n",
      "batch 842: loss 0.131016\n",
      "batch 843: loss 0.214743\n",
      "batch 844: loss 0.310390\n",
      "batch 845: loss 0.327703\n",
      "batch 846: loss 0.174558\n",
      "batch 847: loss 0.082885\n",
      "batch 848: loss 0.101334\n",
      "batch 849: loss 0.214920\n",
      "batch 850: loss 0.297551\n",
      "batch 851: loss 0.151487\n",
      "batch 852: loss 0.110121\n",
      "batch 853: loss 0.534166\n",
      "batch 854: loss 0.296164\n",
      "batch 855: loss 0.176090\n",
      "batch 856: loss 0.083094\n",
      "batch 857: loss 0.143002\n",
      "batch 858: loss 0.142520\n",
      "batch 859: loss 0.242105\n",
      "batch 860: loss 0.232504\n",
      "batch 861: loss 0.252199\n",
      "batch 862: loss 0.088072\n",
      "batch 863: loss 0.167626\n",
      "batch 864: loss 0.265540\n",
      "batch 865: loss 0.187333\n",
      "batch 866: loss 0.071053\n",
      "batch 867: loss 0.154288\n",
      "batch 868: loss 0.151326\n",
      "batch 869: loss 0.121102\n",
      "batch 870: loss 0.134167\n",
      "batch 871: loss 0.190823\n",
      "batch 872: loss 0.316035\n",
      "batch 873: loss 0.142819\n",
      "batch 874: loss 0.214694\n",
      "batch 875: loss 0.202620\n",
      "batch 876: loss 0.098851\n",
      "batch 877: loss 0.184782\n",
      "batch 878: loss 0.163049\n",
      "batch 879: loss 0.372268\n",
      "batch 880: loss 0.339815\n",
      "batch 881: loss 0.225529\n",
      "batch 882: loss 0.265741\n",
      "batch 883: loss 0.161038\n",
      "batch 884: loss 0.092652\n",
      "batch 885: loss 0.170095\n",
      "batch 886: loss 0.368441\n",
      "batch 887: loss 0.112444\n",
      "batch 888: loss 0.192618\n",
      "batch 889: loss 0.040848\n",
      "batch 890: loss 0.478136\n",
      "batch 891: loss 0.165341\n",
      "batch 892: loss 0.149171\n",
      "batch 893: loss 0.128107\n",
      "batch 894: loss 0.266427\n",
      "batch 895: loss 0.209961\n",
      "batch 896: loss 0.072288\n",
      "batch 897: loss 0.135598\n",
      "batch 898: loss 0.087740\n",
      "batch 899: loss 0.221273\n",
      "batch 900: loss 0.360139\n",
      "batch 901: loss 0.111198\n",
      "batch 902: loss 0.098196\n",
      "batch 903: loss 0.110022\n",
      "batch 904: loss 0.262413\n",
      "batch 905: loss 0.118481\n",
      "batch 906: loss 0.169563\n",
      "batch 907: loss 0.138152\n",
      "batch 908: loss 0.107372\n",
      "batch 909: loss 0.198607\n",
      "batch 910: loss 0.246402\n",
      "batch 911: loss 0.235812\n",
      "batch 912: loss 0.287457\n",
      "batch 913: loss 0.132691\n",
      "batch 914: loss 0.117724\n",
      "batch 915: loss 0.156626\n",
      "batch 916: loss 0.141703\n",
      "batch 917: loss 0.180941\n",
      "batch 918: loss 0.212037\n",
      "batch 919: loss 0.164382\n",
      "batch 920: loss 0.230134\n",
      "batch 921: loss 0.088567\n",
      "batch 922: loss 0.104059\n",
      "batch 923: loss 0.095359\n",
      "batch 924: loss 0.121740\n",
      "batch 925: loss 0.188605\n",
      "batch 926: loss 0.104498\n",
      "batch 927: loss 0.356798\n",
      "batch 928: loss 0.198218\n",
      "batch 929: loss 0.156816\n",
      "batch 930: loss 0.168307\n",
      "batch 931: loss 0.144427\n",
      "batch 932: loss 0.235877\n",
      "batch 933: loss 0.190431\n",
      "batch 934: loss 0.101702\n",
      "batch 935: loss 0.341751\n",
      "batch 936: loss 0.147552\n",
      "batch 937: loss 0.239254\n",
      "batch 938: loss 0.084147\n",
      "batch 939: loss 0.305760\n",
      "batch 940: loss 0.203615\n",
      "batch 941: loss 0.202914\n",
      "batch 942: loss 0.175990\n",
      "batch 943: loss 0.335230\n",
      "batch 944: loss 0.183731\n",
      "batch 945: loss 0.247519\n",
      "batch 946: loss 0.158965\n",
      "batch 947: loss 0.149092\n",
      "batch 948: loss 0.174144\n",
      "batch 949: loss 0.471624\n",
      "batch 950: loss 0.204314\n",
      "batch 951: loss 0.120280\n",
      "batch 952: loss 0.340511\n",
      "batch 953: loss 0.118498\n",
      "batch 954: loss 0.181457\n",
      "batch 955: loss 0.065170\n",
      "batch 956: loss 0.191914\n",
      "batch 957: loss 0.094968\n",
      "batch 958: loss 0.378538\n",
      "batch 959: loss 0.087281\n",
      "batch 960: loss 0.199491\n",
      "batch 961: loss 0.062758\n",
      "batch 962: loss 0.167943\n",
      "batch 963: loss 0.265663\n",
      "batch 964: loss 0.209401\n",
      "batch 965: loss 0.208536\n",
      "batch 966: loss 0.170019\n",
      "batch 967: loss 0.104075\n",
      "batch 968: loss 0.218417\n",
      "batch 969: loss 0.122537\n",
      "batch 970: loss 0.146039\n",
      "batch 971: loss 0.223537\n",
      "batch 972: loss 0.133705\n",
      "batch 973: loss 0.220961\n",
      "batch 974: loss 0.200444\n",
      "batch 975: loss 0.113406\n",
      "batch 976: loss 0.057717\n",
      "batch 977: loss 0.249468\n",
      "batch 978: loss 0.132632\n",
      "batch 979: loss 0.149835\n",
      "batch 980: loss 0.203137\n",
      "batch 981: loss 0.078376\n",
      "batch 982: loss 0.134102\n",
      "batch 983: loss 0.116482\n",
      "batch 984: loss 0.075990\n",
      "batch 985: loss 0.107419\n",
      "batch 986: loss 0.149836\n",
      "batch 987: loss 0.054173\n",
      "batch 988: loss 0.333165\n",
      "batch 989: loss 0.099639\n",
      "batch 990: loss 0.301078\n",
      "batch 991: loss 0.268687\n",
      "batch 992: loss 0.082858\n",
      "batch 993: loss 0.095253\n",
      "batch 994: loss 0.127743\n",
      "batch 995: loss 0.088802\n",
      "batch 996: loss 0.221246\n",
      "batch 997: loss 0.249225\n",
      "batch 998: loss 0.137286\n",
      "batch 999: loss 0.069672\n",
      "batch 1000: loss 0.087843\n",
      "batch 1001: loss 0.125299\n",
      "batch 1002: loss 0.306681\n",
      "batch 1003: loss 0.114883\n",
      "batch 1004: loss 0.158670\n",
      "batch 1005: loss 0.047705\n",
      "batch 1006: loss 0.103942\n",
      "batch 1007: loss 0.192968\n",
      "batch 1008: loss 0.148106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1009: loss 0.156234\n",
      "batch 1010: loss 0.109541\n",
      "batch 1011: loss 0.112047\n",
      "batch 1012: loss 0.070254\n",
      "batch 1013: loss 0.190675\n",
      "batch 1014: loss 0.199943\n",
      "batch 1015: loss 0.145734\n",
      "batch 1016: loss 0.192558\n",
      "batch 1017: loss 0.107726\n",
      "batch 1018: loss 0.341545\n",
      "batch 1019: loss 0.219242\n",
      "batch 1020: loss 0.195877\n",
      "batch 1021: loss 0.266778\n",
      "batch 1022: loss 0.105959\n",
      "batch 1023: loss 0.114902\n",
      "batch 1024: loss 0.124128\n",
      "batch 1025: loss 0.195042\n",
      "batch 1026: loss 0.237744\n",
      "batch 1027: loss 0.134760\n",
      "batch 1028: loss 0.091405\n",
      "batch 1029: loss 0.094443\n",
      "batch 1030: loss 0.575960\n",
      "batch 1031: loss 0.217058\n",
      "batch 1032: loss 0.155264\n",
      "batch 1033: loss 0.070170\n",
      "batch 1034: loss 0.179063\n",
      "batch 1035: loss 0.133224\n",
      "batch 1036: loss 0.252399\n",
      "batch 1037: loss 0.315145\n",
      "batch 1038: loss 0.308006\n",
      "batch 1039: loss 0.054328\n",
      "batch 1040: loss 0.096342\n",
      "batch 1041: loss 0.206589\n",
      "batch 1042: loss 0.051051\n",
      "batch 1043: loss 0.103626\n",
      "batch 1044: loss 0.115388\n",
      "batch 1045: loss 0.036220\n",
      "batch 1046: loss 0.149905\n",
      "batch 1047: loss 0.072031\n",
      "batch 1048: loss 0.197541\n",
      "batch 1049: loss 0.073211\n",
      "batch 1050: loss 0.200122\n",
      "batch 1051: loss 0.200575\n",
      "batch 1052: loss 0.194604\n",
      "batch 1053: loss 0.190093\n",
      "batch 1054: loss 0.112330\n",
      "batch 1055: loss 0.125130\n",
      "batch 1056: loss 0.277111\n",
      "batch 1057: loss 0.166658\n",
      "batch 1058: loss 0.116432\n",
      "batch 1059: loss 0.237021\n",
      "batch 1060: loss 0.110048\n",
      "batch 1061: loss 0.092377\n",
      "batch 1062: loss 0.077313\n",
      "batch 1063: loss 0.078922\n",
      "batch 1064: loss 0.054476\n",
      "batch 1065: loss 0.094146\n",
      "batch 1066: loss 0.071023\n",
      "batch 1067: loss 0.143849\n",
      "batch 1068: loss 0.101919\n",
      "batch 1069: loss 0.185366\n",
      "batch 1070: loss 0.259664\n",
      "batch 1071: loss 0.172698\n",
      "batch 1072: loss 0.164458\n",
      "batch 1073: loss 0.076293\n",
      "batch 1074: loss 0.239240\n",
      "batch 1075: loss 0.224505\n",
      "batch 1076: loss 0.062851\n",
      "batch 1077: loss 0.176573\n",
      "batch 1078: loss 0.140715\n",
      "batch 1079: loss 0.168601\n",
      "batch 1080: loss 0.114142\n",
      "batch 1081: loss 0.104847\n",
      "batch 1082: loss 0.303382\n",
      "batch 1083: loss 0.200782\n",
      "batch 1084: loss 0.134586\n",
      "batch 1085: loss 0.181063\n",
      "batch 1086: loss 0.062365\n",
      "batch 1087: loss 0.367679\n",
      "batch 1088: loss 0.130173\n",
      "batch 1089: loss 0.146444\n",
      "batch 1090: loss 0.058727\n",
      "batch 1091: loss 0.182049\n",
      "batch 1092: loss 0.257881\n",
      "batch 1093: loss 0.096525\n",
      "batch 1094: loss 0.219723\n",
      "batch 1095: loss 0.167384\n",
      "batch 1096: loss 0.440397\n",
      "batch 1097: loss 0.154036\n",
      "batch 1098: loss 0.156070\n",
      "batch 1099: loss 0.040139\n",
      "batch 1100: loss 0.159342\n",
      "batch 1101: loss 0.163889\n",
      "batch 1102: loss 0.072514\n",
      "batch 1103: loss 0.095483\n",
      "batch 1104: loss 0.120324\n",
      "batch 1105: loss 0.369143\n",
      "batch 1106: loss 0.376369\n",
      "batch 1107: loss 0.083641\n",
      "batch 1108: loss 0.141714\n",
      "batch 1109: loss 0.258123\n",
      "batch 1110: loss 0.371454\n",
      "batch 1111: loss 0.420065\n",
      "batch 1112: loss 0.177532\n",
      "batch 1113: loss 0.107566\n",
      "batch 1114: loss 0.234254\n",
      "batch 1115: loss 0.135064\n",
      "batch 1116: loss 0.157811\n",
      "batch 1117: loss 0.119935\n",
      "batch 1118: loss 0.311915\n",
      "batch 1119: loss 0.072320\n",
      "batch 1120: loss 0.177675\n",
      "batch 1121: loss 0.166778\n",
      "batch 1122: loss 0.184579\n",
      "batch 1123: loss 0.184249\n",
      "batch 1124: loss 0.145698\n",
      "batch 1125: loss 0.143212\n",
      "batch 1126: loss 0.126467\n",
      "batch 1127: loss 0.179360\n",
      "batch 1128: loss 0.118602\n",
      "batch 1129: loss 0.166708\n",
      "batch 1130: loss 0.173892\n",
      "batch 1131: loss 0.201264\n",
      "batch 1132: loss 0.220069\n",
      "batch 1133: loss 0.165245\n",
      "batch 1134: loss 0.393247\n",
      "batch 1135: loss 0.147390\n",
      "batch 1136: loss 0.098726\n",
      "batch 1137: loss 0.138410\n",
      "batch 1138: loss 0.174446\n",
      "batch 1139: loss 0.102855\n",
      "batch 1140: loss 0.257575\n",
      "batch 1141: loss 0.192352\n",
      "batch 1142: loss 0.164477\n",
      "batch 1143: loss 0.148032\n",
      "batch 1144: loss 0.103495\n",
      "batch 1145: loss 0.168981\n",
      "batch 1146: loss 0.286727\n",
      "batch 1147: loss 0.196389\n",
      "batch 1148: loss 0.150469\n",
      "batch 1149: loss 0.355893\n",
      "batch 1150: loss 0.051379\n",
      "batch 1151: loss 0.306830\n",
      "batch 1152: loss 0.162700\n",
      "batch 1153: loss 0.110175\n",
      "batch 1154: loss 0.189954\n",
      "batch 1155: loss 0.062332\n",
      "batch 1156: loss 0.065482\n",
      "batch 1157: loss 0.157048\n",
      "batch 1158: loss 0.109719\n",
      "batch 1159: loss 0.128399\n",
      "batch 1160: loss 0.039138\n",
      "batch 1161: loss 0.160291\n",
      "batch 1162: loss 0.133061\n",
      "batch 1163: loss 0.082320\n",
      "batch 1164: loss 0.230225\n",
      "batch 1165: loss 0.192642\n",
      "batch 1166: loss 0.173064\n",
      "batch 1167: loss 0.146223\n",
      "batch 1168: loss 0.263436\n",
      "batch 1169: loss 0.168699\n",
      "batch 1170: loss 0.036517\n",
      "batch 1171: loss 0.135699\n",
      "batch 1172: loss 0.148326\n",
      "batch 1173: loss 0.041543\n",
      "batch 1174: loss 0.295762\n",
      "batch 1175: loss 0.114775\n",
      "batch 1176: loss 0.081463\n",
      "batch 1177: loss 0.093980\n",
      "batch 1178: loss 0.119630\n",
      "batch 1179: loss 0.080149\n",
      "batch 1180: loss 0.168530\n",
      "batch 1181: loss 0.175530\n",
      "batch 1182: loss 0.091314\n",
      "batch 1183: loss 0.331321\n",
      "batch 1184: loss 0.187812\n",
      "batch 1185: loss 0.256146\n",
      "batch 1186: loss 0.306306\n",
      "batch 1187: loss 0.094847\n",
      "batch 1188: loss 0.279026\n",
      "batch 1189: loss 0.111056\n",
      "batch 1190: loss 0.097376\n",
      "batch 1191: loss 0.078227\n",
      "batch 1192: loss 0.473767\n",
      "batch 1193: loss 0.099414\n",
      "batch 1194: loss 0.183777\n",
      "batch 1195: loss 0.144528\n",
      "batch 1196: loss 0.176716\n",
      "batch 1197: loss 0.171697\n",
      "batch 1198: loss 0.033241\n",
      "batch 1199: loss 0.111806\n",
      "batch 1200: loss 0.153630\n",
      "batch 1201: loss 0.150845\n",
      "batch 1202: loss 0.209362\n",
      "batch 1203: loss 0.185400\n",
      "batch 1204: loss 0.258354\n",
      "batch 1205: loss 0.412346\n",
      "batch 1206: loss 0.099768\n",
      "batch 1207: loss 0.154193\n",
      "batch 1208: loss 0.127993\n",
      "batch 1209: loss 0.131907\n",
      "batch 1210: loss 0.144947\n",
      "batch 1211: loss 0.334854\n",
      "batch 1212: loss 0.086550\n",
      "batch 1213: loss 0.106033\n",
      "batch 1214: loss 0.208468\n",
      "batch 1215: loss 0.361237\n",
      "batch 1216: loss 0.277193\n",
      "batch 1217: loss 0.172368\n",
      "batch 1218: loss 0.203733\n",
      "batch 1219: loss 0.122633\n",
      "batch 1220: loss 0.150932\n",
      "batch 1221: loss 0.114739\n",
      "batch 1222: loss 0.050877\n",
      "batch 1223: loss 0.153071\n",
      "batch 1224: loss 0.228538\n",
      "batch 1225: loss 0.054519\n",
      "batch 1226: loss 0.226536\n",
      "batch 1227: loss 0.332890\n",
      "batch 1228: loss 0.383076\n",
      "batch 1229: loss 0.104565\n",
      "batch 1230: loss 0.245060\n",
      "batch 1231: loss 0.291751\n",
      "batch 1232: loss 0.149825\n",
      "batch 1233: loss 0.064829\n",
      "batch 1234: loss 0.148500\n",
      "batch 1235: loss 0.223233\n",
      "batch 1236: loss 0.122781\n",
      "batch 1237: loss 0.246993\n",
      "batch 1238: loss 0.115942\n",
      "batch 1239: loss 0.102917\n",
      "batch 1240: loss 0.057521\n",
      "batch 1241: loss 0.067007\n",
      "batch 1242: loss 0.072391\n",
      "batch 1243: loss 0.095732\n",
      "batch 1244: loss 0.108748\n",
      "batch 1245: loss 0.391107\n",
      "batch 1246: loss 0.139029\n",
      "batch 1247: loss 0.146664\n",
      "batch 1248: loss 0.299296\n",
      "batch 1249: loss 0.056755\n",
      "batch 1250: loss 0.226974\n",
      "batch 1251: loss 0.108794\n",
      "batch 1252: loss 0.068486\n",
      "batch 1253: loss 0.182271\n",
      "batch 1254: loss 0.168460\n",
      "batch 1255: loss 0.081353\n",
      "batch 1256: loss 0.129685\n",
      "batch 1257: loss 0.070750\n",
      "batch 1258: loss 0.190751\n",
      "batch 1259: loss 0.109166\n",
      "batch 1260: loss 0.115754\n",
      "batch 1261: loss 0.120018\n",
      "batch 1262: loss 0.056198\n",
      "batch 1263: loss 0.172382\n",
      "batch 1264: loss 0.119579\n",
      "batch 1265: loss 0.064681\n",
      "batch 1266: loss 0.043820\n",
      "batch 1267: loss 0.203860\n",
      "batch 1268: loss 0.127158\n",
      "batch 1269: loss 0.071751\n",
      "batch 1270: loss 0.244269\n",
      "batch 1271: loss 0.091840\n",
      "batch 1272: loss 0.058976\n",
      "batch 1273: loss 0.178176\n",
      "batch 1274: loss 0.061870\n",
      "batch 1275: loss 0.065613\n",
      "batch 1276: loss 0.133273\n",
      "batch 1277: loss 0.045865\n",
      "batch 1278: loss 0.255649\n",
      "batch 1279: loss 0.103972\n",
      "batch 1280: loss 0.053837\n",
      "batch 1281: loss 0.073994\n",
      "batch 1282: loss 0.088824\n",
      "batch 1283: loss 0.166251\n",
      "batch 1284: loss 0.144558\n",
      "batch 1285: loss 0.054647\n",
      "batch 1286: loss 0.290556\n",
      "batch 1287: loss 0.104092\n",
      "batch 1288: loss 0.184457\n",
      "batch 1289: loss 0.118649\n",
      "batch 1290: loss 0.288076\n",
      "batch 1291: loss 0.233224\n",
      "batch 1292: loss 0.254215\n",
      "batch 1293: loss 0.249091\n",
      "batch 1294: loss 0.085486\n",
      "batch 1295: loss 0.155666\n",
      "batch 1296: loss 0.117536\n",
      "batch 1297: loss 0.082027\n",
      "batch 1298: loss 0.191594\n",
      "batch 1299: loss 0.092443\n",
      "batch 1300: loss 0.112665\n",
      "batch 1301: loss 0.117533\n",
      "batch 1302: loss 0.109013\n",
      "batch 1303: loss 0.206148\n",
      "batch 1304: loss 0.080263\n",
      "batch 1305: loss 0.177223\n",
      "batch 1306: loss 0.230311\n",
      "batch 1307: loss 0.147693\n",
      "batch 1308: loss 0.182865\n",
      "batch 1309: loss 0.257564\n",
      "batch 1310: loss 0.079466\n",
      "batch 1311: loss 0.134094\n",
      "batch 1312: loss 0.105443\n",
      "batch 1313: loss 0.072078\n",
      "batch 1314: loss 0.055462\n",
      "batch 1315: loss 0.208521\n",
      "batch 1316: loss 0.114263\n",
      "batch 1317: loss 0.147150\n",
      "batch 1318: loss 0.264629\n",
      "batch 1319: loss 0.196568\n",
      "batch 1320: loss 0.116227\n",
      "batch 1321: loss 0.159504\n",
      "batch 1322: loss 0.088555\n",
      "batch 1323: loss 0.061789\n",
      "batch 1324: loss 0.240080\n",
      "batch 1325: loss 0.040237\n",
      "batch 1326: loss 0.172044\n",
      "batch 1327: loss 0.270501\n",
      "batch 1328: loss 0.121135\n",
      "batch 1329: loss 0.134051\n",
      "batch 1330: loss 0.273505\n",
      "batch 1331: loss 0.146176\n",
      "batch 1332: loss 0.083120\n",
      "batch 1333: loss 0.106529\n",
      "batch 1334: loss 0.080471\n",
      "batch 1335: loss 0.138299\n",
      "batch 1336: loss 0.068399\n",
      "batch 1337: loss 0.117790\n",
      "batch 1338: loss 0.085561\n",
      "batch 1339: loss 0.123970\n",
      "batch 1340: loss 0.027883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1341: loss 0.154748\n",
      "batch 1342: loss 0.087963\n",
      "batch 1343: loss 0.133031\n",
      "batch 1344: loss 0.142947\n",
      "batch 1345: loss 0.127596\n",
      "batch 1346: loss 0.133709\n",
      "batch 1347: loss 0.097252\n",
      "batch 1348: loss 0.229546\n",
      "batch 1349: loss 0.233560\n",
      "batch 1350: loss 0.072082\n",
      "batch 1351: loss 0.096195\n",
      "batch 1352: loss 0.156937\n",
      "batch 1353: loss 0.074492\n",
      "batch 1354: loss 0.140459\n",
      "batch 1355: loss 0.132774\n",
      "batch 1356: loss 0.082736\n",
      "batch 1357: loss 0.134929\n",
      "batch 1358: loss 0.075598\n",
      "batch 1359: loss 0.103545\n",
      "batch 1360: loss 0.085108\n",
      "batch 1361: loss 0.203485\n",
      "batch 1362: loss 0.072804\n",
      "batch 1363: loss 0.127868\n",
      "batch 1364: loss 0.319042\n",
      "batch 1365: loss 0.071953\n",
      "batch 1366: loss 0.040803\n",
      "batch 1367: loss 0.233312\n",
      "batch 1368: loss 0.200146\n",
      "batch 1369: loss 0.133670\n",
      "batch 1370: loss 0.256150\n",
      "batch 1371: loss 0.131899\n",
      "batch 1372: loss 0.061795\n",
      "batch 1373: loss 0.075071\n",
      "batch 1374: loss 0.193443\n",
      "batch 1375: loss 0.180886\n",
      "batch 1376: loss 0.140202\n",
      "batch 1377: loss 0.265849\n",
      "batch 1378: loss 0.311208\n",
      "batch 1379: loss 0.172975\n",
      "batch 1380: loss 0.124615\n",
      "batch 1381: loss 0.203603\n",
      "batch 1382: loss 0.144542\n",
      "batch 1383: loss 0.250503\n",
      "batch 1384: loss 0.303532\n",
      "batch 1385: loss 0.116235\n",
      "batch 1386: loss 0.196743\n",
      "batch 1387: loss 0.153209\n",
      "batch 1388: loss 0.118929\n",
      "batch 1389: loss 0.108455\n",
      "batch 1390: loss 0.069868\n",
      "batch 1391: loss 0.095093\n",
      "batch 1392: loss 0.228318\n",
      "batch 1393: loss 0.090620\n",
      "batch 1394: loss 0.238700\n",
      "batch 1395: loss 0.025433\n",
      "batch 1396: loss 0.102776\n",
      "batch 1397: loss 0.090103\n",
      "batch 1398: loss 0.168829\n",
      "batch 1399: loss 0.117559\n",
      "batch 1400: loss 0.199175\n",
      "batch 1401: loss 0.407137\n",
      "batch 1402: loss 0.071580\n",
      "batch 1403: loss 0.367016\n",
      "batch 1404: loss 0.110065\n",
      "batch 1405: loss 0.278575\n",
      "batch 1406: loss 0.109704\n",
      "batch 1407: loss 0.185458\n",
      "batch 1408: loss 0.225001\n",
      "batch 1409: loss 0.378076\n",
      "batch 1410: loss 0.067286\n",
      "batch 1411: loss 0.140592\n",
      "batch 1412: loss 0.140891\n",
      "batch 1413: loss 0.180551\n",
      "batch 1414: loss 0.234558\n",
      "batch 1415: loss 0.116539\n",
      "batch 1416: loss 0.170369\n",
      "batch 1417: loss 0.103579\n",
      "batch 1418: loss 0.134804\n",
      "batch 1419: loss 0.149723\n",
      "batch 1420: loss 0.359453\n",
      "batch 1421: loss 0.167397\n",
      "batch 1422: loss 0.090411\n",
      "batch 1423: loss 0.052517\n",
      "batch 1424: loss 0.170427\n",
      "batch 1425: loss 0.110432\n",
      "batch 1426: loss 0.130081\n",
      "batch 1427: loss 0.176736\n",
      "batch 1428: loss 0.110220\n",
      "batch 1429: loss 0.092865\n",
      "batch 1430: loss 0.056730\n",
      "batch 1431: loss 0.084169\n",
      "batch 1432: loss 0.163844\n",
      "batch 1433: loss 0.159894\n",
      "batch 1434: loss 0.314148\n",
      "batch 1435: loss 0.098643\n",
      "batch 1436: loss 0.089248\n",
      "batch 1437: loss 0.075923\n",
      "batch 1438: loss 0.221930\n",
      "batch 1439: loss 0.365069\n",
      "batch 1440: loss 0.104605\n",
      "batch 1441: loss 0.119622\n",
      "batch 1442: loss 0.169501\n",
      "batch 1443: loss 0.150715\n",
      "batch 1444: loss 0.069847\n",
      "batch 1445: loss 0.172275\n",
      "batch 1446: loss 0.076737\n",
      "batch 1447: loss 0.049951\n",
      "batch 1448: loss 0.122924\n",
      "batch 1449: loss 0.121679\n",
      "batch 1450: loss 0.121672\n",
      "batch 1451: loss 0.161216\n",
      "batch 1452: loss 0.121597\n",
      "batch 1453: loss 0.071551\n",
      "batch 1454: loss 0.093891\n",
      "batch 1455: loss 0.136002\n",
      "batch 1456: loss 0.253053\n",
      "batch 1457: loss 0.088294\n",
      "batch 1458: loss 0.090811\n",
      "batch 1459: loss 0.081404\n",
      "batch 1460: loss 0.270309\n",
      "batch 1461: loss 0.076039\n",
      "batch 1462: loss 0.121323\n",
      "batch 1463: loss 0.040311\n",
      "batch 1464: loss 0.225965\n",
      "batch 1465: loss 0.133323\n",
      "batch 1466: loss 0.112004\n",
      "batch 1467: loss 0.085771\n",
      "batch 1468: loss 0.102945\n",
      "batch 1469: loss 0.313407\n",
      "batch 1470: loss 0.117824\n",
      "batch 1471: loss 0.137286\n",
      "batch 1472: loss 0.215566\n",
      "batch 1473: loss 0.266527\n",
      "batch 1474: loss 0.093154\n",
      "batch 1475: loss 0.036079\n",
      "batch 1476: loss 0.085400\n",
      "batch 1477: loss 0.232978\n",
      "batch 1478: loss 0.140775\n",
      "batch 1479: loss 0.072368\n",
      "batch 1480: loss 0.054066\n",
      "batch 1481: loss 0.224273\n",
      "batch 1482: loss 0.064825\n",
      "batch 1483: loss 0.194122\n",
      "batch 1484: loss 0.124653\n",
      "batch 1485: loss 0.107368\n",
      "batch 1486: loss 0.147470\n",
      "batch 1487: loss 0.086014\n",
      "batch 1488: loss 0.137196\n",
      "batch 1489: loss 0.393609\n",
      "batch 1490: loss 0.063324\n",
      "batch 1491: loss 0.158501\n",
      "batch 1492: loss 0.067902\n",
      "batch 1493: loss 0.127339\n",
      "batch 1494: loss 0.169554\n",
      "batch 1495: loss 0.182318\n",
      "batch 1496: loss 0.111995\n",
      "batch 1497: loss 0.091486\n",
      "batch 1498: loss 0.061222\n",
      "batch 1499: loss 0.320425\n",
      "batch 1500: loss 0.117425\n",
      "batch 1501: loss 0.098811\n",
      "batch 1502: loss 0.040449\n",
      "batch 1503: loss 0.056291\n",
      "batch 1504: loss 0.143451\n",
      "batch 1505: loss 0.127177\n",
      "batch 1506: loss 0.225834\n",
      "batch 1507: loss 0.203080\n",
      "batch 1508: loss 0.090498\n",
      "batch 1509: loss 0.187446\n",
      "batch 1510: loss 0.075665\n",
      "batch 1511: loss 0.216532\n",
      "batch 1512: loss 0.188784\n",
      "batch 1513: loss 0.336008\n",
      "batch 1514: loss 0.152180\n",
      "batch 1515: loss 0.073569\n",
      "batch 1516: loss 0.310044\n",
      "batch 1517: loss 0.175265\n",
      "batch 1518: loss 0.178541\n",
      "batch 1519: loss 0.152127\n",
      "batch 1520: loss 0.095251\n",
      "batch 1521: loss 0.074612\n",
      "batch 1522: loss 0.081326\n",
      "batch 1523: loss 0.313165\n",
      "batch 1524: loss 0.093790\n",
      "batch 1525: loss 0.138501\n",
      "batch 1526: loss 0.109785\n",
      "batch 1527: loss 0.156217\n",
      "batch 1528: loss 0.119076\n",
      "batch 1529: loss 0.051862\n",
      "batch 1530: loss 0.344054\n",
      "batch 1531: loss 0.027178\n",
      "batch 1532: loss 0.183242\n",
      "batch 1533: loss 0.154658\n",
      "batch 1534: loss 0.100107\n",
      "batch 1535: loss 0.122304\n",
      "batch 1536: loss 0.165495\n",
      "batch 1537: loss 0.083061\n",
      "batch 1538: loss 0.233383\n",
      "batch 1539: loss 0.061562\n",
      "batch 1540: loss 0.084091\n",
      "batch 1541: loss 0.054345\n",
      "batch 1542: loss 0.076471\n",
      "batch 1543: loss 0.113861\n",
      "batch 1544: loss 0.246853\n",
      "batch 1545: loss 0.354704\n",
      "batch 1546: loss 0.285279\n",
      "batch 1547: loss 0.098866\n",
      "batch 1548: loss 0.122391\n",
      "batch 1549: loss 0.038656\n",
      "batch 1550: loss 0.032452\n",
      "batch 1551: loss 0.268556\n",
      "batch 1552: loss 0.153396\n",
      "batch 1553: loss 0.148276\n",
      "batch 1554: loss 0.077328\n",
      "batch 1555: loss 0.291974\n",
      "batch 1556: loss 0.070660\n",
      "batch 1557: loss 0.066078\n",
      "batch 1558: loss 0.107593\n",
      "batch 1559: loss 0.164317\n",
      "batch 1560: loss 0.099355\n",
      "batch 1561: loss 0.216075\n",
      "batch 1562: loss 0.249022\n",
      "batch 1563: loss 0.058988\n",
      "batch 1564: loss 0.078348\n",
      "batch 1565: loss 0.062883\n",
      "batch 1566: loss 0.142197\n",
      "batch 1567: loss 0.160981\n",
      "batch 1568: loss 0.068294\n",
      "batch 1569: loss 0.131912\n",
      "batch 1570: loss 0.235152\n",
      "batch 1571: loss 0.208924\n",
      "batch 1572: loss 0.161955\n",
      "batch 1573: loss 0.098910\n",
      "batch 1574: loss 0.152681\n",
      "batch 1575: loss 0.161078\n",
      "batch 1576: loss 0.132395\n",
      "batch 1577: loss 0.073016\n",
      "batch 1578: loss 0.286569\n",
      "batch 1579: loss 0.258484\n",
      "batch 1580: loss 0.127609\n",
      "batch 1581: loss 0.184855\n",
      "batch 1582: loss 0.040615\n",
      "batch 1583: loss 0.295962\n",
      "batch 1584: loss 0.165811\n",
      "batch 1585: loss 0.162167\n",
      "batch 1586: loss 0.075059\n",
      "batch 1587: loss 0.329118\n",
      "batch 1588: loss 0.100868\n",
      "batch 1589: loss 0.131933\n",
      "batch 1590: loss 0.096353\n",
      "batch 1591: loss 0.254515\n",
      "batch 1592: loss 0.053991\n",
      "batch 1593: loss 0.320146\n",
      "batch 1594: loss 0.180720\n",
      "batch 1595: loss 0.249762\n",
      "batch 1596: loss 0.030040\n",
      "batch 1597: loss 0.149442\n",
      "batch 1598: loss 0.177873\n",
      "batch 1599: loss 0.040816\n",
      "batch 1600: loss 0.079202\n",
      "batch 1601: loss 0.122242\n",
      "batch 1602: loss 0.149737\n",
      "batch 1603: loss 0.200315\n",
      "batch 1604: loss 0.282393\n",
      "batch 1605: loss 0.211654\n",
      "batch 1606: loss 0.186442\n",
      "batch 1607: loss 0.097985\n",
      "batch 1608: loss 0.042338\n",
      "batch 1609: loss 0.129873\n",
      "batch 1610: loss 0.186642\n",
      "batch 1611: loss 0.185674\n",
      "batch 1612: loss 0.105162\n",
      "batch 1613: loss 0.131136\n",
      "batch 1614: loss 0.105762\n",
      "batch 1615: loss 0.068672\n",
      "batch 1616: loss 0.163975\n",
      "batch 1617: loss 0.134983\n",
      "batch 1618: loss 0.132495\n",
      "batch 1619: loss 0.189738\n",
      "batch 1620: loss 0.183894\n",
      "batch 1621: loss 0.162465\n",
      "batch 1622: loss 0.075700\n",
      "batch 1623: loss 0.121778\n",
      "batch 1624: loss 0.062760\n",
      "batch 1625: loss 0.154742\n",
      "batch 1626: loss 0.086770\n",
      "batch 1627: loss 0.371108\n",
      "batch 1628: loss 0.044881\n",
      "batch 1629: loss 0.063187\n",
      "batch 1630: loss 0.106392\n",
      "batch 1631: loss 0.037031\n",
      "batch 1632: loss 0.185447\n",
      "batch 1633: loss 0.098474\n",
      "batch 1634: loss 0.174106\n",
      "batch 1635: loss 0.128655\n",
      "batch 1636: loss 0.086284\n",
      "batch 1637: loss 0.161811\n",
      "batch 1638: loss 0.085712\n",
      "batch 1639: loss 0.186073\n",
      "batch 1640: loss 0.340162\n",
      "batch 1641: loss 0.035501\n",
      "batch 1642: loss 0.092708\n",
      "batch 1643: loss 0.055366\n",
      "batch 1644: loss 0.150995\n",
      "batch 1645: loss 0.055490\n",
      "batch 1646: loss 0.147180\n",
      "batch 1647: loss 0.130440\n",
      "batch 1648: loss 0.208115\n",
      "batch 1649: loss 0.049077\n",
      "batch 1650: loss 0.069204\n",
      "batch 1651: loss 0.112969\n",
      "batch 1652: loss 0.157088\n",
      "batch 1653: loss 0.128594\n",
      "batch 1654: loss 0.089187\n",
      "batch 1655: loss 0.106103\n",
      "batch 1656: loss 0.185104\n",
      "batch 1657: loss 0.080450\n",
      "batch 1658: loss 0.089527\n",
      "batch 1659: loss 0.219247\n",
      "batch 1660: loss 0.072016\n",
      "batch 1661: loss 0.152573\n",
      "batch 1662: loss 0.208167\n",
      "batch 1663: loss 0.073372\n",
      "batch 1664: loss 0.231477\n",
      "batch 1665: loss 0.097235\n",
      "batch 1666: loss 0.125351\n",
      "batch 1667: loss 0.058476\n",
      "batch 1668: loss 0.099338\n",
      "batch 1669: loss 0.168908\n",
      "batch 1670: loss 0.160035\n",
      "batch 1671: loss 0.079717\n",
      "batch 1672: loss 0.379288\n",
      "batch 1673: loss 0.047941\n",
      "batch 1674: loss 0.122960\n",
      "batch 1675: loss 0.057239\n",
      "batch 1676: loss 0.140345\n",
      "batch 1677: loss 0.332039\n",
      "batch 1678: loss 0.251295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1679: loss 0.234198\n",
      "batch 1680: loss 0.046610\n",
      "batch 1681: loss 0.060960\n",
      "batch 1682: loss 0.151495\n",
      "batch 1683: loss 0.108967\n",
      "batch 1684: loss 0.137659\n",
      "batch 1685: loss 0.049222\n",
      "batch 1686: loss 0.222519\n",
      "batch 1687: loss 0.077001\n",
      "batch 1688: loss 0.134183\n",
      "batch 1689: loss 0.043086\n",
      "batch 1690: loss 0.192661\n",
      "batch 1691: loss 0.231231\n",
      "batch 1692: loss 0.087949\n",
      "batch 1693: loss 0.211083\n",
      "batch 1694: loss 0.222689\n",
      "batch 1695: loss 0.172486\n",
      "batch 1696: loss 0.075634\n",
      "batch 1697: loss 0.252229\n",
      "batch 1698: loss 0.077829\n",
      "batch 1699: loss 0.131433\n",
      "batch 1700: loss 0.141713\n",
      "batch 1701: loss 0.231697\n",
      "batch 1702: loss 0.283069\n",
      "batch 1703: loss 0.072943\n",
      "batch 1704: loss 0.049865\n",
      "batch 1705: loss 0.098785\n",
      "batch 1706: loss 0.135179\n",
      "batch 1707: loss 0.227527\n",
      "batch 1708: loss 0.341239\n",
      "batch 1709: loss 0.253548\n",
      "batch 1710: loss 0.118332\n",
      "batch 1711: loss 0.048732\n",
      "batch 1712: loss 0.078513\n",
      "batch 1713: loss 0.163374\n",
      "batch 1714: loss 0.206944\n",
      "batch 1715: loss 0.130391\n",
      "batch 1716: loss 0.170963\n",
      "batch 1717: loss 0.125274\n",
      "batch 1718: loss 0.188252\n",
      "batch 1719: loss 0.110521\n",
      "batch 1720: loss 0.083247\n",
      "batch 1721: loss 0.228014\n",
      "batch 1722: loss 0.051724\n",
      "batch 1723: loss 0.183625\n",
      "batch 1724: loss 0.182550\n",
      "batch 1725: loss 0.134280\n",
      "batch 1726: loss 0.115967\n",
      "batch 1727: loss 0.079612\n",
      "batch 1728: loss 0.299003\n",
      "batch 1729: loss 0.117548\n",
      "batch 1730: loss 0.075530\n",
      "batch 1731: loss 0.229282\n",
      "batch 1732: loss 0.106347\n",
      "batch 1733: loss 0.101238\n",
      "batch 1734: loss 0.178721\n",
      "batch 1735: loss 0.041401\n",
      "batch 1736: loss 0.098222\n",
      "batch 1737: loss 0.050276\n",
      "batch 1738: loss 0.102347\n",
      "batch 1739: loss 0.060405\n",
      "batch 1740: loss 0.204893\n",
      "batch 1741: loss 0.127276\n",
      "batch 1742: loss 0.164078\n",
      "batch 1743: loss 0.099634\n",
      "batch 1744: loss 0.157172\n",
      "batch 1745: loss 0.159668\n",
      "batch 1746: loss 0.047145\n",
      "batch 1747: loss 0.237105\n",
      "batch 1748: loss 0.058066\n",
      "batch 1749: loss 0.102511\n",
      "batch 1750: loss 0.028989\n",
      "batch 1751: loss 0.041540\n",
      "batch 1752: loss 0.199387\n",
      "batch 1753: loss 0.240017\n",
      "batch 1754: loss 0.044298\n",
      "batch 1755: loss 0.141078\n",
      "batch 1756: loss 0.071708\n",
      "batch 1757: loss 0.168080\n",
      "batch 1758: loss 0.113508\n",
      "batch 1759: loss 0.122917\n",
      "batch 1760: loss 0.115548\n",
      "batch 1761: loss 0.076244\n",
      "batch 1762: loss 0.103844\n",
      "batch 1763: loss 0.061669\n",
      "batch 1764: loss 0.117989\n",
      "batch 1765: loss 0.118577\n",
      "batch 1766: loss 0.136076\n",
      "batch 1767: loss 0.053318\n",
      "batch 1768: loss 0.307241\n",
      "batch 1769: loss 0.132024\n",
      "batch 1770: loss 0.177189\n",
      "batch 1771: loss 0.223348\n",
      "batch 1772: loss 0.211132\n",
      "batch 1773: loss 0.081451\n",
      "batch 1774: loss 0.112491\n",
      "batch 1775: loss 0.160210\n",
      "batch 1776: loss 0.095702\n",
      "batch 1777: loss 0.173807\n",
      "batch 1778: loss 0.097210\n",
      "batch 1779: loss 0.085622\n",
      "batch 1780: loss 0.075710\n",
      "batch 1781: loss 0.100094\n",
      "batch 1782: loss 0.056328\n",
      "batch 1783: loss 0.102996\n",
      "batch 1784: loss 0.043560\n",
      "batch 1785: loss 0.065729\n",
      "batch 1786: loss 0.072381\n",
      "batch 1787: loss 0.211053\n",
      "batch 1788: loss 0.246484\n",
      "batch 1789: loss 0.119832\n",
      "batch 1790: loss 0.096832\n",
      "batch 1791: loss 0.047147\n",
      "batch 1792: loss 0.067087\n",
      "batch 1793: loss 0.058191\n",
      "batch 1794: loss 0.058921\n",
      "batch 1795: loss 0.056422\n",
      "batch 1796: loss 0.062643\n",
      "batch 1797: loss 0.064809\n",
      "batch 1798: loss 0.197941\n",
      "batch 1799: loss 0.099844\n",
      "batch 1800: loss 0.306209\n",
      "batch 1801: loss 0.073939\n",
      "batch 1802: loss 0.152155\n",
      "batch 1803: loss 0.264640\n",
      "batch 1804: loss 0.079684\n",
      "batch 1805: loss 0.320907\n",
      "batch 1806: loss 0.099550\n",
      "batch 1807: loss 0.098931\n",
      "batch 1808: loss 0.096267\n",
      "batch 1809: loss 0.116212\n",
      "batch 1810: loss 0.160199\n",
      "batch 1811: loss 0.060430\n",
      "batch 1812: loss 0.043771\n",
      "batch 1813: loss 0.078081\n",
      "batch 1814: loss 0.043828\n",
      "batch 1815: loss 0.170012\n",
      "batch 1816: loss 0.098219\n",
      "batch 1817: loss 0.196160\n",
      "batch 1818: loss 0.135073\n",
      "batch 1819: loss 0.205948\n",
      "batch 1820: loss 0.126127\n",
      "batch 1821: loss 0.090573\n",
      "batch 1822: loss 0.053165\n",
      "batch 1823: loss 0.117481\n",
      "batch 1824: loss 0.114710\n",
      "batch 1825: loss 0.028183\n",
      "batch 1826: loss 0.160420\n",
      "batch 1827: loss 0.127613\n",
      "batch 1828: loss 0.064874\n",
      "batch 1829: loss 0.120064\n",
      "batch 1830: loss 0.087005\n",
      "batch 1831: loss 0.319288\n",
      "batch 1832: loss 0.195555\n",
      "batch 1833: loss 0.241859\n",
      "batch 1834: loss 0.120243\n",
      "batch 1835: loss 0.241756\n",
      "batch 1836: loss 0.119200\n",
      "batch 1837: loss 0.131598\n",
      "batch 1838: loss 0.059485\n",
      "batch 1839: loss 0.030878\n",
      "batch 1840: loss 0.209982\n",
      "batch 1841: loss 0.177054\n",
      "batch 1842: loss 0.055464\n",
      "batch 1843: loss 0.107134\n",
      "batch 1844: loss 0.185808\n",
      "batch 1845: loss 0.063300\n",
      "batch 1846: loss 0.025026\n",
      "batch 1847: loss 0.094947\n",
      "batch 1848: loss 0.150524\n",
      "batch 1849: loss 0.183127\n",
      "batch 1850: loss 0.054719\n",
      "batch 1851: loss 0.287966\n",
      "batch 1852: loss 0.252274\n",
      "batch 1853: loss 0.072863\n",
      "batch 1854: loss 0.237011\n",
      "batch 1855: loss 0.129119\n",
      "batch 1856: loss 0.104074\n",
      "batch 1857: loss 0.176570\n",
      "batch 1858: loss 0.155844\n",
      "batch 1859: loss 0.156129\n",
      "batch 1860: loss 0.187093\n",
      "batch 1861: loss 0.132099\n",
      "batch 1862: loss 0.032170\n",
      "batch 1863: loss 0.213581\n",
      "batch 1864: loss 0.062434\n",
      "batch 1865: loss 0.216911\n",
      "batch 1866: loss 0.149863\n",
      "batch 1867: loss 0.054888\n",
      "batch 1868: loss 0.137262\n",
      "batch 1869: loss 0.072327\n",
      "batch 1870: loss 0.058624\n",
      "batch 1871: loss 0.076178\n",
      "batch 1872: loss 0.205902\n",
      "batch 1873: loss 0.132168\n",
      "batch 1874: loss 0.193243\n",
      "batch 1875: loss 0.197153\n",
      "batch 1876: loss 0.134997\n",
      "batch 1877: loss 0.027440\n",
      "batch 1878: loss 0.166484\n",
      "batch 1879: loss 0.212224\n",
      "batch 1880: loss 0.165300\n",
      "batch 1881: loss 0.078001\n",
      "batch 1882: loss 0.076223\n",
      "batch 1883: loss 0.066070\n",
      "batch 1884: loss 0.396078\n",
      "batch 1885: loss 0.102657\n",
      "batch 1886: loss 0.100561\n",
      "batch 1887: loss 0.173771\n",
      "batch 1888: loss 0.099303\n",
      "batch 1889: loss 0.108063\n",
      "batch 1890: loss 0.080323\n",
      "batch 1891: loss 0.111313\n",
      "batch 1892: loss 0.121184\n",
      "batch 1893: loss 0.396080\n",
      "batch 1894: loss 0.220865\n",
      "batch 1895: loss 0.064477\n",
      "batch 1896: loss 0.113137\n",
      "batch 1897: loss 0.113545\n",
      "batch 1898: loss 0.149824\n",
      "batch 1899: loss 0.044596\n",
      "batch 1900: loss 0.141778\n",
      "batch 1901: loss 0.049784\n",
      "batch 1902: loss 0.184018\n",
      "batch 1903: loss 0.087444\n",
      "batch 1904: loss 0.155119\n",
      "batch 1905: loss 0.065007\n",
      "batch 1906: loss 0.214484\n",
      "batch 1907: loss 0.065847\n",
      "batch 1908: loss 0.052227\n",
      "batch 1909: loss 0.069661\n",
      "batch 1910: loss 0.079919\n",
      "batch 1911: loss 0.044018\n",
      "batch 1912: loss 0.161132\n",
      "batch 1913: loss 0.112529\n",
      "batch 1914: loss 0.090704\n",
      "batch 1915: loss 0.181011\n",
      "batch 1916: loss 0.091452\n",
      "batch 1917: loss 0.047551\n",
      "batch 1918: loss 0.106479\n",
      "batch 1919: loss 0.127544\n",
      "batch 1920: loss 0.049675\n",
      "batch 1921: loss 0.189289\n",
      "batch 1922: loss 0.092884\n",
      "batch 1923: loss 0.096243\n",
      "batch 1924: loss 0.160016\n",
      "batch 1925: loss 0.035714\n",
      "batch 1926: loss 0.179528\n",
      "batch 1927: loss 0.073538\n",
      "batch 1928: loss 0.081149\n",
      "batch 1929: loss 0.080509\n",
      "batch 1930: loss 0.086903\n",
      "batch 1931: loss 0.035642\n",
      "batch 1932: loss 0.104240\n",
      "batch 1933: loss 0.050567\n",
      "batch 1934: loss 0.099354\n",
      "batch 1935: loss 0.095600\n",
      "batch 1936: loss 0.024043\n",
      "batch 1937: loss 0.257369\n",
      "batch 1938: loss 0.075774\n",
      "batch 1939: loss 0.082522\n",
      "batch 1940: loss 0.064659\n",
      "batch 1941: loss 0.074966\n",
      "batch 1942: loss 0.044531\n",
      "batch 1943: loss 0.117746\n",
      "batch 1944: loss 0.017270\n",
      "batch 1945: loss 0.068046\n",
      "batch 1946: loss 0.125817\n",
      "batch 1947: loss 0.274741\n",
      "batch 1948: loss 0.075255\n",
      "batch 1949: loss 0.017719\n",
      "batch 1950: loss 0.045015\n",
      "batch 1951: loss 0.057485\n",
      "batch 1952: loss 0.150167\n",
      "batch 1953: loss 0.170029\n",
      "batch 1954: loss 0.069887\n",
      "batch 1955: loss 0.117789\n",
      "batch 1956: loss 0.156706\n",
      "batch 1957: loss 0.152870\n",
      "batch 1958: loss 0.290900\n",
      "batch 1959: loss 0.216280\n",
      "batch 1960: loss 0.266160\n",
      "batch 1961: loss 0.131569\n",
      "batch 1962: loss 0.063162\n",
      "batch 1963: loss 0.191101\n",
      "batch 1964: loss 0.131321\n",
      "batch 1965: loss 0.184026\n",
      "batch 1966: loss 0.068151\n",
      "batch 1967: loss 0.175582\n",
      "batch 1968: loss 0.236750\n",
      "batch 1969: loss 0.090611\n",
      "batch 1970: loss 0.032266\n",
      "batch 1971: loss 0.041268\n",
      "batch 1972: loss 0.104512\n",
      "batch 1973: loss 0.148008\n",
      "batch 1974: loss 0.041226\n",
      "batch 1975: loss 0.081143\n",
      "batch 1976: loss 0.046433\n",
      "batch 1977: loss 0.069151\n",
      "batch 1978: loss 0.031413\n",
      "batch 1979: loss 0.344604\n",
      "batch 1980: loss 0.126789\n",
      "batch 1981: loss 0.123410\n",
      "batch 1982: loss 0.213709\n",
      "batch 1983: loss 0.068345\n",
      "batch 1984: loss 0.167401\n",
      "batch 1985: loss 0.087712\n",
      "batch 1986: loss 0.202108\n",
      "batch 1987: loss 0.044149\n",
      "batch 1988: loss 0.156324\n",
      "batch 1989: loss 0.029362\n",
      "batch 1990: loss 0.129446\n",
      "batch 1991: loss 0.042930\n",
      "batch 1992: loss 0.068275\n",
      "batch 1993: loss 0.173329\n",
      "batch 1994: loss 0.116957\n",
      "batch 1995: loss 0.055834\n",
      "batch 1996: loss 0.071289\n",
      "batch 1997: loss 0.098828\n",
      "batch 1998: loss 0.283186\n",
      "batch 1999: loss 0.092633\n",
      "batch 2000: loss 0.287670\n",
      "batch 2001: loss 0.086540\n",
      "batch 2002: loss 0.042188\n",
      "batch 2003: loss 0.092564\n",
      "batch 2004: loss 0.066173\n",
      "batch 2005: loss 0.153597\n",
      "batch 2006: loss 0.051787\n",
      "batch 2007: loss 0.027631\n",
      "batch 2008: loss 0.123033\n",
      "batch 2009: loss 0.075042\n",
      "batch 2010: loss 0.041852\n",
      "batch 2011: loss 0.161191\n",
      "batch 2012: loss 0.183403\n",
      "batch 2013: loss 0.060950\n",
      "batch 2014: loss 0.117368\n",
      "batch 2015: loss 0.071463\n",
      "batch 2016: loss 0.043533\n",
      "batch 2017: loss 0.127776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2018: loss 0.073631\n",
      "batch 2019: loss 0.068210\n",
      "batch 2020: loss 0.353305\n",
      "batch 2021: loss 0.141389\n",
      "batch 2022: loss 0.114661\n",
      "batch 2023: loss 0.216378\n",
      "batch 2024: loss 0.067543\n",
      "batch 2025: loss 0.298857\n",
      "batch 2026: loss 0.059981\n",
      "batch 2027: loss 0.065037\n",
      "batch 2028: loss 0.033319\n",
      "batch 2029: loss 0.039643\n",
      "batch 2030: loss 0.295403\n",
      "batch 2031: loss 0.111665\n",
      "batch 2032: loss 0.118637\n",
      "batch 2033: loss 0.025287\n",
      "batch 2034: loss 0.146813\n",
      "batch 2035: loss 0.075870\n",
      "batch 2036: loss 0.316391\n",
      "batch 2037: loss 0.052660\n",
      "batch 2038: loss 0.160141\n",
      "batch 2039: loss 0.059286\n",
      "batch 2040: loss 0.097738\n",
      "batch 2041: loss 0.039095\n",
      "batch 2042: loss 0.077879\n",
      "batch 2043: loss 0.150620\n",
      "batch 2044: loss 0.068997\n",
      "batch 2045: loss 0.091090\n",
      "batch 2046: loss 0.085704\n",
      "batch 2047: loss 0.063647\n",
      "batch 2048: loss 0.120590\n",
      "batch 2049: loss 0.070650\n",
      "batch 2050: loss 0.091913\n",
      "batch 2051: loss 0.109092\n",
      "batch 2052: loss 0.199356\n",
      "batch 2053: loss 0.133844\n",
      "batch 2054: loss 0.121111\n",
      "batch 2055: loss 0.097331\n",
      "batch 2056: loss 0.051004\n",
      "batch 2057: loss 0.063358\n",
      "batch 2058: loss 0.074341\n",
      "batch 2059: loss 0.096567\n",
      "batch 2060: loss 0.191163\n",
      "batch 2061: loss 0.092959\n",
      "batch 2062: loss 0.047282\n",
      "batch 2063: loss 0.082084\n",
      "batch 2064: loss 0.131466\n",
      "batch 2065: loss 0.053897\n",
      "batch 2066: loss 0.064274\n",
      "batch 2067: loss 0.109624\n",
      "batch 2068: loss 0.064273\n",
      "batch 2069: loss 0.090439\n",
      "batch 2070: loss 0.087170\n",
      "batch 2071: loss 0.257468\n",
      "batch 2072: loss 0.063982\n",
      "batch 2073: loss 0.159802\n",
      "batch 2074: loss 0.318020\n",
      "batch 2075: loss 0.014773\n",
      "batch 2076: loss 0.080073\n",
      "batch 2077: loss 0.022186\n",
      "batch 2078: loss 0.067807\n",
      "batch 2079: loss 0.045669\n",
      "batch 2080: loss 0.159482\n",
      "batch 2081: loss 0.259277\n",
      "batch 2082: loss 0.123632\n",
      "batch 2083: loss 0.101735\n",
      "batch 2084: loss 0.034421\n",
      "batch 2085: loss 0.035601\n",
      "batch 2086: loss 0.085817\n",
      "batch 2087: loss 0.243213\n",
      "batch 2088: loss 0.119018\n",
      "batch 2089: loss 0.048240\n",
      "batch 2090: loss 0.278423\n",
      "batch 2091: loss 0.173052\n",
      "batch 2092: loss 0.130749\n",
      "batch 2093: loss 0.150360\n",
      "batch 2094: loss 0.165393\n",
      "batch 2095: loss 0.188239\n",
      "batch 2096: loss 0.135045\n",
      "batch 2097: loss 0.067789\n",
      "batch 2098: loss 0.028076\n",
      "batch 2099: loss 0.091880\n",
      "batch 2100: loss 0.131261\n",
      "batch 2101: loss 0.029940\n",
      "batch 2102: loss 0.080389\n",
      "batch 2103: loss 0.235003\n",
      "batch 2104: loss 0.198936\n",
      "batch 2105: loss 0.141159\n",
      "batch 2106: loss 0.072771\n",
      "batch 2107: loss 0.132187\n",
      "batch 2108: loss 0.182698\n",
      "batch 2109: loss 0.092828\n",
      "batch 2110: loss 0.144959\n",
      "batch 2111: loss 0.197175\n",
      "batch 2112: loss 0.103132\n",
      "batch 2113: loss 0.221468\n",
      "batch 2114: loss 0.027996\n",
      "batch 2115: loss 0.151013\n",
      "batch 2116: loss 0.070043\n",
      "batch 2117: loss 0.140743\n",
      "batch 2118: loss 0.116393\n",
      "batch 2119: loss 0.114664\n",
      "batch 2120: loss 0.161465\n",
      "batch 2121: loss 0.080927\n",
      "batch 2122: loss 0.144687\n",
      "batch 2123: loss 0.188830\n",
      "batch 2124: loss 0.137601\n",
      "batch 2125: loss 0.123379\n",
      "batch 2126: loss 0.084216\n",
      "batch 2127: loss 0.148848\n",
      "batch 2128: loss 0.138523\n",
      "batch 2129: loss 0.076081\n",
      "batch 2130: loss 0.222391\n",
      "batch 2131: loss 0.026919\n",
      "batch 2132: loss 0.199714\n",
      "batch 2133: loss 0.230602\n",
      "batch 2134: loss 0.049680\n",
      "batch 2135: loss 0.227945\n",
      "batch 2136: loss 0.076552\n",
      "batch 2137: loss 0.080559\n",
      "batch 2138: loss 0.034444\n",
      "batch 2139: loss 0.057456\n",
      "batch 2140: loss 0.136520\n",
      "batch 2141: loss 0.221428\n",
      "batch 2142: loss 0.143004\n",
      "batch 2143: loss 0.150844\n",
      "batch 2144: loss 0.080369\n",
      "batch 2145: loss 0.115948\n",
      "batch 2146: loss 0.082844\n",
      "batch 2147: loss 0.048381\n",
      "batch 2148: loss 0.185596\n",
      "batch 2149: loss 0.072980\n",
      "batch 2150: loss 0.215786\n",
      "batch 2151: loss 0.073690\n",
      "batch 2152: loss 0.015308\n",
      "batch 2153: loss 0.278887\n",
      "batch 2154: loss 0.148632\n",
      "batch 2155: loss 0.082546\n",
      "batch 2156: loss 0.205378\n",
      "batch 2157: loss 0.196814\n",
      "batch 2158: loss 0.125474\n",
      "batch 2159: loss 0.068538\n",
      "batch 2160: loss 0.045600\n",
      "batch 2161: loss 0.223588\n",
      "batch 2162: loss 0.046912\n",
      "batch 2163: loss 0.130557\n",
      "batch 2164: loss 0.055621\n",
      "batch 2165: loss 0.133263\n",
      "batch 2166: loss 0.136824\n",
      "batch 2167: loss 0.050615\n",
      "batch 2168: loss 0.079931\n",
      "batch 2169: loss 0.072721\n",
      "batch 2170: loss 0.045818\n",
      "batch 2171: loss 0.028660\n",
      "batch 2172: loss 0.057837\n",
      "batch 2173: loss 0.384828\n",
      "batch 2174: loss 0.191914\n",
      "batch 2175: loss 0.123849\n",
      "batch 2176: loss 0.276143\n",
      "batch 2177: loss 0.123670\n",
      "batch 2178: loss 0.077647\n",
      "batch 2179: loss 0.071425\n",
      "batch 2180: loss 0.135757\n",
      "batch 2181: loss 0.028444\n",
      "batch 2182: loss 0.075455\n",
      "batch 2183: loss 0.060177\n",
      "batch 2184: loss 0.174831\n",
      "batch 2185: loss 0.105034\n",
      "batch 2186: loss 0.074360\n",
      "batch 2187: loss 0.084472\n",
      "batch 2188: loss 0.074501\n",
      "batch 2189: loss 0.077223\n",
      "batch 2190: loss 0.076349\n",
      "batch 2191: loss 0.027045\n",
      "batch 2192: loss 0.026288\n",
      "batch 2193: loss 0.218344\n",
      "batch 2194: loss 0.265378\n",
      "batch 2195: loss 0.091284\n",
      "batch 2196: loss 0.072872\n",
      "batch 2197: loss 0.048932\n",
      "batch 2198: loss 0.309108\n",
      "batch 2199: loss 0.228420\n",
      "batch 2200: loss 0.066557\n",
      "batch 2201: loss 0.102525\n",
      "batch 2202: loss 0.118688\n",
      "batch 2203: loss 0.063380\n",
      "batch 2204: loss 0.227483\n",
      "batch 2205: loss 0.078889\n",
      "batch 2206: loss 0.033582\n",
      "batch 2207: loss 0.120033\n",
      "batch 2208: loss 0.131549\n",
      "batch 2209: loss 0.192283\n",
      "batch 2210: loss 0.057137\n",
      "batch 2211: loss 0.207000\n",
      "batch 2212: loss 0.028683\n",
      "batch 2213: loss 0.159933\n",
      "batch 2214: loss 0.131299\n",
      "batch 2215: loss 0.063833\n",
      "batch 2216: loss 0.068612\n",
      "batch 2217: loss 0.062815\n",
      "batch 2218: loss 0.037731\n",
      "batch 2219: loss 0.116138\n",
      "batch 2220: loss 0.108441\n",
      "batch 2221: loss 0.069979\n",
      "batch 2222: loss 0.039392\n",
      "batch 2223: loss 0.269204\n",
      "batch 2224: loss 0.098280\n",
      "batch 2225: loss 0.231043\n",
      "batch 2226: loss 0.125764\n",
      "batch 2227: loss 0.089570\n",
      "batch 2228: loss 0.041606\n",
      "batch 2229: loss 0.155492\n",
      "batch 2230: loss 0.034590\n",
      "batch 2231: loss 0.057353\n",
      "batch 2232: loss 0.092433\n",
      "batch 2233: loss 0.115649\n",
      "batch 2234: loss 0.464992\n",
      "batch 2235: loss 0.080325\n",
      "batch 2236: loss 0.032851\n",
      "batch 2237: loss 0.109613\n",
      "batch 2238: loss 0.128500\n",
      "batch 2239: loss 0.088097\n",
      "batch 2240: loss 0.049093\n",
      "batch 2241: loss 0.051294\n",
      "batch 2242: loss 0.034478\n",
      "batch 2243: loss 0.049189\n",
      "batch 2244: loss 0.162191\n",
      "batch 2245: loss 0.036842\n",
      "batch 2246: loss 0.098163\n",
      "batch 2247: loss 0.051548\n",
      "batch 2248: loss 0.118467\n",
      "batch 2249: loss 0.249057\n",
      "batch 2250: loss 0.085359\n",
      "batch 2251: loss 0.145640\n",
      "batch 2252: loss 0.184711\n",
      "batch 2253: loss 0.048013\n",
      "batch 2254: loss 0.129137\n",
      "batch 2255: loss 0.185166\n",
      "batch 2256: loss 0.079346\n",
      "batch 2257: loss 0.113666\n",
      "batch 2258: loss 0.122215\n",
      "batch 2259: loss 0.063818\n",
      "batch 2260: loss 0.315543\n",
      "batch 2261: loss 0.081766\n",
      "batch 2262: loss 0.179513\n",
      "batch 2263: loss 0.031796\n",
      "batch 2264: loss 0.055215\n",
      "batch 2265: loss 0.041435\n",
      "batch 2266: loss 0.073335\n",
      "batch 2267: loss 0.048077\n",
      "batch 2268: loss 0.107945\n",
      "batch 2269: loss 0.065235\n",
      "batch 2270: loss 0.085785\n",
      "batch 2271: loss 0.052102\n",
      "batch 2272: loss 0.139566\n",
      "batch 2273: loss 0.060939\n",
      "batch 2274: loss 0.072546\n",
      "batch 2275: loss 0.026936\n",
      "batch 2276: loss 0.034173\n",
      "batch 2277: loss 0.020838\n",
      "batch 2278: loss 0.075184\n",
      "batch 2279: loss 0.037587\n",
      "batch 2280: loss 0.094581\n",
      "batch 2281: loss 0.057132\n",
      "batch 2282: loss 0.027569\n",
      "batch 2283: loss 0.088905\n",
      "batch 2284: loss 0.117284\n",
      "batch 2285: loss 0.079316\n",
      "batch 2286: loss 0.138572\n",
      "batch 2287: loss 0.062091\n",
      "batch 2288: loss 0.041694\n",
      "batch 2289: loss 0.046992\n",
      "batch 2290: loss 0.321614\n",
      "batch 2291: loss 0.020521\n",
      "batch 2292: loss 0.104015\n",
      "batch 2293: loss 0.033263\n",
      "batch 2294: loss 0.156744\n",
      "batch 2295: loss 0.038902\n",
      "batch 2296: loss 0.091428\n",
      "batch 2297: loss 0.046455\n",
      "batch 2298: loss 0.163411\n",
      "batch 2299: loss 0.051970\n",
      "batch 2300: loss 0.038559\n",
      "batch 2301: loss 0.100268\n",
      "batch 2302: loss 0.097528\n",
      "batch 2303: loss 0.103848\n",
      "batch 2304: loss 0.132171\n",
      "batch 2305: loss 0.264006\n",
      "batch 2306: loss 0.052375\n",
      "batch 2307: loss 0.117579\n",
      "batch 2308: loss 0.057075\n",
      "batch 2309: loss 0.041689\n",
      "batch 2310: loss 0.059700\n",
      "batch 2311: loss 0.177946\n",
      "batch 2312: loss 0.149079\n",
      "batch 2313: loss 0.049050\n",
      "batch 2314: loss 0.148312\n",
      "batch 2315: loss 0.122116\n",
      "batch 2316: loss 0.034361\n",
      "batch 2317: loss 0.039811\n",
      "batch 2318: loss 0.083231\n",
      "batch 2319: loss 0.148327\n",
      "batch 2320: loss 0.088761\n",
      "batch 2321: loss 0.136745\n",
      "batch 2322: loss 0.054957\n",
      "batch 2323: loss 0.120337\n",
      "batch 2324: loss 0.162249\n",
      "batch 2325: loss 0.033718\n",
      "batch 2326: loss 0.092338\n",
      "batch 2327: loss 0.231777\n",
      "batch 2328: loss 0.040636\n",
      "batch 2329: loss 0.025026\n",
      "batch 2330: loss 0.020631\n",
      "batch 2331: loss 0.071576\n",
      "batch 2332: loss 0.057441\n",
      "batch 2333: loss 0.063830\n",
      "batch 2334: loss 0.060409\n",
      "batch 2335: loss 0.034716\n",
      "batch 2336: loss 0.155103\n",
      "batch 2337: loss 0.077981\n",
      "batch 2338: loss 0.041750\n",
      "batch 2339: loss 0.169521\n",
      "batch 2340: loss 0.268423\n",
      "batch 2341: loss 0.057450\n",
      "batch 2342: loss 0.028229\n",
      "batch 2343: loss 0.064929\n",
      "batch 2344: loss 0.023554\n",
      "batch 2345: loss 0.038225\n",
      "batch 2346: loss 0.066267\n",
      "batch 2347: loss 0.048361\n",
      "batch 2348: loss 0.122365\n",
      "batch 2349: loss 0.157660\n",
      "batch 2350: loss 0.124714\n",
      "batch 2351: loss 0.077169\n",
      "batch 2352: loss 0.295152\n",
      "batch 2353: loss 0.075658\n",
      "batch 2354: loss 0.077392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2355: loss 0.130350\n",
      "batch 2356: loss 0.246310\n",
      "batch 2357: loss 0.034481\n",
      "batch 2358: loss 0.020769\n",
      "batch 2359: loss 0.121668\n",
      "batch 2360: loss 0.063215\n",
      "batch 2361: loss 0.049488\n",
      "batch 2362: loss 0.202264\n",
      "batch 2363: loss 0.031086\n",
      "batch 2364: loss 0.060104\n",
      "batch 2365: loss 0.047621\n",
      "batch 2366: loss 0.154475\n",
      "batch 2367: loss 0.317391\n",
      "batch 2368: loss 0.017888\n",
      "batch 2369: loss 0.135021\n",
      "batch 2370: loss 0.067062\n",
      "batch 2371: loss 0.094890\n",
      "batch 2372: loss 0.037344\n",
      "batch 2373: loss 0.153989\n",
      "batch 2374: loss 0.190612\n",
      "batch 2375: loss 0.274292\n",
      "batch 2376: loss 0.094432\n",
      "batch 2377: loss 0.141967\n",
      "batch 2378: loss 0.027714\n",
      "batch 2379: loss 0.156208\n",
      "batch 2380: loss 0.114741\n",
      "batch 2381: loss 0.080494\n",
      "batch 2382: loss 0.098100\n",
      "batch 2383: loss 0.133565\n",
      "batch 2384: loss 0.023946\n",
      "batch 2385: loss 0.073382\n",
      "batch 2386: loss 0.094195\n",
      "batch 2387: loss 0.027692\n",
      "batch 2388: loss 0.044630\n",
      "batch 2389: loss 0.062117\n",
      "batch 2390: loss 0.065014\n",
      "batch 2391: loss 0.087378\n",
      "batch 2392: loss 0.056802\n",
      "batch 2393: loss 0.090687\n",
      "batch 2394: loss 0.087525\n",
      "batch 2395: loss 0.065708\n",
      "batch 2396: loss 0.056910\n",
      "batch 2397: loss 0.164486\n",
      "batch 2398: loss 0.117101\n",
      "batch 2399: loss 0.069466\n",
      "batch 2400: loss 0.099348\n",
      "batch 2401: loss 0.070829\n",
      "batch 2402: loss 0.109423\n",
      "batch 2403: loss 0.019054\n",
      "batch 2404: loss 0.025997\n",
      "batch 2405: loss 0.140744\n",
      "batch 2406: loss 0.045722\n",
      "batch 2407: loss 0.082207\n",
      "batch 2408: loss 0.062976\n",
      "batch 2409: loss 0.330463\n",
      "batch 2410: loss 0.135871\n",
      "batch 2411: loss 0.063384\n",
      "batch 2412: loss 0.058073\n",
      "batch 2413: loss 0.023482\n",
      "batch 2414: loss 0.125695\n",
      "batch 2415: loss 0.090393\n",
      "batch 2416: loss 0.050600\n",
      "batch 2417: loss 0.069800\n",
      "batch 2418: loss 0.135154\n",
      "batch 2419: loss 0.048032\n",
      "batch 2420: loss 0.089244\n",
      "batch 2421: loss 0.110408\n",
      "batch 2422: loss 0.136579\n",
      "batch 2423: loss 0.128101\n",
      "batch 2424: loss 0.089597\n",
      "batch 2425: loss 0.040594\n",
      "batch 2426: loss 0.092252\n",
      "batch 2427: loss 0.057154\n",
      "batch 2428: loss 0.195480\n",
      "batch 2429: loss 0.054644\n",
      "batch 2430: loss 0.517030\n",
      "batch 2431: loss 0.032960\n",
      "batch 2432: loss 0.101366\n",
      "batch 2433: loss 0.127185\n",
      "batch 2434: loss 0.055304\n",
      "batch 2435: loss 0.117378\n",
      "batch 2436: loss 0.170540\n",
      "batch 2437: loss 0.123209\n",
      "batch 2438: loss 0.179248\n",
      "batch 2439: loss 0.231538\n",
      "batch 2440: loss 0.137052\n",
      "batch 2441: loss 0.055377\n",
      "batch 2442: loss 0.077441\n",
      "batch 2443: loss 0.078632\n",
      "batch 2444: loss 0.106017\n",
      "batch 2445: loss 0.020123\n",
      "batch 2446: loss 0.136930\n",
      "batch 2447: loss 0.064021\n",
      "batch 2448: loss 0.167460\n",
      "batch 2449: loss 0.040808\n",
      "batch 2450: loss 0.037310\n",
      "batch 2451: loss 0.043007\n",
      "batch 2452: loss 0.148348\n",
      "batch 2453: loss 0.121462\n",
      "batch 2454: loss 0.160762\n",
      "batch 2455: loss 0.177230\n",
      "batch 2456: loss 0.100510\n",
      "batch 2457: loss 0.033882\n",
      "batch 2458: loss 0.085259\n",
      "batch 2459: loss 0.093867\n",
      "batch 2460: loss 0.060732\n",
      "batch 2461: loss 0.188421\n",
      "batch 2462: loss 0.074553\n",
      "batch 2463: loss 0.074138\n",
      "batch 2464: loss 0.069814\n",
      "batch 2465: loss 0.212190\n",
      "batch 2466: loss 0.056439\n",
      "batch 2467: loss 0.035439\n",
      "batch 2468: loss 0.121341\n",
      "batch 2469: loss 0.027022\n",
      "batch 2470: loss 0.052870\n",
      "batch 2471: loss 0.082706\n",
      "batch 2472: loss 0.059707\n",
      "batch 2473: loss 0.054609\n",
      "batch 2474: loss 0.132875\n",
      "batch 2475: loss 0.157167\n",
      "batch 2476: loss 0.095748\n",
      "batch 2477: loss 0.053450\n",
      "batch 2478: loss 0.080895\n",
      "batch 2479: loss 0.034505\n",
      "batch 2480: loss 0.094508\n",
      "batch 2481: loss 0.044359\n",
      "batch 2482: loss 0.064760\n",
      "batch 2483: loss 0.226100\n",
      "batch 2484: loss 0.072618\n",
      "batch 2485: loss 0.037535\n",
      "batch 2486: loss 0.043347\n",
      "batch 2487: loss 0.185043\n",
      "batch 2488: loss 0.073401\n",
      "batch 2489: loss 0.069245\n",
      "batch 2490: loss 0.073489\n",
      "batch 2491: loss 0.122577\n",
      "batch 2492: loss 0.026269\n",
      "batch 2493: loss 0.052930\n",
      "batch 2494: loss 0.138382\n",
      "batch 2495: loss 0.035492\n",
      "batch 2496: loss 0.135992\n",
      "batch 2497: loss 0.056764\n",
      "batch 2498: loss 0.067019\n",
      "batch 2499: loss 0.141468\n",
      "batch 2500: loss 0.309918\n",
      "batch 2501: loss 0.076711\n",
      "batch 2502: loss 0.100662\n",
      "batch 2503: loss 0.028142\n",
      "batch 2504: loss 0.045019\n",
      "batch 2505: loss 0.111856\n",
      "batch 2506: loss 0.075923\n",
      "batch 2507: loss 0.056887\n",
      "batch 2508: loss 0.166406\n",
      "batch 2509: loss 0.332434\n",
      "batch 2510: loss 0.023503\n",
      "batch 2511: loss 0.024943\n",
      "batch 2512: loss 0.122062\n",
      "batch 2513: loss 0.079554\n",
      "batch 2514: loss 0.074057\n",
      "batch 2515: loss 0.116962\n",
      "batch 2516: loss 0.158992\n",
      "batch 2517: loss 0.193021\n",
      "batch 2518: loss 0.082864\n",
      "batch 2519: loss 0.059165\n",
      "batch 2520: loss 0.141460\n",
      "batch 2521: loss 0.180312\n",
      "batch 2522: loss 0.087583\n",
      "batch 2523: loss 0.151734\n",
      "batch 2524: loss 0.200731\n",
      "batch 2525: loss 0.035851\n",
      "batch 2526: loss 0.078350\n",
      "batch 2527: loss 0.096515\n",
      "batch 2528: loss 0.092591\n",
      "batch 2529: loss 0.040640\n",
      "batch 2530: loss 0.087718\n",
      "batch 2531: loss 0.086497\n",
      "batch 2532: loss 0.035468\n",
      "batch 2533: loss 0.161897\n",
      "batch 2534: loss 0.053758\n",
      "batch 2535: loss 0.080499\n",
      "batch 2536: loss 0.191525\n",
      "batch 2537: loss 0.084458\n",
      "batch 2538: loss 0.112813\n",
      "batch 2539: loss 0.062264\n",
      "batch 2540: loss 0.078621\n",
      "batch 2541: loss 0.061294\n",
      "batch 2542: loss 0.089672\n",
      "batch 2543: loss 0.152315\n",
      "batch 2544: loss 0.225388\n",
      "batch 2545: loss 0.104740\n",
      "batch 2546: loss 0.055827\n",
      "batch 2547: loss 0.186532\n",
      "batch 2548: loss 0.119613\n",
      "batch 2549: loss 0.042581\n",
      "batch 2550: loss 0.076836\n",
      "batch 2551: loss 0.036210\n",
      "batch 2552: loss 0.109539\n",
      "batch 2553: loss 0.091028\n",
      "batch 2554: loss 0.138385\n",
      "batch 2555: loss 0.114192\n",
      "batch 2556: loss 0.112464\n",
      "batch 2557: loss 0.036207\n",
      "batch 2558: loss 0.086645\n",
      "batch 2559: loss 0.051435\n",
      "batch 2560: loss 0.023185\n",
      "batch 2561: loss 0.096145\n",
      "batch 2562: loss 0.143153\n",
      "batch 2563: loss 0.094233\n",
      "batch 2564: loss 0.034391\n",
      "batch 2565: loss 0.057841\n",
      "batch 2566: loss 0.178772\n",
      "batch 2567: loss 0.093862\n",
      "batch 2568: loss 0.069924\n",
      "batch 2569: loss 0.055766\n",
      "batch 2570: loss 0.251817\n",
      "batch 2571: loss 0.029157\n",
      "batch 2572: loss 0.033083\n",
      "batch 2573: loss 0.136426\n",
      "batch 2574: loss 0.050358\n",
      "batch 2575: loss 0.184052\n",
      "batch 2576: loss 0.066841\n",
      "batch 2577: loss 0.055464\n",
      "batch 2578: loss 0.053084\n",
      "batch 2579: loss 0.041395\n",
      "batch 2580: loss 0.137508\n",
      "batch 2581: loss 0.053791\n",
      "batch 2582: loss 0.110889\n",
      "batch 2583: loss 0.035739\n",
      "batch 2584: loss 0.056633\n",
      "batch 2585: loss 0.106759\n",
      "batch 2586: loss 0.103422\n",
      "batch 2587: loss 0.095185\n",
      "batch 2588: loss 0.072195\n",
      "batch 2589: loss 0.095130\n",
      "batch 2590: loss 0.032320\n",
      "batch 2591: loss 0.109669\n",
      "batch 2592: loss 0.051638\n",
      "batch 2593: loss 0.165809\n",
      "batch 2594: loss 0.082115\n",
      "batch 2595: loss 0.086791\n",
      "batch 2596: loss 0.058174\n",
      "batch 2597: loss 0.085006\n",
      "batch 2598: loss 0.092724\n",
      "batch 2599: loss 0.096919\n",
      "batch 2600: loss 0.191634\n",
      "batch 2601: loss 0.073542\n",
      "batch 2602: loss 0.102417\n",
      "batch 2603: loss 0.120340\n",
      "batch 2604: loss 0.044148\n",
      "batch 2605: loss 0.098337\n",
      "batch 2606: loss 0.195246\n",
      "batch 2607: loss 0.112260\n",
      "batch 2608: loss 0.056375\n",
      "batch 2609: loss 0.130629\n",
      "batch 2610: loss 0.056363\n",
      "batch 2611: loss 0.091091\n",
      "batch 2612: loss 0.119190\n",
      "batch 2613: loss 0.057945\n",
      "batch 2614: loss 0.102609\n",
      "batch 2615: loss 0.142532\n",
      "batch 2616: loss 0.125479\n",
      "batch 2617: loss 0.040502\n",
      "batch 2618: loss 0.392194\n",
      "batch 2619: loss 0.073040\n",
      "batch 2620: loss 0.086577\n",
      "batch 2621: loss 0.165499\n",
      "batch 2622: loss 0.303763\n",
      "batch 2623: loss 0.017123\n",
      "batch 2624: loss 0.161977\n",
      "batch 2625: loss 0.066828\n",
      "batch 2626: loss 0.031374\n",
      "batch 2627: loss 0.187219\n",
      "batch 2628: loss 0.139834\n",
      "batch 2629: loss 0.087512\n",
      "batch 2630: loss 0.125372\n",
      "batch 2631: loss 0.085641\n",
      "batch 2632: loss 0.159093\n",
      "batch 2633: loss 0.205358\n",
      "batch 2634: loss 0.066253\n",
      "batch 2635: loss 0.022840\n",
      "batch 2636: loss 0.162970\n",
      "batch 2637: loss 0.198556\n",
      "batch 2638: loss 0.014311\n",
      "batch 2639: loss 0.176795\n",
      "batch 2640: loss 0.099191\n",
      "batch 2641: loss 0.072080\n",
      "batch 2642: loss 0.056211\n",
      "batch 2643: loss 0.031942\n",
      "batch 2644: loss 0.160482\n",
      "batch 2645: loss 0.190119\n",
      "batch 2646: loss 0.111330\n",
      "batch 2647: loss 0.047579\n",
      "batch 2648: loss 0.201620\n",
      "batch 2649: loss 0.096762\n",
      "batch 2650: loss 0.049128\n",
      "batch 2651: loss 0.096518\n",
      "batch 2652: loss 0.056691\n",
      "batch 2653: loss 0.058414\n",
      "batch 2654: loss 0.049329\n",
      "batch 2655: loss 0.049791\n",
      "batch 2656: loss 0.170395\n",
      "batch 2657: loss 0.077705\n",
      "batch 2658: loss 0.111694\n",
      "batch 2659: loss 0.136787\n",
      "batch 2660: loss 0.091320\n",
      "batch 2661: loss 0.031119\n",
      "batch 2662: loss 0.053155\n",
      "batch 2663: loss 0.065792\n",
      "batch 2664: loss 0.085581\n",
      "batch 2665: loss 0.080319\n",
      "batch 2666: loss 0.128097\n",
      "batch 2667: loss 0.096709\n",
      "batch 2668: loss 0.082246\n",
      "batch 2669: loss 0.200392\n",
      "batch 2670: loss 0.046488\n",
      "batch 2671: loss 0.104262\n",
      "batch 2672: loss 0.048927\n",
      "batch 2673: loss 0.060106\n",
      "batch 2674: loss 0.074590\n",
      "batch 2675: loss 0.056422\n",
      "batch 2676: loss 0.051418\n",
      "batch 2677: loss 0.073075\n",
      "batch 2678: loss 0.267923\n",
      "batch 2679: loss 0.048934\n",
      "batch 2680: loss 0.115151\n",
      "batch 2681: loss 0.044083\n",
      "batch 2682: loss 0.135881\n",
      "batch 2683: loss 0.172075\n",
      "batch 2684: loss 0.119270\n",
      "batch 2685: loss 0.090451\n",
      "batch 2686: loss 0.065776\n",
      "batch 2687: loss 0.223930\n",
      "batch 2688: loss 0.048598\n",
      "batch 2689: loss 0.153137\n",
      "batch 2690: loss 0.081048\n",
      "batch 2691: loss 0.152903\n",
      "batch 2692: loss 0.042947\n",
      "batch 2693: loss 0.117444\n",
      "batch 2694: loss 0.105711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2695: loss 0.038093\n",
      "batch 2696: loss 0.284340\n",
      "batch 2697: loss 0.109086\n",
      "batch 2698: loss 0.089192\n",
      "batch 2699: loss 0.108856\n",
      "batch 2700: loss 0.043901\n",
      "batch 2701: loss 0.110045\n",
      "batch 2702: loss 0.068297\n",
      "batch 2703: loss 0.069473\n",
      "batch 2704: loss 0.053298\n",
      "batch 2705: loss 0.057842\n",
      "batch 2706: loss 0.066053\n",
      "batch 2707: loss 0.043189\n",
      "batch 2708: loss 0.075837\n",
      "batch 2709: loss 0.043430\n",
      "batch 2710: loss 0.064378\n",
      "batch 2711: loss 0.028908\n",
      "batch 2712: loss 0.202399\n",
      "batch 2713: loss 0.096580\n",
      "batch 2714: loss 0.029390\n",
      "batch 2715: loss 0.043699\n",
      "batch 2716: loss 0.091654\n",
      "batch 2717: loss 0.150475\n",
      "batch 2718: loss 0.107252\n",
      "batch 2719: loss 0.075156\n",
      "batch 2720: loss 0.276152\n",
      "batch 2721: loss 0.133526\n",
      "batch 2722: loss 0.031911\n",
      "batch 2723: loss 0.154928\n",
      "batch 2724: loss 0.169524\n",
      "batch 2725: loss 0.108939\n",
      "batch 2726: loss 0.199170\n",
      "batch 2727: loss 0.114946\n",
      "batch 2728: loss 0.137480\n",
      "batch 2729: loss 0.088153\n",
      "batch 2730: loss 0.118776\n",
      "batch 2731: loss 0.050511\n",
      "batch 2732: loss 0.044979\n",
      "batch 2733: loss 0.041704\n",
      "batch 2734: loss 0.077241\n",
      "batch 2735: loss 0.101122\n",
      "batch 2736: loss 0.146618\n",
      "batch 2737: loss 0.198275\n",
      "batch 2738: loss 0.117987\n",
      "batch 2739: loss 0.018695\n",
      "batch 2740: loss 0.068301\n",
      "batch 2741: loss 0.112083\n",
      "batch 2742: loss 0.201181\n",
      "batch 2743: loss 0.070330\n",
      "batch 2744: loss 0.034426\n",
      "batch 2745: loss 0.046080\n",
      "batch 2746: loss 0.116998\n",
      "batch 2747: loss 0.043411\n",
      "batch 2748: loss 0.176815\n",
      "batch 2749: loss 0.067782\n",
      "batch 2750: loss 0.059983\n",
      "batch 2751: loss 0.036102\n",
      "batch 2752: loss 0.066733\n",
      "batch 2753: loss 0.108857\n",
      "batch 2754: loss 0.021381\n",
      "batch 2755: loss 0.174632\n",
      "batch 2756: loss 0.045287\n",
      "batch 2757: loss 0.089029\n",
      "batch 2758: loss 0.040215\n",
      "batch 2759: loss 0.055531\n",
      "batch 2760: loss 0.053392\n",
      "batch 2761: loss 0.174660\n",
      "batch 2762: loss 0.126240\n",
      "batch 2763: loss 0.033183\n",
      "batch 2764: loss 0.056940\n",
      "batch 2765: loss 0.104515\n",
      "batch 2766: loss 0.150648\n",
      "batch 2767: loss 0.036529\n",
      "batch 2768: loss 0.118828\n",
      "batch 2769: loss 0.077686\n",
      "batch 2770: loss 0.090779\n",
      "batch 2771: loss 0.069610\n",
      "batch 2772: loss 0.077047\n",
      "batch 2773: loss 0.208368\n",
      "batch 2774: loss 0.046042\n",
      "batch 2775: loss 0.073903\n",
      "batch 2776: loss 0.092127\n",
      "batch 2777: loss 0.107544\n",
      "batch 2778: loss 0.235413\n",
      "batch 2779: loss 0.149592\n",
      "batch 2780: loss 0.096703\n",
      "batch 2781: loss 0.058359\n",
      "batch 2782: loss 0.126925\n",
      "batch 2783: loss 0.119818\n",
      "batch 2784: loss 0.158931\n",
      "batch 2785: loss 0.036303\n",
      "batch 2786: loss 0.057162\n",
      "batch 2787: loss 0.022905\n",
      "batch 2788: loss 0.065861\n",
      "batch 2789: loss 0.028200\n",
      "batch 2790: loss 0.260571\n",
      "batch 2791: loss 0.100249\n",
      "batch 2792: loss 0.101219\n",
      "batch 2793: loss 0.159449\n",
      "batch 2794: loss 0.073108\n",
      "batch 2795: loss 0.086163\n",
      "batch 2796: loss 0.022298\n",
      "batch 2797: loss 0.096350\n",
      "batch 2798: loss 0.051516\n",
      "batch 2799: loss 0.031477\n",
      "batch 2800: loss 0.051042\n",
      "batch 2801: loss 0.090858\n",
      "batch 2802: loss 0.067059\n",
      "batch 2803: loss 0.235218\n",
      "batch 2804: loss 0.190467\n",
      "batch 2805: loss 0.105152\n",
      "batch 2806: loss 0.043423\n",
      "batch 2807: loss 0.081439\n",
      "batch 2808: loss 0.082952\n",
      "batch 2809: loss 0.028010\n",
      "batch 2810: loss 0.163417\n",
      "batch 2811: loss 0.211538\n",
      "batch 2812: loss 0.023611\n",
      "batch 2813: loss 0.058782\n",
      "batch 2814: loss 0.034828\n",
      "batch 2815: loss 0.103482\n",
      "batch 2816: loss 0.026014\n",
      "batch 2817: loss 0.053274\n",
      "batch 2818: loss 0.108412\n",
      "batch 2819: loss 0.069376\n",
      "batch 2820: loss 0.080364\n",
      "batch 2821: loss 0.049990\n",
      "batch 2822: loss 0.021403\n",
      "batch 2823: loss 0.136860\n",
      "batch 2824: loss 0.168883\n",
      "batch 2825: loss 0.044604\n",
      "batch 2826: loss 0.014762\n",
      "batch 2827: loss 0.070035\n",
      "batch 2828: loss 0.038444\n",
      "batch 2829: loss 0.186295\n",
      "batch 2830: loss 0.137863\n",
      "batch 2831: loss 0.167425\n",
      "batch 2832: loss 0.231001\n",
      "batch 2833: loss 0.091391\n",
      "batch 2834: loss 0.093080\n",
      "batch 2835: loss 0.074682\n",
      "batch 2836: loss 0.106611\n",
      "batch 2837: loss 0.015824\n",
      "batch 2838: loss 0.193763\n",
      "batch 2839: loss 0.075913\n",
      "batch 2840: loss 0.039832\n",
      "batch 2841: loss 0.155360\n",
      "batch 2842: loss 0.053274\n",
      "batch 2843: loss 0.014231\n",
      "batch 2844: loss 0.401837\n",
      "batch 2845: loss 0.133944\n",
      "batch 2846: loss 0.108724\n",
      "batch 2847: loss 0.058226\n",
      "batch 2848: loss 0.021705\n",
      "batch 2849: loss 0.107753\n",
      "batch 2850: loss 0.174007\n",
      "batch 2851: loss 0.021276\n",
      "batch 2852: loss 0.177387\n",
      "batch 2853: loss 0.191380\n",
      "batch 2854: loss 0.085479\n",
      "batch 2855: loss 0.078106\n",
      "batch 2856: loss 0.082609\n",
      "batch 2857: loss 0.033750\n",
      "batch 2858: loss 0.111879\n",
      "batch 2859: loss 0.104578\n",
      "batch 2860: loss 0.076488\n",
      "batch 2861: loss 0.025132\n",
      "batch 2862: loss 0.056764\n",
      "batch 2863: loss 0.066572\n",
      "batch 2864: loss 0.119627\n",
      "batch 2865: loss 0.065491\n",
      "batch 2866: loss 0.050950\n",
      "batch 2867: loss 0.040237\n",
      "batch 2868: loss 0.023970\n",
      "batch 2869: loss 0.039897\n",
      "batch 2870: loss 0.048036\n",
      "batch 2871: loss 0.044770\n",
      "batch 2872: loss 0.031843\n",
      "batch 2873: loss 0.054007\n",
      "batch 2874: loss 0.030296\n",
      "batch 2875: loss 0.106497\n",
      "batch 2876: loss 0.092755\n",
      "batch 2877: loss 0.165052\n",
      "batch 2878: loss 0.031426\n",
      "batch 2879: loss 0.088026\n",
      "batch 2880: loss 0.046337\n",
      "batch 2881: loss 0.145019\n",
      "batch 2882: loss 0.220542\n",
      "batch 2883: loss 0.081676\n",
      "batch 2884: loss 0.039610\n",
      "batch 2885: loss 0.041608\n",
      "batch 2886: loss 0.091741\n",
      "batch 2887: loss 0.088191\n",
      "batch 2888: loss 0.116202\n",
      "batch 2889: loss 0.105786\n",
      "batch 2890: loss 0.066918\n",
      "batch 2891: loss 0.076651\n",
      "batch 2892: loss 0.087306\n",
      "batch 2893: loss 0.022835\n",
      "batch 2894: loss 0.069993\n",
      "batch 2895: loss 0.115591\n",
      "batch 2896: loss 0.165167\n",
      "batch 2897: loss 0.180419\n",
      "batch 2898: loss 0.056190\n",
      "batch 2899: loss 0.129030\n",
      "batch 2900: loss 0.128654\n",
      "batch 2901: loss 0.090320\n",
      "batch 2902: loss 0.011806\n",
      "batch 2903: loss 0.035679\n",
      "batch 2904: loss 0.055711\n",
      "batch 2905: loss 0.086924\n",
      "batch 2906: loss 0.107203\n",
      "batch 2907: loss 0.042237\n",
      "batch 2908: loss 0.019043\n",
      "batch 2909: loss 0.165395\n",
      "batch 2910: loss 0.165181\n",
      "batch 2911: loss 0.119911\n",
      "batch 2912: loss 0.149628\n",
      "batch 2913: loss 0.081825\n",
      "batch 2914: loss 0.072782\n",
      "batch 2915: loss 0.101764\n",
      "batch 2916: loss 0.101406\n",
      "batch 2917: loss 0.159685\n",
      "batch 2918: loss 0.054019\n",
      "batch 2919: loss 0.075207\n",
      "batch 2920: loss 0.059319\n",
      "batch 2921: loss 0.037188\n",
      "batch 2922: loss 0.027756\n",
      "batch 2923: loss 0.047549\n",
      "batch 2924: loss 0.129755\n",
      "batch 2925: loss 0.159231\n",
      "batch 2926: loss 0.151959\n",
      "batch 2927: loss 0.073813\n",
      "batch 2928: loss 0.052238\n",
      "batch 2929: loss 0.048842\n",
      "batch 2930: loss 0.162978\n",
      "batch 2931: loss 0.137003\n",
      "batch 2932: loss 0.093364\n",
      "batch 2933: loss 0.079384\n",
      "batch 2934: loss 0.026781\n",
      "batch 2935: loss 0.048694\n",
      "batch 2936: loss 0.229448\n",
      "batch 2937: loss 0.132689\n",
      "batch 2938: loss 0.121040\n",
      "batch 2939: loss 0.053523\n",
      "batch 2940: loss 0.174327\n",
      "batch 2941: loss 0.036216\n",
      "batch 2942: loss 0.023633\n",
      "batch 2943: loss 0.085914\n",
      "batch 2944: loss 0.141199\n",
      "batch 2945: loss 0.146837\n",
      "batch 2946: loss 0.053579\n",
      "batch 2947: loss 0.017194\n",
      "batch 2948: loss 0.028771\n",
      "batch 2949: loss 0.180353\n",
      "batch 2950: loss 0.024100\n",
      "batch 2951: loss 0.025688\n",
      "batch 2952: loss 0.084908\n",
      "batch 2953: loss 0.112150\n",
      "batch 2954: loss 0.131376\n",
      "batch 2955: loss 0.112943\n",
      "batch 2956: loss 0.036429\n",
      "batch 2957: loss 0.034690\n",
      "batch 2958: loss 0.052167\n",
      "batch 2959: loss 0.114938\n",
      "batch 2960: loss 0.017499\n",
      "batch 2961: loss 0.014867\n",
      "batch 2962: loss 0.064028\n",
      "batch 2963: loss 0.018408\n",
      "batch 2964: loss 0.033990\n",
      "batch 2965: loss 0.044932\n",
      "batch 2966: loss 0.033847\n",
      "batch 2967: loss 0.031506\n",
      "batch 2968: loss 0.084474\n",
      "batch 2969: loss 0.159639\n",
      "batch 2970: loss 0.032054\n",
      "batch 2971: loss 0.077976\n",
      "batch 2972: loss 0.052140\n",
      "batch 2973: loss 0.052745\n",
      "batch 2974: loss 0.156459\n",
      "batch 2975: loss 0.172308\n",
      "batch 2976: loss 0.031240\n",
      "batch 2977: loss 0.173642\n",
      "batch 2978: loss 0.043444\n",
      "batch 2979: loss 0.050123\n",
      "batch 2980: loss 0.094177\n",
      "batch 2981: loss 0.028919\n",
      "batch 2982: loss 0.095046\n",
      "batch 2983: loss 0.028799\n",
      "batch 2984: loss 0.084442\n",
      "batch 2985: loss 0.020447\n",
      "batch 2986: loss 0.077214\n",
      "batch 2987: loss 0.133756\n",
      "batch 2988: loss 0.051553\n",
      "batch 2989: loss 0.220957\n",
      "batch 2990: loss 0.126351\n",
      "batch 2991: loss 0.031980\n",
      "batch 2992: loss 0.019304\n",
      "batch 2993: loss 0.014826\n",
      "batch 2994: loss 0.112217\n",
      "batch 2995: loss 0.049738\n",
      "batch 2996: loss 0.030847\n",
      "batch 2997: loss 0.163519\n",
      "batch 2998: loss 0.080824\n",
      "batch 2999: loss 0.163024\n",
      "batch 3000: loss 0.056273\n",
      "batch 3001: loss 0.110807\n",
      "batch 3002: loss 0.065398\n",
      "batch 3003: loss 0.038708\n",
      "batch 3004: loss 0.033982\n",
      "batch 3005: loss 0.050104\n",
      "batch 3006: loss 0.145443\n",
      "batch 3007: loss 0.092231\n",
      "batch 3008: loss 0.101397\n",
      "batch 3009: loss 0.048761\n",
      "batch 3010: loss 0.028723\n",
      "batch 3011: loss 0.040962\n",
      "batch 3012: loss 0.090847\n",
      "batch 3013: loss 0.063411\n",
      "batch 3014: loss 0.088015\n",
      "batch 3015: loss 0.040020\n",
      "batch 3016: loss 0.096712\n",
      "batch 3017: loss 0.105204\n",
      "batch 3018: loss 0.035855\n",
      "batch 3019: loss 0.026943\n",
      "batch 3020: loss 0.104501\n",
      "batch 3021: loss 0.136711\n",
      "batch 3022: loss 0.216434\n",
      "batch 3023: loss 0.075578\n",
      "batch 3024: loss 0.057656\n",
      "batch 3025: loss 0.022690\n",
      "batch 3026: loss 0.069047\n",
      "batch 3027: loss 0.051513\n",
      "batch 3028: loss 0.044658\n",
      "batch 3029: loss 0.019876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3030: loss 0.046887\n",
      "batch 3031: loss 0.082227\n",
      "batch 3032: loss 0.024574\n",
      "batch 3033: loss 0.137155\n",
      "batch 3034: loss 0.038000\n",
      "batch 3035: loss 0.017864\n",
      "batch 3036: loss 0.069539\n",
      "batch 3037: loss 0.052872\n",
      "batch 3038: loss 0.103921\n",
      "batch 3039: loss 0.105504\n",
      "batch 3040: loss 0.100022\n",
      "batch 3041: loss 0.043063\n",
      "batch 3042: loss 0.189763\n",
      "batch 3043: loss 0.048018\n",
      "batch 3044: loss 0.039081\n",
      "batch 3045: loss 0.033843\n",
      "batch 3046: loss 0.086513\n",
      "batch 3047: loss 0.150366\n",
      "batch 3048: loss 0.018937\n",
      "batch 3049: loss 0.073106\n",
      "batch 3050: loss 0.200702\n",
      "batch 3051: loss 0.206837\n",
      "batch 3052: loss 0.075422\n",
      "batch 3053: loss 0.073749\n",
      "batch 3054: loss 0.106359\n",
      "batch 3055: loss 0.022642\n",
      "batch 3056: loss 0.055619\n",
      "batch 3057: loss 0.140377\n",
      "batch 3058: loss 0.067899\n",
      "batch 3059: loss 0.244004\n",
      "batch 3060: loss 0.153798\n",
      "batch 3061: loss 0.095745\n",
      "batch 3062: loss 0.057028\n",
      "batch 3063: loss 0.056478\n",
      "batch 3064: loss 0.043031\n",
      "batch 3065: loss 0.045408\n",
      "batch 3066: loss 0.078359\n",
      "batch 3067: loss 0.164106\n",
      "batch 3068: loss 0.032058\n",
      "batch 3069: loss 0.030753\n",
      "batch 3070: loss 0.082326\n",
      "batch 3071: loss 0.104142\n",
      "batch 3072: loss 0.183327\n",
      "batch 3073: loss 0.048996\n",
      "batch 3074: loss 0.040857\n",
      "batch 3075: loss 0.124801\n",
      "batch 3076: loss 0.035759\n",
      "batch 3077: loss 0.050630\n",
      "batch 3078: loss 0.042194\n",
      "batch 3079: loss 0.014131\n",
      "batch 3080: loss 0.039481\n",
      "batch 3081: loss 0.048981\n",
      "batch 3082: loss 0.078120\n",
      "batch 3083: loss 0.130376\n",
      "batch 3084: loss 0.213247\n",
      "batch 3085: loss 0.053994\n",
      "batch 3086: loss 0.083999\n",
      "batch 3087: loss 0.118404\n",
      "batch 3088: loss 0.041440\n",
      "batch 3089: loss 0.047364\n",
      "batch 3090: loss 0.037443\n",
      "batch 3091: loss 0.099087\n",
      "batch 3092: loss 0.091627\n",
      "batch 3093: loss 0.051807\n",
      "batch 3094: loss 0.053381\n",
      "batch 3095: loss 0.116043\n",
      "batch 3096: loss 0.040553\n",
      "batch 3097: loss 0.091458\n",
      "batch 3098: loss 0.031315\n",
      "batch 3099: loss 0.011964\n",
      "batch 3100: loss 0.017190\n",
      "batch 3101: loss 0.009872\n",
      "batch 3102: loss 0.078903\n",
      "batch 3103: loss 0.065821\n",
      "batch 3104: loss 0.038306\n",
      "batch 3105: loss 0.022306\n",
      "batch 3106: loss 0.175582\n",
      "batch 3107: loss 0.078516\n",
      "batch 3108: loss 0.081119\n",
      "batch 3109: loss 0.027143\n",
      "batch 3110: loss 0.383587\n",
      "batch 3111: loss 0.039623\n",
      "batch 3112: loss 0.076908\n",
      "batch 3113: loss 0.082388\n",
      "batch 3114: loss 0.056242\n",
      "batch 3115: loss 0.138933\n",
      "batch 3116: loss 0.021560\n",
      "batch 3117: loss 0.098565\n",
      "batch 3118: loss 0.059656\n",
      "batch 3119: loss 0.025285\n",
      "batch 3120: loss 0.137202\n",
      "batch 3121: loss 0.032386\n",
      "batch 3122: loss 0.021844\n",
      "batch 3123: loss 0.011487\n",
      "batch 3124: loss 0.032399\n",
      "batch 3125: loss 0.058229\n",
      "batch 3126: loss 0.052623\n",
      "batch 3127: loss 0.101545\n",
      "batch 3128: loss 0.090697\n",
      "batch 3129: loss 0.068417\n",
      "batch 3130: loss 0.083892\n",
      "batch 3131: loss 0.141213\n",
      "batch 3132: loss 0.032132\n",
      "batch 3133: loss 0.062201\n",
      "batch 3134: loss 0.104159\n",
      "batch 3135: loss 0.045326\n",
      "batch 3136: loss 0.090513\n",
      "batch 3137: loss 0.037875\n",
      "batch 3138: loss 0.049201\n",
      "batch 3139: loss 0.070312\n",
      "batch 3140: loss 0.041639\n",
      "batch 3141: loss 0.071859\n",
      "batch 3142: loss 0.144397\n",
      "batch 3143: loss 0.043383\n",
      "batch 3144: loss 0.060245\n",
      "batch 3145: loss 0.028583\n",
      "batch 3146: loss 0.051368\n",
      "batch 3147: loss 0.059277\n",
      "batch 3148: loss 0.077538\n",
      "batch 3149: loss 0.020915\n",
      "batch 3150: loss 0.051299\n",
      "batch 3151: loss 0.062772\n",
      "batch 3152: loss 0.043921\n",
      "batch 3153: loss 0.078873\n",
      "batch 3154: loss 0.087110\n",
      "batch 3155: loss 0.056440\n",
      "batch 3156: loss 0.116508\n",
      "batch 3157: loss 0.056683\n",
      "batch 3158: loss 0.159737\n",
      "batch 3159: loss 0.009210\n",
      "batch 3160: loss 0.136609\n",
      "batch 3161: loss 0.116223\n",
      "batch 3162: loss 0.067119\n",
      "batch 3163: loss 0.155666\n",
      "batch 3164: loss 0.028283\n",
      "batch 3165: loss 0.091428\n",
      "batch 3166: loss 0.054186\n",
      "batch 3167: loss 0.020465\n",
      "batch 3168: loss 0.024032\n",
      "batch 3169: loss 0.032458\n",
      "batch 3170: loss 0.049720\n",
      "batch 3171: loss 0.110411\n",
      "batch 3172: loss 0.040316\n",
      "batch 3173: loss 0.024241\n",
      "batch 3174: loss 0.014911\n",
      "batch 3175: loss 0.017329\n",
      "batch 3176: loss 0.066471\n",
      "batch 3177: loss 0.097525\n",
      "batch 3178: loss 0.037827\n",
      "batch 3179: loss 0.073632\n",
      "batch 3180: loss 0.040205\n",
      "batch 3181: loss 0.033930\n",
      "batch 3182: loss 0.026886\n",
      "batch 3183: loss 0.030873\n",
      "batch 3184: loss 0.032231\n",
      "batch 3185: loss 0.029203\n",
      "batch 3186: loss 0.019965\n",
      "batch 3187: loss 0.194029\n",
      "batch 3188: loss 0.059312\n",
      "batch 3189: loss 0.057066\n",
      "batch 3190: loss 0.140537\n",
      "batch 3191: loss 0.038251\n",
      "batch 3192: loss 0.058842\n",
      "batch 3193: loss 0.063414\n",
      "batch 3194: loss 0.065254\n",
      "batch 3195: loss 0.057853\n",
      "batch 3196: loss 0.144120\n",
      "batch 3197: loss 0.135236\n",
      "batch 3198: loss 0.086830\n",
      "batch 3199: loss 0.145371\n",
      "batch 3200: loss 0.137928\n",
      "batch 3201: loss 0.045521\n",
      "batch 3202: loss 0.045114\n",
      "batch 3203: loss 0.028020\n",
      "batch 3204: loss 0.127888\n",
      "batch 3205: loss 0.075508\n",
      "batch 3206: loss 0.042553\n",
      "batch 3207: loss 0.020698\n",
      "batch 3208: loss 0.029387\n",
      "batch 3209: loss 0.030067\n",
      "batch 3210: loss 0.093672\n",
      "batch 3211: loss 0.116035\n",
      "batch 3212: loss 0.072955\n",
      "batch 3213: loss 0.142590\n",
      "batch 3214: loss 0.024957\n",
      "batch 3215: loss 0.015135\n",
      "batch 3216: loss 0.154931\n",
      "batch 3217: loss 0.058216\n",
      "batch 3218: loss 0.056892\n",
      "batch 3219: loss 0.016844\n",
      "batch 3220: loss 0.133202\n",
      "batch 3221: loss 0.156770\n",
      "batch 3222: loss 0.098031\n",
      "batch 3223: loss 0.014274\n",
      "batch 3224: loss 0.030018\n",
      "batch 3225: loss 0.019263\n",
      "batch 3226: loss 0.183863\n",
      "batch 3227: loss 0.120458\n",
      "batch 3228: loss 0.126882\n",
      "batch 3229: loss 0.074469\n",
      "batch 3230: loss 0.109593\n",
      "batch 3231: loss 0.024161\n",
      "batch 3232: loss 0.158229\n",
      "batch 3233: loss 0.075171\n",
      "batch 3234: loss 0.068118\n",
      "batch 3235: loss 0.009376\n",
      "batch 3236: loss 0.080489\n",
      "batch 3237: loss 0.035896\n",
      "batch 3238: loss 0.052559\n",
      "batch 3239: loss 0.021590\n",
      "batch 3240: loss 0.022237\n",
      "batch 3241: loss 0.093926\n",
      "batch 3242: loss 0.028436\n",
      "batch 3243: loss 0.104718\n",
      "batch 3244: loss 0.211149\n",
      "batch 3245: loss 0.059658\n",
      "batch 3246: loss 0.245205\n",
      "batch 3247: loss 0.029686\n",
      "batch 3248: loss 0.100677\n",
      "batch 3249: loss 0.037895\n",
      "batch 3250: loss 0.115043\n",
      "batch 3251: loss 0.063217\n",
      "batch 3252: loss 0.093317\n",
      "batch 3253: loss 0.076140\n",
      "batch 3254: loss 0.081205\n",
      "batch 3255: loss 0.113254\n",
      "batch 3256: loss 0.096583\n",
      "batch 3257: loss 0.019036\n",
      "batch 3258: loss 0.047097\n",
      "batch 3259: loss 0.022895\n",
      "batch 3260: loss 0.097651\n",
      "batch 3261: loss 0.025439\n",
      "batch 3262: loss 0.071742\n",
      "batch 3263: loss 0.042127\n",
      "batch 3264: loss 0.132145\n",
      "batch 3265: loss 0.092586\n",
      "batch 3266: loss 0.042303\n",
      "batch 3267: loss 0.120209\n",
      "batch 3268: loss 0.054608\n",
      "batch 3269: loss 0.045293\n",
      "batch 3270: loss 0.129626\n",
      "batch 3271: loss 0.038034\n",
      "batch 3272: loss 0.042234\n",
      "batch 3273: loss 0.038410\n",
      "batch 3274: loss 0.051722\n",
      "batch 3275: loss 0.062067\n",
      "batch 3276: loss 0.134231\n",
      "batch 3277: loss 0.050647\n",
      "batch 3278: loss 0.140278\n",
      "batch 3279: loss 0.058248\n",
      "batch 3280: loss 0.020531\n",
      "batch 3281: loss 0.047970\n",
      "batch 3282: loss 0.017235\n",
      "batch 3283: loss 0.033877\n",
      "batch 3284: loss 0.061397\n",
      "batch 3285: loss 0.043419\n",
      "batch 3286: loss 0.075445\n",
      "batch 3287: loss 0.102229\n",
      "batch 3288: loss 0.073019\n",
      "batch 3289: loss 0.205104\n",
      "batch 3290: loss 0.014352\n",
      "batch 3291: loss 0.064483\n",
      "batch 3292: loss 0.136170\n",
      "batch 3293: loss 0.044068\n",
      "batch 3294: loss 0.019484\n",
      "batch 3295: loss 0.127922\n",
      "batch 3296: loss 0.184394\n",
      "batch 3297: loss 0.042200\n",
      "batch 3298: loss 0.039700\n",
      "batch 3299: loss 0.083236\n",
      "batch 3300: loss 0.214738\n",
      "batch 3301: loss 0.027063\n",
      "batch 3302: loss 0.131861\n",
      "batch 3303: loss 0.024741\n",
      "batch 3304: loss 0.232008\n",
      "batch 3305: loss 0.071500\n",
      "batch 3306: loss 0.042406\n",
      "batch 3307: loss 0.061523\n",
      "batch 3308: loss 0.033688\n",
      "batch 3309: loss 0.059689\n",
      "batch 3310: loss 0.037092\n",
      "batch 3311: loss 0.151422\n",
      "batch 3312: loss 0.113432\n",
      "batch 3313: loss 0.062559\n",
      "batch 3314: loss 0.160858\n",
      "batch 3315: loss 0.046910\n",
      "batch 3316: loss 0.113521\n",
      "batch 3317: loss 0.086796\n",
      "batch 3318: loss 0.289536\n",
      "batch 3319: loss 0.102582\n",
      "batch 3320: loss 0.044662\n",
      "batch 3321: loss 0.038005\n",
      "batch 3322: loss 0.054184\n",
      "batch 3323: loss 0.378195\n",
      "batch 3324: loss 0.123040\n",
      "batch 3325: loss 0.136064\n",
      "batch 3326: loss 0.051632\n",
      "batch 3327: loss 0.024418\n",
      "batch 3328: loss 0.089844\n",
      "batch 3329: loss 0.094766\n",
      "batch 3330: loss 0.010483\n",
      "batch 3331: loss 0.147340\n",
      "batch 3332: loss 0.021175\n",
      "batch 3333: loss 0.187798\n",
      "batch 3334: loss 0.115193\n",
      "batch 3335: loss 0.078915\n",
      "batch 3336: loss 0.145086\n",
      "batch 3337: loss 0.081074\n",
      "batch 3338: loss 0.092400\n",
      "batch 3339: loss 0.169406\n",
      "batch 3340: loss 0.220077\n",
      "batch 3341: loss 0.046203\n",
      "batch 3342: loss 0.049476\n",
      "batch 3343: loss 0.077065\n",
      "batch 3344: loss 0.079567\n",
      "batch 3345: loss 0.022362\n",
      "batch 3346: loss 0.018017\n",
      "batch 3347: loss 0.065412\n",
      "batch 3348: loss 0.090382\n",
      "batch 3349: loss 0.091782\n",
      "batch 3350: loss 0.093008\n",
      "batch 3351: loss 0.096778\n",
      "batch 3352: loss 0.018236\n",
      "batch 3353: loss 0.121841\n",
      "batch 3354: loss 0.048823\n",
      "batch 3355: loss 0.095738\n",
      "batch 3356: loss 0.223226\n",
      "batch 3357: loss 0.107730\n",
      "batch 3358: loss 0.119196\n",
      "batch 3359: loss 0.064162\n",
      "batch 3360: loss 0.053181\n",
      "batch 3361: loss 0.098663\n",
      "batch 3362: loss 0.050561\n",
      "batch 3363: loss 0.026807\n",
      "batch 3364: loss 0.014493\n",
      "batch 3365: loss 0.062472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3366: loss 0.041670\n",
      "batch 3367: loss 0.064618\n",
      "batch 3368: loss 0.041957\n",
      "batch 3369: loss 0.049870\n",
      "batch 3370: loss 0.060263\n",
      "batch 3371: loss 0.060886\n",
      "batch 3372: loss 0.174063\n",
      "batch 3373: loss 0.052726\n",
      "batch 3374: loss 0.044236\n",
      "batch 3375: loss 0.025836\n",
      "batch 3376: loss 0.161467\n",
      "batch 3377: loss 0.031406\n",
      "batch 3378: loss 0.139448\n",
      "batch 3379: loss 0.069558\n",
      "batch 3380: loss 0.012331\n",
      "batch 3381: loss 0.227151\n",
      "batch 3382: loss 0.053731\n",
      "batch 3383: loss 0.098084\n",
      "batch 3384: loss 0.178142\n",
      "batch 3385: loss 0.083397\n",
      "batch 3386: loss 0.049928\n",
      "batch 3387: loss 0.082797\n",
      "batch 3388: loss 0.024421\n",
      "batch 3389: loss 0.063308\n",
      "batch 3390: loss 0.286704\n",
      "batch 3391: loss 0.062117\n",
      "batch 3392: loss 0.053257\n",
      "batch 3393: loss 0.085264\n",
      "batch 3394: loss 0.110868\n",
      "batch 3395: loss 0.049224\n",
      "batch 3396: loss 0.122820\n",
      "batch 3397: loss 0.076596\n",
      "batch 3398: loss 0.024318\n",
      "batch 3399: loss 0.120803\n",
      "batch 3400: loss 0.052204\n",
      "batch 3401: loss 0.138065\n",
      "batch 3402: loss 0.022345\n",
      "batch 3403: loss 0.029151\n",
      "batch 3404: loss 0.090943\n",
      "batch 3405: loss 0.022190\n",
      "batch 3406: loss 0.073064\n",
      "batch 3407: loss 0.063268\n",
      "batch 3408: loss 0.029650\n",
      "batch 3409: loss 0.074810\n",
      "batch 3410: loss 0.199651\n",
      "batch 3411: loss 0.133917\n",
      "batch 3412: loss 0.074098\n",
      "batch 3413: loss 0.016151\n",
      "batch 3414: loss 0.026202\n",
      "batch 3415: loss 0.065740\n",
      "batch 3416: loss 0.065021\n",
      "batch 3417: loss 0.035910\n",
      "batch 3418: loss 0.128944\n",
      "batch 3419: loss 0.022676\n",
      "batch 3420: loss 0.216991\n",
      "batch 3421: loss 0.104137\n",
      "batch 3422: loss 0.038653\n",
      "batch 3423: loss 0.036238\n",
      "batch 3424: loss 0.194261\n",
      "batch 3425: loss 0.079301\n",
      "batch 3426: loss 0.081982\n",
      "batch 3427: loss 0.094778\n",
      "batch 3428: loss 0.110759\n",
      "batch 3429: loss 0.013167\n",
      "batch 3430: loss 0.056772\n",
      "batch 3431: loss 0.022325\n",
      "batch 3432: loss 0.031846\n",
      "batch 3433: loss 0.066553\n",
      "batch 3434: loss 0.096160\n",
      "batch 3435: loss 0.056447\n",
      "batch 3436: loss 0.023341\n",
      "batch 3437: loss 0.062059\n",
      "batch 3438: loss 0.034589\n",
      "batch 3439: loss 0.036443\n",
      "batch 3440: loss 0.091844\n",
      "batch 3441: loss 0.198530\n",
      "batch 3442: loss 0.076623\n",
      "batch 3443: loss 0.125709\n",
      "batch 3444: loss 0.035095\n",
      "batch 3445: loss 0.017030\n",
      "batch 3446: loss 0.119081\n",
      "batch 3447: loss 0.065085\n",
      "batch 3448: loss 0.041252\n",
      "batch 3449: loss 0.058129\n",
      "batch 3450: loss 0.118865\n",
      "batch 3451: loss 0.016838\n",
      "batch 3452: loss 0.034895\n",
      "batch 3453: loss 0.079255\n",
      "batch 3454: loss 0.020942\n",
      "batch 3455: loss 0.040913\n",
      "batch 3456: loss 0.063716\n",
      "batch 3457: loss 0.022369\n",
      "batch 3458: loss 0.045909\n",
      "batch 3459: loss 0.087388\n",
      "batch 3460: loss 0.032490\n",
      "batch 3461: loss 0.026822\n",
      "batch 3462: loss 0.056254\n",
      "batch 3463: loss 0.063459\n",
      "batch 3464: loss 0.136074\n",
      "batch 3465: loss 0.021737\n",
      "batch 3466: loss 0.014106\n",
      "batch 3467: loss 0.057111\n",
      "batch 3468: loss 0.040941\n",
      "batch 3469: loss 0.021378\n",
      "batch 3470: loss 0.144650\n",
      "batch 3471: loss 0.228778\n",
      "batch 3472: loss 0.050039\n",
      "batch 3473: loss 0.093470\n",
      "batch 3474: loss 0.091579\n",
      "batch 3475: loss 0.112221\n",
      "batch 3476: loss 0.053415\n",
      "batch 3477: loss 0.078178\n",
      "batch 3478: loss 0.063628\n",
      "batch 3479: loss 0.082730\n",
      "batch 3480: loss 0.026127\n",
      "batch 3481: loss 0.110439\n",
      "batch 3482: loss 0.103018\n",
      "batch 3483: loss 0.184716\n",
      "batch 3484: loss 0.056305\n",
      "batch 3485: loss 0.032570\n",
      "batch 3486: loss 0.054586\n",
      "batch 3487: loss 0.024129\n",
      "batch 3488: loss 0.084858\n",
      "batch 3489: loss 0.362877\n",
      "batch 3490: loss 0.091961\n",
      "batch 3491: loss 0.037909\n",
      "batch 3492: loss 0.020509\n",
      "batch 3493: loss 0.058206\n",
      "batch 3494: loss 0.148501\n",
      "batch 3495: loss 0.151410\n",
      "batch 3496: loss 0.198682\n",
      "batch 3497: loss 0.063626\n",
      "batch 3498: loss 0.142312\n",
      "batch 3499: loss 0.099048\n",
      "batch 3500: loss 0.114502\n",
      "batch 3501: loss 0.026706\n",
      "batch 3502: loss 0.130862\n",
      "batch 3503: loss 0.080667\n",
      "batch 3504: loss 0.074045\n",
      "batch 3505: loss 0.047205\n",
      "batch 3506: loss 0.096777\n",
      "batch 3507: loss 0.081251\n",
      "batch 3508: loss 0.029819\n",
      "batch 3509: loss 0.057969\n",
      "batch 3510: loss 0.181920\n",
      "batch 3511: loss 0.034573\n",
      "batch 3512: loss 0.042262\n",
      "batch 3513: loss 0.021205\n",
      "batch 3514: loss 0.044789\n",
      "batch 3515: loss 0.233507\n",
      "batch 3516: loss 0.108841\n",
      "batch 3517: loss 0.087188\n",
      "batch 3518: loss 0.190930\n",
      "batch 3519: loss 0.019681\n",
      "batch 3520: loss 0.230267\n",
      "batch 3521: loss 0.015915\n",
      "batch 3522: loss 0.033783\n",
      "batch 3523: loss 0.035093\n",
      "batch 3524: loss 0.065926\n",
      "batch 3525: loss 0.082255\n",
      "batch 3526: loss 0.162481\n",
      "batch 3527: loss 0.344549\n",
      "batch 3528: loss 0.080415\n",
      "batch 3529: loss 0.057155\n",
      "batch 3530: loss 0.013693\n",
      "batch 3531: loss 0.136816\n",
      "batch 3532: loss 0.031541\n",
      "batch 3533: loss 0.253388\n",
      "batch 3534: loss 0.098724\n",
      "batch 3535: loss 0.016577\n",
      "batch 3536: loss 0.049867\n",
      "batch 3537: loss 0.082288\n",
      "batch 3538: loss 0.018324\n",
      "batch 3539: loss 0.149233\n",
      "batch 3540: loss 0.133557\n",
      "batch 3541: loss 0.130311\n",
      "batch 3542: loss 0.041606\n",
      "batch 3543: loss 0.035418\n",
      "batch 3544: loss 0.034212\n",
      "batch 3545: loss 0.096504\n",
      "batch 3546: loss 0.029931\n",
      "batch 3547: loss 0.103753\n",
      "batch 3548: loss 0.057783\n",
      "batch 3549: loss 0.112518\n",
      "batch 3550: loss 0.222112\n",
      "batch 3551: loss 0.021917\n",
      "batch 3552: loss 0.059836\n",
      "batch 3553: loss 0.082908\n",
      "batch 3554: loss 0.029388\n",
      "batch 3555: loss 0.143945\n",
      "batch 3556: loss 0.068200\n",
      "batch 3557: loss 0.030535\n",
      "batch 3558: loss 0.081175\n",
      "batch 3559: loss 0.036387\n",
      "batch 3560: loss 0.093209\n",
      "batch 3561: loss 0.040882\n",
      "batch 3562: loss 0.040871\n",
      "batch 3563: loss 0.084803\n",
      "batch 3564: loss 0.161268\n",
      "batch 3565: loss 0.133435\n",
      "batch 3566: loss 0.094518\n",
      "batch 3567: loss 0.023482\n",
      "batch 3568: loss 0.069351\n",
      "batch 3569: loss 0.088388\n",
      "batch 3570: loss 0.069746\n",
      "batch 3571: loss 0.122972\n",
      "batch 3572: loss 0.158517\n",
      "batch 3573: loss 0.083162\n",
      "batch 3574: loss 0.082936\n",
      "batch 3575: loss 0.130026\n",
      "batch 3576: loss 0.018447\n",
      "batch 3577: loss 0.060747\n",
      "batch 3578: loss 0.204002\n",
      "batch 3579: loss 0.081617\n",
      "batch 3580: loss 0.131365\n",
      "batch 3581: loss 0.021858\n",
      "batch 3582: loss 0.040268\n",
      "batch 3583: loss 0.021508\n",
      "batch 3584: loss 0.051679\n",
      "batch 3585: loss 0.011256\n",
      "batch 3586: loss 0.229158\n",
      "batch 3587: loss 0.131381\n",
      "batch 3588: loss 0.111553\n",
      "batch 3589: loss 0.051550\n",
      "batch 3590: loss 0.057967\n",
      "batch 3591: loss 0.083997\n",
      "batch 3592: loss 0.138699\n",
      "batch 3593: loss 0.043529\n",
      "batch 3594: loss 0.050857\n",
      "batch 3595: loss 0.072044\n",
      "batch 3596: loss 0.074874\n",
      "batch 3597: loss 0.143972\n",
      "batch 3598: loss 0.071850\n",
      "batch 3599: loss 0.200532\n",
      "batch 3600: loss 0.053309\n",
      "batch 3601: loss 0.197308\n",
      "batch 3602: loss 0.064761\n",
      "batch 3603: loss 0.070628\n",
      "batch 3604: loss 0.082112\n",
      "batch 3605: loss 0.008770\n",
      "batch 3606: loss 0.146654\n",
      "batch 3607: loss 0.056348\n",
      "batch 3608: loss 0.036963\n",
      "batch 3609: loss 0.030657\n",
      "batch 3610: loss 0.144529\n",
      "batch 3611: loss 0.031264\n",
      "batch 3612: loss 0.055368\n",
      "batch 3613: loss 0.080520\n",
      "batch 3614: loss 0.111888\n",
      "batch 3615: loss 0.105374\n",
      "batch 3616: loss 0.050724\n",
      "batch 3617: loss 0.021905\n",
      "batch 3618: loss 0.191734\n",
      "batch 3619: loss 0.056580\n",
      "batch 3620: loss 0.086705\n",
      "batch 3621: loss 0.048284\n",
      "batch 3622: loss 0.046720\n",
      "batch 3623: loss 0.025040\n",
      "batch 3624: loss 0.039296\n",
      "batch 3625: loss 0.092859\n",
      "batch 3626: loss 0.029767\n",
      "batch 3627: loss 0.027167\n",
      "batch 3628: loss 0.114984\n",
      "batch 3629: loss 0.106150\n",
      "batch 3630: loss 0.039381\n",
      "batch 3631: loss 0.020206\n",
      "batch 3632: loss 0.064789\n",
      "batch 3633: loss 0.032042\n",
      "batch 3634: loss 0.016984\n",
      "batch 3635: loss 0.034790\n",
      "batch 3636: loss 0.043763\n",
      "batch 3637: loss 0.092248\n",
      "batch 3638: loss 0.027657\n",
      "batch 3639: loss 0.262880\n",
      "batch 3640: loss 0.161630\n",
      "batch 3641: loss 0.062122\n",
      "batch 3642: loss 0.071359\n",
      "batch 3643: loss 0.056246\n",
      "batch 3644: loss 0.106513\n",
      "batch 3645: loss 0.055526\n",
      "batch 3646: loss 0.034760\n",
      "batch 3647: loss 0.011865\n",
      "batch 3648: loss 0.069713\n",
      "batch 3649: loss 0.077573\n",
      "batch 3650: loss 0.048735\n",
      "batch 3651: loss 0.113947\n",
      "batch 3652: loss 0.039825\n",
      "batch 3653: loss 0.023910\n",
      "batch 3654: loss 0.047354\n",
      "batch 3655: loss 0.060947\n",
      "batch 3656: loss 0.137266\n",
      "batch 3657: loss 0.076757\n",
      "batch 3658: loss 0.090194\n",
      "batch 3659: loss 0.046734\n",
      "batch 3660: loss 0.046176\n",
      "batch 3661: loss 0.049567\n",
      "batch 3662: loss 0.028052\n",
      "batch 3663: loss 0.077722\n",
      "batch 3664: loss 0.062642\n",
      "batch 3665: loss 0.015505\n",
      "batch 3666: loss 0.196726\n",
      "batch 3667: loss 0.131603\n",
      "batch 3668: loss 0.040061\n",
      "batch 3669: loss 0.041624\n",
      "batch 3670: loss 0.085705\n",
      "batch 3671: loss 0.140782\n",
      "batch 3672: loss 0.030192\n",
      "batch 3673: loss 0.027967\n",
      "batch 3674: loss 0.047875\n",
      "batch 3675: loss 0.055108\n",
      "batch 3676: loss 0.050628\n",
      "batch 3677: loss 0.068307\n",
      "batch 3678: loss 0.046015\n",
      "batch 3679: loss 0.068375\n",
      "batch 3680: loss 0.113291\n",
      "batch 3681: loss 0.036963\n",
      "batch 3682: loss 0.054061\n",
      "batch 3683: loss 0.047787\n",
      "batch 3684: loss 0.107045\n",
      "batch 3685: loss 0.073896\n",
      "batch 3686: loss 0.042256\n",
      "batch 3687: loss 0.088463\n",
      "batch 3688: loss 0.054611\n",
      "batch 3689: loss 0.032867\n",
      "batch 3690: loss 0.135179\n",
      "batch 3691: loss 0.074134\n",
      "batch 3692: loss 0.021977\n",
      "batch 3693: loss 0.041537\n",
      "batch 3694: loss 0.013847\n",
      "batch 3695: loss 0.030170\n",
      "batch 3696: loss 0.164442\n",
      "batch 3697: loss 0.095661\n",
      "batch 3698: loss 0.128810\n",
      "batch 3699: loss 0.016593\n",
      "batch 3700: loss 0.037851\n",
      "batch 3701: loss 0.017605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3702: loss 0.138025\n",
      "batch 3703: loss 0.092022\n",
      "batch 3704: loss 0.168532\n",
      "batch 3705: loss 0.070502\n",
      "batch 3706: loss 0.052274\n",
      "batch 3707: loss 0.053715\n",
      "batch 3708: loss 0.093549\n",
      "batch 3709: loss 0.108607\n",
      "batch 3710: loss 0.010725\n",
      "batch 3711: loss 0.133316\n",
      "batch 3712: loss 0.027444\n",
      "batch 3713: loss 0.044935\n",
      "batch 3714: loss 0.102989\n",
      "batch 3715: loss 0.044246\n",
      "batch 3716: loss 0.035496\n",
      "batch 3717: loss 0.120179\n",
      "batch 3718: loss 0.179447\n",
      "batch 3719: loss 0.039822\n",
      "batch 3720: loss 0.045079\n",
      "batch 3721: loss 0.082695\n",
      "batch 3722: loss 0.022994\n",
      "batch 3723: loss 0.096556\n",
      "batch 3724: loss 0.146626\n",
      "batch 3725: loss 0.023665\n",
      "batch 3726: loss 0.060866\n",
      "batch 3727: loss 0.122735\n",
      "batch 3728: loss 0.053382\n",
      "batch 3729: loss 0.050571\n",
      "batch 3730: loss 0.025430\n",
      "batch 3731: loss 0.015605\n",
      "batch 3732: loss 0.080272\n",
      "batch 3733: loss 0.026290\n",
      "batch 3734: loss 0.098870\n",
      "batch 3735: loss 0.028636\n",
      "batch 3736: loss 0.098575\n",
      "batch 3737: loss 0.053111\n",
      "batch 3738: loss 0.153110\n",
      "batch 3739: loss 0.032034\n",
      "batch 3740: loss 0.066567\n",
      "batch 3741: loss 0.094810\n",
      "batch 3742: loss 0.075988\n",
      "batch 3743: loss 0.042126\n",
      "batch 3744: loss 0.115157\n",
      "batch 3745: loss 0.165529\n",
      "batch 3746: loss 0.076814\n",
      "batch 3747: loss 0.174999\n",
      "batch 3748: loss 0.023278\n",
      "batch 3749: loss 0.145673\n",
      "batch 3750: loss 0.092090\n",
      "batch 3751: loss 0.042140\n",
      "batch 3752: loss 0.179991\n",
      "batch 3753: loss 0.068932\n",
      "batch 3754: loss 0.028531\n",
      "batch 3755: loss 0.158332\n",
      "batch 3756: loss 0.191784\n",
      "batch 3757: loss 0.045301\n",
      "batch 3758: loss 0.122364\n",
      "batch 3759: loss 0.028173\n",
      "batch 3760: loss 0.031969\n",
      "batch 3761: loss 0.043872\n",
      "batch 3762: loss 0.025780\n",
      "batch 3763: loss 0.234253\n",
      "batch 3764: loss 0.160582\n",
      "batch 3765: loss 0.073787\n",
      "batch 3766: loss 0.028694\n",
      "batch 3767: loss 0.077072\n",
      "batch 3768: loss 0.055877\n",
      "batch 3769: loss 0.016904\n",
      "batch 3770: loss 0.025974\n",
      "batch 3771: loss 0.054955\n",
      "batch 3772: loss 0.119040\n",
      "batch 3773: loss 0.034653\n",
      "batch 3774: loss 0.036902\n",
      "batch 3775: loss 0.015902\n",
      "batch 3776: loss 0.033703\n",
      "batch 3777: loss 0.032501\n",
      "batch 3778: loss 0.065204\n",
      "batch 3779: loss 0.040455\n",
      "batch 3780: loss 0.179633\n",
      "batch 3781: loss 0.009563\n",
      "batch 3782: loss 0.042756\n",
      "batch 3783: loss 0.102200\n",
      "batch 3784: loss 0.070651\n",
      "batch 3785: loss 0.035050\n",
      "batch 3786: loss 0.107087\n",
      "batch 3787: loss 0.060649\n",
      "batch 3788: loss 0.082509\n",
      "batch 3789: loss 0.055143\n",
      "batch 3790: loss 0.043075\n",
      "batch 3791: loss 0.056601\n",
      "batch 3792: loss 0.050689\n",
      "batch 3793: loss 0.079014\n",
      "batch 3794: loss 0.024328\n",
      "batch 3795: loss 0.090654\n",
      "batch 3796: loss 0.018619\n",
      "batch 3797: loss 0.045472\n",
      "batch 3798: loss 0.053686\n",
      "batch 3799: loss 0.019226\n",
      "batch 3800: loss 0.143433\n",
      "batch 3801: loss 0.052965\n",
      "batch 3802: loss 0.070399\n",
      "batch 3803: loss 0.096955\n",
      "batch 3804: loss 0.055696\n",
      "batch 3805: loss 0.256151\n",
      "batch 3806: loss 0.150164\n",
      "batch 3807: loss 0.261176\n",
      "batch 3808: loss 0.065640\n",
      "batch 3809: loss 0.056754\n",
      "batch 3810: loss 0.064578\n",
      "batch 3811: loss 0.122881\n",
      "batch 3812: loss 0.036029\n",
      "batch 3813: loss 0.059212\n",
      "batch 3814: loss 0.078316\n",
      "batch 3815: loss 0.081894\n",
      "batch 3816: loss 0.044985\n",
      "batch 3817: loss 0.034365\n",
      "batch 3818: loss 0.043266\n",
      "batch 3819: loss 0.037080\n",
      "batch 3820: loss 0.068110\n",
      "batch 3821: loss 0.064026\n",
      "batch 3822: loss 0.053527\n",
      "batch 3823: loss 0.037867\n",
      "batch 3824: loss 0.121820\n",
      "batch 3825: loss 0.130446\n",
      "batch 3826: loss 0.008768\n",
      "batch 3827: loss 0.031172\n",
      "batch 3828: loss 0.038239\n",
      "batch 3829: loss 0.150546\n",
      "batch 3830: loss 0.078117\n",
      "batch 3831: loss 0.085683\n",
      "batch 3832: loss 0.039943\n",
      "batch 3833: loss 0.191181\n",
      "batch 3834: loss 0.084372\n",
      "batch 3835: loss 0.078596\n",
      "batch 3836: loss 0.092189\n",
      "batch 3837: loss 0.064345\n",
      "batch 3838: loss 0.145988\n",
      "batch 3839: loss 0.060913\n",
      "batch 3840: loss 0.022231\n",
      "batch 3841: loss 0.108204\n",
      "batch 3842: loss 0.029623\n",
      "batch 3843: loss 0.104792\n",
      "batch 3844: loss 0.297705\n",
      "batch 3845: loss 0.218707\n",
      "batch 3846: loss 0.057440\n",
      "batch 3847: loss 0.132511\n",
      "batch 3848: loss 0.056895\n",
      "batch 3849: loss 0.037657\n",
      "batch 3850: loss 0.037932\n",
      "batch 3851: loss 0.010226\n",
      "batch 3852: loss 0.047260\n",
      "batch 3853: loss 0.043222\n",
      "batch 3854: loss 0.039819\n",
      "batch 3855: loss 0.054914\n",
      "batch 3856: loss 0.084937\n",
      "batch 3857: loss 0.193320\n",
      "batch 3858: loss 0.114240\n",
      "batch 3859: loss 0.153038\n",
      "batch 3860: loss 0.174300\n",
      "batch 3861: loss 0.009400\n",
      "batch 3862: loss 0.114854\n",
      "batch 3863: loss 0.061212\n",
      "batch 3864: loss 0.246015\n",
      "batch 3865: loss 0.212503\n",
      "batch 3866: loss 0.047790\n",
      "batch 3867: loss 0.059123\n",
      "batch 3868: loss 0.025699\n",
      "batch 3869: loss 0.045114\n",
      "batch 3870: loss 0.047136\n",
      "batch 3871: loss 0.066890\n",
      "batch 3872: loss 0.019235\n",
      "batch 3873: loss 0.067194\n",
      "batch 3874: loss 0.042064\n",
      "batch 3875: loss 0.032690\n",
      "batch 3876: loss 0.087024\n",
      "batch 3877: loss 0.049384\n",
      "batch 3878: loss 0.033714\n",
      "batch 3879: loss 0.043374\n",
      "batch 3880: loss 0.019638\n",
      "batch 3881: loss 0.085555\n",
      "batch 3882: loss 0.253606\n",
      "batch 3883: loss 0.019289\n",
      "batch 3884: loss 0.027172\n",
      "batch 3885: loss 0.106948\n",
      "batch 3886: loss 0.136225\n",
      "batch 3887: loss 0.071327\n",
      "batch 3888: loss 0.027254\n",
      "batch 3889: loss 0.053681\n",
      "batch 3890: loss 0.102989\n",
      "batch 3891: loss 0.122824\n",
      "batch 3892: loss 0.138673\n",
      "batch 3893: loss 0.133619\n",
      "batch 3894: loss 0.013651\n",
      "batch 3895: loss 0.327582\n",
      "batch 3896: loss 0.033993\n",
      "batch 3897: loss 0.020150\n",
      "batch 3898: loss 0.144219\n",
      "batch 3899: loss 0.099731\n",
      "batch 3900: loss 0.015117\n",
      "batch 3901: loss 0.049668\n",
      "batch 3902: loss 0.024712\n",
      "batch 3903: loss 0.085733\n",
      "batch 3904: loss 0.117548\n",
      "batch 3905: loss 0.132880\n",
      "batch 3906: loss 0.015487\n",
      "batch 3907: loss 0.019574\n",
      "batch 3908: loss 0.018749\n",
      "batch 3909: loss 0.063434\n",
      "batch 3910: loss 0.055785\n",
      "batch 3911: loss 0.079731\n",
      "batch 3912: loss 0.074469\n",
      "batch 3913: loss 0.033961\n",
      "batch 3914: loss 0.080120\n",
      "batch 3915: loss 0.332030\n",
      "batch 3916: loss 0.120358\n",
      "batch 3917: loss 0.037618\n",
      "batch 3918: loss 0.036079\n",
      "batch 3919: loss 0.042077\n",
      "batch 3920: loss 0.047700\n",
      "batch 3921: loss 0.036344\n",
      "batch 3922: loss 0.155370\n",
      "batch 3923: loss 0.053348\n",
      "batch 3924: loss 0.031372\n",
      "batch 3925: loss 0.113248\n",
      "batch 3926: loss 0.091168\n",
      "batch 3927: loss 0.090551\n",
      "batch 3928: loss 0.034016\n",
      "batch 3929: loss 0.029520\n",
      "batch 3930: loss 0.045782\n",
      "batch 3931: loss 0.048921\n",
      "batch 3932: loss 0.089514\n",
      "batch 3933: loss 0.055949\n",
      "batch 3934: loss 0.079660\n",
      "batch 3935: loss 0.073748\n",
      "batch 3936: loss 0.033215\n",
      "batch 3937: loss 0.020074\n",
      "batch 3938: loss 0.082209\n",
      "batch 3939: loss 0.101721\n",
      "batch 3940: loss 0.008956\n",
      "batch 3941: loss 0.119352\n",
      "batch 3942: loss 0.108480\n",
      "batch 3943: loss 0.163040\n",
      "batch 3944: loss 0.087898\n",
      "batch 3945: loss 0.010077\n",
      "batch 3946: loss 0.156433\n",
      "batch 3947: loss 0.041103\n",
      "batch 3948: loss 0.053499\n",
      "batch 3949: loss 0.048667\n",
      "batch 3950: loss 0.149303\n",
      "batch 3951: loss 0.007324\n",
      "batch 3952: loss 0.041414\n",
      "batch 3953: loss 0.043493\n",
      "batch 3954: loss 0.119645\n",
      "batch 3955: loss 0.089800\n",
      "batch 3956: loss 0.139193\n",
      "batch 3957: loss 0.214910\n",
      "batch 3958: loss 0.111230\n",
      "batch 3959: loss 0.043517\n",
      "batch 3960: loss 0.043744\n",
      "batch 3961: loss 0.145395\n",
      "batch 3962: loss 0.216632\n",
      "batch 3963: loss 0.072754\n",
      "batch 3964: loss 0.042402\n",
      "batch 3965: loss 0.137004\n",
      "batch 3966: loss 0.070860\n",
      "batch 3967: loss 0.118177\n",
      "batch 3968: loss 0.052065\n",
      "batch 3969: loss 0.068634\n",
      "batch 3970: loss 0.103594\n",
      "batch 3971: loss 0.067295\n",
      "batch 3972: loss 0.060943\n",
      "batch 3973: loss 0.020887\n",
      "batch 3974: loss 0.028257\n",
      "batch 3975: loss 0.029919\n",
      "batch 3976: loss 0.111000\n",
      "batch 3977: loss 0.061201\n",
      "batch 3978: loss 0.078858\n",
      "batch 3979: loss 0.058576\n",
      "batch 3980: loss 0.051251\n",
      "batch 3981: loss 0.093029\n",
      "batch 3982: loss 0.174244\n",
      "batch 3983: loss 0.039127\n",
      "batch 3984: loss 0.076595\n",
      "batch 3985: loss 0.015177\n",
      "batch 3986: loss 0.084304\n",
      "batch 3987: loss 0.035521\n",
      "batch 3988: loss 0.044936\n",
      "batch 3989: loss 0.146984\n",
      "batch 3990: loss 0.029820\n",
      "batch 3991: loss 0.073352\n",
      "batch 3992: loss 0.066951\n",
      "batch 3993: loss 0.122876\n",
      "batch 3994: loss 0.067303\n",
      "batch 3995: loss 0.231369\n",
      "batch 3996: loss 0.251590\n",
      "batch 3997: loss 0.058757\n",
      "batch 3998: loss 0.034396\n",
      "batch 3999: loss 0.045730\n",
      "batch 4000: loss 0.090676\n",
      "batch 4001: loss 0.032294\n",
      "batch 4002: loss 0.025635\n",
      "batch 4003: loss 0.177603\n",
      "batch 4004: loss 0.050494\n",
      "batch 4005: loss 0.048312\n",
      "batch 4006: loss 0.031116\n",
      "batch 4007: loss 0.191404\n",
      "batch 4008: loss 0.062388\n",
      "batch 4009: loss 0.086819\n",
      "batch 4010: loss 0.052713\n",
      "batch 4011: loss 0.036754\n",
      "batch 4012: loss 0.133211\n",
      "batch 4013: loss 0.041345\n",
      "batch 4014: loss 0.037261\n",
      "batch 4015: loss 0.067805\n",
      "batch 4016: loss 0.026657\n",
      "batch 4017: loss 0.039424\n",
      "batch 4018: loss 0.038955\n",
      "batch 4019: loss 0.115166\n",
      "batch 4020: loss 0.016452\n",
      "batch 4021: loss 0.053521\n",
      "batch 4022: loss 0.124063\n",
      "batch 4023: loss 0.331649\n",
      "batch 4024: loss 0.044413\n",
      "batch 4025: loss 0.098829\n",
      "batch 4026: loss 0.102513\n",
      "batch 4027: loss 0.027564\n",
      "batch 4028: loss 0.012778\n",
      "batch 4029: loss 0.082292\n",
      "batch 4030: loss 0.018585\n",
      "batch 4031: loss 0.021383\n",
      "batch 4032: loss 0.109912\n",
      "batch 4033: loss 0.184948\n",
      "batch 4034: loss 0.078991\n",
      "batch 4035: loss 0.073546\n",
      "batch 4036: loss 0.120015\n",
      "batch 4037: loss 0.028359\n",
      "batch 4038: loss 0.112342\n",
      "batch 4039: loss 0.049797\n",
      "batch 4040: loss 0.036041\n",
      "batch 4041: loss 0.085933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4042: loss 0.027052\n",
      "batch 4043: loss 0.049749\n",
      "batch 4044: loss 0.073173\n",
      "batch 4045: loss 0.128604\n",
      "batch 4046: loss 0.073971\n",
      "batch 4047: loss 0.035247\n",
      "batch 4048: loss 0.025738\n",
      "batch 4049: loss 0.024741\n",
      "batch 4050: loss 0.019606\n",
      "batch 4051: loss 0.119411\n",
      "batch 4052: loss 0.037069\n",
      "batch 4053: loss 0.067469\n",
      "batch 4054: loss 0.053603\n",
      "batch 4055: loss 0.027569\n",
      "batch 4056: loss 0.079934\n",
      "batch 4057: loss 0.082109\n",
      "batch 4058: loss 0.049387\n",
      "batch 4059: loss 0.276429\n",
      "batch 4060: loss 0.075579\n",
      "batch 4061: loss 0.052072\n",
      "batch 4062: loss 0.089996\n",
      "batch 4063: loss 0.048676\n",
      "batch 4064: loss 0.043466\n",
      "batch 4065: loss 0.021156\n",
      "batch 4066: loss 0.004475\n",
      "batch 4067: loss 0.084687\n",
      "batch 4068: loss 0.058513\n",
      "batch 4069: loss 0.060451\n",
      "batch 4070: loss 0.071697\n",
      "batch 4071: loss 0.046369\n",
      "batch 4072: loss 0.037537\n",
      "batch 4073: loss 0.049000\n",
      "batch 4074: loss 0.019922\n",
      "batch 4075: loss 0.008100\n",
      "batch 4076: loss 0.047846\n",
      "batch 4077: loss 0.040992\n",
      "batch 4078: loss 0.081566\n",
      "batch 4079: loss 0.043458\n",
      "batch 4080: loss 0.115521\n",
      "batch 4081: loss 0.126654\n",
      "batch 4082: loss 0.089122\n",
      "batch 4083: loss 0.016516\n",
      "batch 4084: loss 0.019972\n",
      "batch 4085: loss 0.012839\n",
      "batch 4086: loss 0.130308\n",
      "batch 4087: loss 0.088593\n",
      "batch 4088: loss 0.014180\n",
      "batch 4089: loss 0.017110\n",
      "batch 4090: loss 0.028361\n",
      "batch 4091: loss 0.044367\n",
      "batch 4092: loss 0.161969\n",
      "batch 4093: loss 0.092729\n",
      "batch 4094: loss 0.228875\n",
      "batch 4095: loss 0.146930\n",
      "batch 4096: loss 0.093425\n",
      "batch 4097: loss 0.012599\n",
      "batch 4098: loss 0.212903\n",
      "batch 4099: loss 0.085497\n",
      "batch 4100: loss 0.055624\n",
      "batch 4101: loss 0.048230\n",
      "batch 4102: loss 0.072052\n",
      "batch 4103: loss 0.014999\n",
      "batch 4104: loss 0.149846\n",
      "batch 4105: loss 0.042854\n",
      "batch 4106: loss 0.049296\n",
      "batch 4107: loss 0.035405\n",
      "batch 4108: loss 0.170536\n",
      "batch 4109: loss 0.073562\n",
      "batch 4110: loss 0.060685\n",
      "batch 4111: loss 0.032653\n",
      "batch 4112: loss 0.105642\n",
      "batch 4113: loss 0.024409\n",
      "batch 4114: loss 0.079961\n",
      "batch 4115: loss 0.044856\n",
      "batch 4116: loss 0.015396\n",
      "batch 4117: loss 0.024214\n",
      "batch 4118: loss 0.078920\n",
      "batch 4119: loss 0.011590\n",
      "batch 4120: loss 0.065388\n",
      "batch 4121: loss 0.062423\n",
      "batch 4122: loss 0.020410\n",
      "batch 4123: loss 0.039236\n",
      "batch 4124: loss 0.038844\n",
      "batch 4125: loss 0.090783\n",
      "batch 4126: loss 0.053651\n",
      "batch 4127: loss 0.099869\n",
      "batch 4128: loss 0.068713\n",
      "batch 4129: loss 0.051327\n",
      "batch 4130: loss 0.008616\n",
      "batch 4131: loss 0.124327\n",
      "batch 4132: loss 0.052291\n",
      "batch 4133: loss 0.081678\n",
      "batch 4134: loss 0.053526\n",
      "batch 4135: loss 0.038771\n",
      "batch 4136: loss 0.056085\n",
      "batch 4137: loss 0.034644\n",
      "batch 4138: loss 0.190075\n",
      "batch 4139: loss 0.142331\n",
      "batch 4140: loss 0.074657\n",
      "batch 4141: loss 0.116869\n",
      "batch 4142: loss 0.055241\n",
      "batch 4143: loss 0.124438\n",
      "batch 4144: loss 0.201605\n",
      "batch 4145: loss 0.014526\n",
      "batch 4146: loss 0.010947\n",
      "batch 4147: loss 0.035547\n",
      "batch 4148: loss 0.201604\n",
      "batch 4149: loss 0.014084\n",
      "batch 4150: loss 0.605255\n",
      "batch 4151: loss 0.027607\n",
      "batch 4152: loss 0.270852\n",
      "batch 4153: loss 0.076487\n",
      "batch 4154: loss 0.057986\n",
      "batch 4155: loss 0.018981\n",
      "batch 4156: loss 0.076294\n",
      "batch 4157: loss 0.091508\n",
      "batch 4158: loss 0.046133\n",
      "batch 4159: loss 0.123879\n",
      "batch 4160: loss 0.043852\n",
      "batch 4161: loss 0.118956\n",
      "batch 4162: loss 0.085416\n",
      "batch 4163: loss 0.102336\n",
      "batch 4164: loss 0.080182\n",
      "batch 4165: loss 0.201192\n",
      "batch 4166: loss 0.308555\n",
      "batch 4167: loss 0.022210\n",
      "batch 4168: loss 0.036013\n",
      "batch 4169: loss 0.019764\n",
      "batch 4170: loss 0.013139\n",
      "batch 4171: loss 0.013033\n",
      "batch 4172: loss 0.039900\n",
      "batch 4173: loss 0.143513\n",
      "batch 4174: loss 0.123936\n",
      "batch 4175: loss 0.046784\n",
      "batch 4176: loss 0.015555\n",
      "batch 4177: loss 0.015493\n",
      "batch 4178: loss 0.156970\n",
      "batch 4179: loss 0.019178\n",
      "batch 4180: loss 0.067691\n",
      "batch 4181: loss 0.067981\n",
      "batch 4182: loss 0.067565\n",
      "batch 4183: loss 0.023119\n",
      "batch 4184: loss 0.051913\n",
      "batch 4185: loss 0.097091\n",
      "batch 4186: loss 0.052618\n",
      "batch 4187: loss 0.026980\n",
      "batch 4188: loss 0.068306\n",
      "batch 4189: loss 0.040005\n",
      "batch 4190: loss 0.019114\n",
      "batch 4191: loss 0.192382\n",
      "batch 4192: loss 0.043407\n",
      "batch 4193: loss 0.150657\n",
      "batch 4194: loss 0.036521\n",
      "batch 4195: loss 0.104712\n",
      "batch 4196: loss 0.104278\n",
      "batch 4197: loss 0.140105\n",
      "batch 4198: loss 0.089240\n",
      "batch 4199: loss 0.017902\n",
      "batch 4200: loss 0.092385\n",
      "batch 4201: loss 0.012192\n",
      "batch 4202: loss 0.084332\n",
      "batch 4203: loss 0.067584\n",
      "batch 4204: loss 0.059587\n",
      "batch 4205: loss 0.104892\n",
      "batch 4206: loss 0.054507\n",
      "batch 4207: loss 0.097863\n",
      "batch 4208: loss 0.085648\n",
      "batch 4209: loss 0.107367\n",
      "batch 4210: loss 0.073830\n",
      "batch 4211: loss 0.104571\n",
      "batch 4212: loss 0.008772\n",
      "batch 4213: loss 0.079911\n",
      "batch 4214: loss 0.095460\n",
      "batch 4215: loss 0.116858\n",
      "batch 4216: loss 0.088460\n",
      "batch 4217: loss 0.032941\n",
      "batch 4218: loss 0.095289\n",
      "batch 4219: loss 0.041163\n",
      "batch 4220: loss 0.109289\n",
      "batch 4221: loss 0.057827\n",
      "batch 4222: loss 0.034152\n",
      "batch 4223: loss 0.057897\n",
      "batch 4224: loss 0.039261\n",
      "batch 4225: loss 0.169963\n",
      "batch 4226: loss 0.102865\n",
      "batch 4227: loss 0.011242\n",
      "batch 4228: loss 0.089710\n",
      "batch 4229: loss 0.162486\n",
      "batch 4230: loss 0.117185\n",
      "batch 4231: loss 0.056120\n",
      "batch 4232: loss 0.036194\n",
      "batch 4233: loss 0.031692\n",
      "batch 4234: loss 0.029204\n",
      "batch 4235: loss 0.033279\n",
      "batch 4236: loss 0.127473\n",
      "batch 4237: loss 0.188858\n",
      "batch 4238: loss 0.058668\n",
      "batch 4239: loss 0.208606\n",
      "batch 4240: loss 0.042416\n",
      "batch 4241: loss 0.037706\n",
      "batch 4242: loss 0.057708\n",
      "batch 4243: loss 0.041907\n",
      "batch 4244: loss 0.144014\n",
      "batch 4245: loss 0.026602\n",
      "batch 4246: loss 0.038590\n",
      "batch 4247: loss 0.044884\n",
      "batch 4248: loss 0.106039\n",
      "batch 4249: loss 0.118054\n",
      "batch 4250: loss 0.027284\n",
      "batch 4251: loss 0.083321\n",
      "batch 4252: loss 0.178867\n",
      "batch 4253: loss 0.038699\n",
      "batch 4254: loss 0.120050\n",
      "batch 4255: loss 0.063532\n",
      "batch 4256: loss 0.109450\n",
      "batch 4257: loss 0.039058\n",
      "batch 4258: loss 0.075584\n",
      "batch 4259: loss 0.077035\n",
      "batch 4260: loss 0.060361\n",
      "batch 4261: loss 0.081324\n",
      "batch 4262: loss 0.059201\n",
      "batch 4263: loss 0.031396\n",
      "batch 4264: loss 0.081830\n",
      "batch 4265: loss 0.022534\n",
      "batch 4266: loss 0.039490\n",
      "batch 4267: loss 0.071891\n",
      "batch 4268: loss 0.162456\n",
      "batch 4269: loss 0.051650\n",
      "batch 4270: loss 0.061628\n",
      "batch 4271: loss 0.050112\n",
      "batch 4272: loss 0.025942\n",
      "batch 4273: loss 0.102328\n",
      "batch 4274: loss 0.186231\n",
      "batch 4275: loss 0.042792\n",
      "batch 4276: loss 0.075613\n",
      "batch 4277: loss 0.109393\n",
      "batch 4278: loss 0.028065\n",
      "batch 4279: loss 0.101987\n",
      "batch 4280: loss 0.093746\n",
      "batch 4281: loss 0.043007\n",
      "batch 4282: loss 0.072986\n",
      "batch 4283: loss 0.128164\n",
      "batch 4284: loss 0.070486\n",
      "batch 4285: loss 0.051895\n",
      "batch 4286: loss 0.042117\n",
      "batch 4287: loss 0.115683\n",
      "batch 4288: loss 0.081727\n",
      "batch 4289: loss 0.080469\n",
      "batch 4290: loss 0.107762\n",
      "batch 4291: loss 0.053370\n",
      "batch 4292: loss 0.157633\n",
      "batch 4293: loss 0.101981\n",
      "batch 4294: loss 0.124795\n",
      "batch 4295: loss 0.028524\n",
      "batch 4296: loss 0.116508\n",
      "batch 4297: loss 0.070505\n",
      "batch 4298: loss 0.024457\n",
      "batch 4299: loss 0.086197\n",
      "batch 4300: loss 0.046159\n",
      "batch 4301: loss 0.026973\n",
      "batch 4302: loss 0.021528\n",
      "batch 4303: loss 0.029034\n",
      "batch 4304: loss 0.058691\n",
      "batch 4305: loss 0.062312\n",
      "batch 4306: loss 0.124057\n",
      "batch 4307: loss 0.070526\n",
      "batch 4308: loss 0.347871\n",
      "batch 4309: loss 0.104273\n",
      "batch 4310: loss 0.045910\n",
      "batch 4311: loss 0.172411\n",
      "batch 4312: loss 0.096635\n",
      "batch 4313: loss 0.107384\n",
      "batch 4314: loss 0.087780\n",
      "batch 4315: loss 0.053591\n",
      "batch 4316: loss 0.034739\n",
      "batch 4317: loss 0.059618\n",
      "batch 4318: loss 0.096629\n",
      "batch 4319: loss 0.214592\n",
      "batch 4320: loss 0.040801\n",
      "batch 4321: loss 0.123927\n",
      "batch 4322: loss 0.025848\n",
      "batch 4323: loss 0.026401\n",
      "batch 4324: loss 0.048656\n",
      "batch 4325: loss 0.032546\n",
      "batch 4326: loss 0.046441\n",
      "batch 4327: loss 0.045902\n",
      "batch 4328: loss 0.041521\n",
      "batch 4329: loss 0.050230\n",
      "batch 4330: loss 0.036274\n",
      "batch 4331: loss 0.023069\n",
      "batch 4332: loss 0.052301\n",
      "batch 4333: loss 0.015460\n",
      "batch 4334: loss 0.037628\n",
      "batch 4335: loss 0.128663\n",
      "batch 4336: loss 0.037207\n",
      "batch 4337: loss 0.014345\n",
      "batch 4338: loss 0.063126\n",
      "batch 4339: loss 0.013859\n",
      "batch 4340: loss 0.024068\n",
      "batch 4341: loss 0.030822\n",
      "batch 4342: loss 0.103291\n",
      "batch 4343: loss 0.058960\n",
      "batch 4344: loss 0.275580\n",
      "batch 4345: loss 0.137296\n",
      "batch 4346: loss 0.030043\n",
      "batch 4347: loss 0.039124\n",
      "batch 4348: loss 0.061704\n",
      "batch 4349: loss 0.024283\n",
      "batch 4350: loss 0.127022\n",
      "batch 4351: loss 0.026178\n",
      "batch 4352: loss 0.030649\n",
      "batch 4353: loss 0.029025\n",
      "batch 4354: loss 0.081123\n",
      "batch 4355: loss 0.018372\n",
      "batch 4356: loss 0.118965\n",
      "batch 4357: loss 0.025990\n",
      "batch 4358: loss 0.041990\n",
      "batch 4359: loss 0.024841\n",
      "batch 4360: loss 0.020850\n",
      "batch 4361: loss 0.040264\n",
      "batch 4362: loss 0.030211\n",
      "batch 4363: loss 0.048230\n",
      "batch 4364: loss 0.063977\n",
      "batch 4365: loss 0.106253\n",
      "batch 4366: loss 0.035495\n",
      "batch 4367: loss 0.027003\n",
      "batch 4368: loss 0.013201\n",
      "batch 4369: loss 0.034719\n",
      "batch 4370: loss 0.048350\n",
      "batch 4371: loss 0.086643\n",
      "batch 4372: loss 0.147904\n",
      "batch 4373: loss 0.034150\n",
      "batch 4374: loss 0.110322\n",
      "batch 4375: loss 0.165571\n",
      "batch 4376: loss 0.029342\n",
      "batch 4377: loss 0.034819\n",
      "batch 4378: loss 0.018131\n",
      "batch 4379: loss 0.014910\n",
      "batch 4380: loss 0.112435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4381: loss 0.148139\n",
      "batch 4382: loss 0.053431\n",
      "batch 4383: loss 0.050869\n",
      "batch 4384: loss 0.049054\n",
      "batch 4385: loss 0.082399\n",
      "batch 4386: loss 0.038735\n",
      "batch 4387: loss 0.127622\n",
      "batch 4388: loss 0.020856\n",
      "batch 4389: loss 0.013505\n",
      "batch 4390: loss 0.094363\n",
      "batch 4391: loss 0.025532\n",
      "batch 4392: loss 0.057302\n",
      "batch 4393: loss 0.046809\n",
      "batch 4394: loss 0.051599\n",
      "batch 4395: loss 0.014929\n",
      "batch 4396: loss 0.105968\n",
      "batch 4397: loss 0.021007\n",
      "batch 4398: loss 0.019068\n",
      "batch 4399: loss 0.077884\n",
      "batch 4400: loss 0.055025\n",
      "batch 4401: loss 0.029480\n",
      "batch 4402: loss 0.019754\n",
      "batch 4403: loss 0.018744\n",
      "batch 4404: loss 0.011391\n",
      "batch 4405: loss 0.037763\n",
      "batch 4406: loss 0.134452\n",
      "batch 4407: loss 0.012631\n",
      "batch 4408: loss 0.089242\n",
      "batch 4409: loss 0.173244\n",
      "batch 4410: loss 0.082721\n",
      "batch 4411: loss 0.076199\n",
      "batch 4412: loss 0.012935\n",
      "batch 4413: loss 0.173199\n",
      "batch 4414: loss 0.067037\n",
      "batch 4415: loss 0.012305\n",
      "batch 4416: loss 0.323236\n",
      "batch 4417: loss 0.065713\n",
      "batch 4418: loss 0.093216\n",
      "batch 4419: loss 0.031721\n",
      "batch 4420: loss 0.075924\n",
      "batch 4421: loss 0.011196\n",
      "batch 4422: loss 0.152054\n",
      "batch 4423: loss 0.004327\n",
      "batch 4424: loss 0.016615\n",
      "batch 4425: loss 0.124196\n",
      "batch 4426: loss 0.211141\n",
      "batch 4427: loss 0.055135\n",
      "batch 4428: loss 0.108009\n",
      "batch 4429: loss 0.068400\n",
      "batch 4430: loss 0.037640\n",
      "batch 4431: loss 0.032075\n",
      "batch 4432: loss 0.085681\n",
      "batch 4433: loss 0.147619\n",
      "batch 4434: loss 0.032430\n",
      "batch 4435: loss 0.012488\n",
      "batch 4436: loss 0.026070\n",
      "batch 4437: loss 0.054677\n",
      "batch 4438: loss 0.048449\n",
      "batch 4439: loss 0.031475\n",
      "batch 4440: loss 0.023591\n",
      "batch 4441: loss 0.025735\n",
      "batch 4442: loss 0.085767\n",
      "batch 4443: loss 0.033246\n",
      "batch 4444: loss 0.033224\n",
      "batch 4445: loss 0.045972\n",
      "batch 4446: loss 0.110418\n",
      "batch 4447: loss 0.048091\n",
      "batch 4448: loss 0.015703\n",
      "batch 4449: loss 0.090920\n",
      "batch 4450: loss 0.033117\n",
      "batch 4451: loss 0.084723\n",
      "batch 4452: loss 0.027165\n",
      "batch 4453: loss 0.056556\n",
      "batch 4454: loss 0.102153\n",
      "batch 4455: loss 0.074572\n",
      "batch 4456: loss 0.127458\n",
      "batch 4457: loss 0.145296\n",
      "batch 4458: loss 0.112093\n",
      "batch 4459: loss 0.067969\n",
      "batch 4460: loss 0.007704\n",
      "batch 4461: loss 0.077747\n",
      "batch 4462: loss 0.067456\n",
      "batch 4463: loss 0.029284\n",
      "batch 4464: loss 0.024965\n",
      "batch 4465: loss 0.027775\n",
      "batch 4466: loss 0.021888\n",
      "batch 4467: loss 0.031405\n",
      "batch 4468: loss 0.175279\n",
      "batch 4469: loss 0.016842\n",
      "batch 4470: loss 0.029059\n",
      "batch 4471: loss 0.015879\n",
      "batch 4472: loss 0.122011\n",
      "batch 4473: loss 0.050440\n",
      "batch 4474: loss 0.017002\n",
      "batch 4475: loss 0.130941\n",
      "batch 4476: loss 0.008761\n",
      "batch 4477: loss 0.018634\n",
      "batch 4478: loss 0.220100\n",
      "batch 4479: loss 0.041372\n",
      "batch 4480: loss 0.020451\n",
      "batch 4481: loss 0.036131\n",
      "batch 4482: loss 0.027750\n",
      "batch 4483: loss 0.121817\n",
      "batch 4484: loss 0.086939\n",
      "batch 4485: loss 0.015820\n",
      "batch 4486: loss 0.088319\n",
      "batch 4487: loss 0.043568\n",
      "batch 4488: loss 0.054225\n",
      "batch 4489: loss 0.023462\n",
      "batch 4490: loss 0.053176\n",
      "batch 4491: loss 0.065578\n",
      "batch 4492: loss 0.023005\n",
      "batch 4493: loss 0.024343\n",
      "batch 4494: loss 0.055873\n",
      "batch 4495: loss 0.062710\n",
      "batch 4496: loss 0.091197\n",
      "batch 4497: loss 0.106878\n",
      "batch 4498: loss 0.033716\n",
      "batch 4499: loss 0.068935\n",
      "batch 4500: loss 0.044057\n",
      "batch 4501: loss 0.024945\n",
      "batch 4502: loss 0.021845\n",
      "batch 4503: loss 0.016769\n",
      "batch 4504: loss 0.022434\n",
      "batch 4505: loss 0.079883\n",
      "batch 4506: loss 0.042949\n",
      "batch 4507: loss 0.020909\n",
      "batch 4508: loss 0.047406\n",
      "batch 4509: loss 0.044268\n",
      "batch 4510: loss 0.098195\n",
      "batch 4511: loss 0.021285\n",
      "batch 4512: loss 0.012929\n",
      "batch 4513: loss 0.041892\n",
      "batch 4514: loss 0.064603\n",
      "batch 4515: loss 0.084701\n",
      "batch 4516: loss 0.049247\n",
      "batch 4517: loss 0.045837\n",
      "batch 4518: loss 0.128531\n",
      "batch 4519: loss 0.063113\n",
      "batch 4520: loss 0.033797\n",
      "batch 4521: loss 0.088928\n",
      "batch 4522: loss 0.116279\n",
      "batch 4523: loss 0.014175\n",
      "batch 4524: loss 0.118251\n",
      "batch 4525: loss 0.079808\n",
      "batch 4526: loss 0.038346\n",
      "batch 4527: loss 0.106939\n",
      "batch 4528: loss 0.014926\n",
      "batch 4529: loss 0.123004\n",
      "batch 4530: loss 0.101266\n",
      "batch 4531: loss 0.027081\n",
      "batch 4532: loss 0.086065\n",
      "batch 4533: loss 0.065873\n",
      "batch 4534: loss 0.123745\n",
      "batch 4535: loss 0.007599\n",
      "batch 4536: loss 0.092662\n",
      "batch 4537: loss 0.132345\n",
      "batch 4538: loss 0.006845\n",
      "batch 4539: loss 0.045563\n",
      "batch 4540: loss 0.111441\n",
      "batch 4541: loss 0.058674\n",
      "batch 4542: loss 0.027188\n",
      "batch 4543: loss 0.056088\n",
      "batch 4544: loss 0.175145\n",
      "batch 4545: loss 0.088003\n",
      "batch 4546: loss 0.017361\n",
      "batch 4547: loss 0.056009\n",
      "batch 4548: loss 0.110581\n",
      "batch 4549: loss 0.083536\n",
      "batch 4550: loss 0.034855\n",
      "batch 4551: loss 0.084967\n",
      "batch 4552: loss 0.018427\n",
      "batch 4553: loss 0.063835\n",
      "batch 4554: loss 0.055911\n",
      "batch 4555: loss 0.059145\n",
      "batch 4556: loss 0.174529\n",
      "batch 4557: loss 0.057619\n",
      "batch 4558: loss 0.015503\n",
      "batch 4559: loss 0.066736\n",
      "batch 4560: loss 0.066873\n",
      "batch 4561: loss 0.014094\n",
      "batch 4562: loss 0.045063\n",
      "batch 4563: loss 0.018223\n",
      "batch 4564: loss 0.182170\n",
      "batch 4565: loss 0.029136\n",
      "batch 4566: loss 0.080091\n",
      "batch 4567: loss 0.035781\n",
      "batch 4568: loss 0.022487\n",
      "batch 4569: loss 0.102530\n",
      "batch 4570: loss 0.028608\n",
      "batch 4571: loss 0.191773\n",
      "batch 4572: loss 0.076153\n",
      "batch 4573: loss 0.100440\n",
      "batch 4574: loss 0.076571\n",
      "batch 4575: loss 0.169385\n",
      "batch 4576: loss 0.027540\n",
      "batch 4577: loss 0.045157\n",
      "batch 4578: loss 0.051879\n",
      "batch 4579: loss 0.045421\n",
      "batch 4580: loss 0.070334\n",
      "batch 4581: loss 0.017558\n",
      "batch 4582: loss 0.132342\n",
      "batch 4583: loss 0.040249\n",
      "batch 4584: loss 0.062533\n",
      "batch 4585: loss 0.031846\n",
      "batch 4586: loss 0.110874\n",
      "batch 4587: loss 0.018048\n",
      "batch 4588: loss 0.103963\n",
      "batch 4589: loss 0.051621\n",
      "batch 4590: loss 0.022188\n",
      "batch 4591: loss 0.033580\n",
      "batch 4592: loss 0.052304\n",
      "batch 4593: loss 0.023138\n",
      "batch 4594: loss 0.029300\n",
      "batch 4595: loss 0.022301\n",
      "batch 4596: loss 0.035536\n",
      "batch 4597: loss 0.066316\n",
      "batch 4598: loss 0.100519\n",
      "batch 4599: loss 0.079009\n",
      "batch 4600: loss 0.015248\n",
      "batch 4601: loss 0.034486\n",
      "batch 4602: loss 0.060614\n",
      "batch 4603: loss 0.013693\n",
      "batch 4604: loss 0.094310\n",
      "batch 4605: loss 0.074164\n",
      "batch 4606: loss 0.063576\n",
      "batch 4607: loss 0.023429\n",
      "batch 4608: loss 0.058549\n",
      "batch 4609: loss 0.024535\n",
      "batch 4610: loss 0.067186\n",
      "batch 4611: loss 0.071064\n",
      "batch 4612: loss 0.125712\n",
      "batch 4613: loss 0.051998\n",
      "batch 4614: loss 0.063537\n",
      "batch 4615: loss 0.019414\n",
      "batch 4616: loss 0.077843\n",
      "batch 4617: loss 0.056520\n",
      "batch 4618: loss 0.159119\n",
      "batch 4619: loss 0.089397\n",
      "batch 4620: loss 0.069200\n",
      "batch 4621: loss 0.089968\n",
      "batch 4622: loss 0.072668\n",
      "batch 4623: loss 0.028493\n",
      "batch 4624: loss 0.116866\n",
      "batch 4625: loss 0.048904\n",
      "batch 4626: loss 0.016121\n",
      "batch 4627: loss 0.038684\n",
      "batch 4628: loss 0.034894\n",
      "batch 4629: loss 0.032726\n",
      "batch 4630: loss 0.036001\n",
      "batch 4631: loss 0.021482\n",
      "batch 4632: loss 0.017154\n",
      "batch 4633: loss 0.027088\n",
      "batch 4634: loss 0.038200\n",
      "batch 4635: loss 0.090639\n",
      "batch 4636: loss 0.030942\n",
      "batch 4637: loss 0.037236\n",
      "batch 4638: loss 0.054545\n",
      "batch 4639: loss 0.010790\n",
      "batch 4640: loss 0.119733\n",
      "batch 4641: loss 0.079814\n",
      "batch 4642: loss 0.022485\n",
      "batch 4643: loss 0.040018\n",
      "batch 4644: loss 0.061105\n",
      "batch 4645: loss 0.118282\n",
      "batch 4646: loss 0.003984\n",
      "batch 4647: loss 0.160141\n",
      "batch 4648: loss 0.090841\n",
      "batch 4649: loss 0.022224\n",
      "batch 4650: loss 0.056731\n",
      "batch 4651: loss 0.027337\n",
      "batch 4652: loss 0.036284\n",
      "batch 4653: loss 0.035420\n",
      "batch 4654: loss 0.046688\n",
      "batch 4655: loss 0.161384\n",
      "batch 4656: loss 0.023661\n",
      "batch 4657: loss 0.046104\n",
      "batch 4658: loss 0.058851\n",
      "batch 4659: loss 0.070842\n",
      "batch 4660: loss 0.028980\n",
      "batch 4661: loss 0.161072\n",
      "batch 4662: loss 0.090656\n",
      "batch 4663: loss 0.034234\n",
      "batch 4664: loss 0.105242\n",
      "batch 4665: loss 0.051517\n",
      "batch 4666: loss 0.064915\n",
      "batch 4667: loss 0.159529\n",
      "batch 4668: loss 0.091324\n",
      "batch 4669: loss 0.090915\n",
      "batch 4670: loss 0.092774\n",
      "batch 4671: loss 0.053728\n",
      "batch 4672: loss 0.038728\n",
      "batch 4673: loss 0.028557\n",
      "batch 4674: loss 0.018667\n",
      "batch 4675: loss 0.036982\n",
      "batch 4676: loss 0.012777\n",
      "batch 4677: loss 0.067394\n",
      "batch 4678: loss 0.046422\n",
      "batch 4679: loss 0.092244\n",
      "batch 4680: loss 0.008497\n",
      "batch 4681: loss 0.096982\n",
      "batch 4682: loss 0.045283\n",
      "batch 4683: loss 0.068662\n",
      "batch 4684: loss 0.060442\n",
      "batch 4685: loss 0.035885\n",
      "batch 4686: loss 0.116264\n",
      "batch 4687: loss 0.024220\n",
      "batch 4688: loss 0.015337\n",
      "batch 4689: loss 0.245353\n",
      "batch 4690: loss 0.036613\n",
      "batch 4691: loss 0.116505\n",
      "batch 4692: loss 0.091865\n",
      "batch 4693: loss 0.015457\n",
      "batch 4694: loss 0.029648\n",
      "batch 4695: loss 0.043049\n",
      "batch 4696: loss 0.010632\n",
      "batch 4697: loss 0.090173\n",
      "batch 4698: loss 0.068868\n",
      "batch 4699: loss 0.048320\n",
      "batch 4700: loss 0.073198\n",
      "batch 4701: loss 0.154246\n",
      "batch 4702: loss 0.041349\n",
      "batch 4703: loss 0.043106\n",
      "batch 4704: loss 0.103262\n",
      "batch 4705: loss 0.093601\n",
      "batch 4706: loss 0.017124\n",
      "batch 4707: loss 0.089946\n",
      "batch 4708: loss 0.028178\n",
      "batch 4709: loss 0.089727\n",
      "batch 4710: loss 0.031484\n",
      "batch 4711: loss 0.105376\n",
      "batch 4712: loss 0.079365\n",
      "batch 4713: loss 0.005268\n",
      "batch 4714: loss 0.062344\n",
      "batch 4715: loss 0.004243\n",
      "batch 4716: loss 0.075341\n",
      "batch 4717: loss 0.111108\n",
      "batch 4718: loss 0.075560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4719: loss 0.071734\n",
      "batch 4720: loss 0.068976\n",
      "batch 4721: loss 0.022084\n",
      "batch 4722: loss 0.058616\n",
      "batch 4723: loss 0.030503\n",
      "batch 4724: loss 0.013907\n",
      "batch 4725: loss 0.057147\n",
      "batch 4726: loss 0.065345\n",
      "batch 4727: loss 0.035268\n",
      "batch 4728: loss 0.058688\n",
      "batch 4729: loss 0.084060\n",
      "batch 4730: loss 0.062663\n",
      "batch 4731: loss 0.041848\n",
      "batch 4732: loss 0.034755\n",
      "batch 4733: loss 0.138174\n",
      "batch 4734: loss 0.072428\n",
      "batch 4735: loss 0.125636\n",
      "batch 4736: loss 0.021028\n",
      "batch 4737: loss 0.098666\n",
      "batch 4738: loss 0.050486\n",
      "batch 4739: loss 0.041377\n",
      "batch 4740: loss 0.019627\n",
      "batch 4741: loss 0.089092\n",
      "batch 4742: loss 0.017630\n",
      "batch 4743: loss 0.209464\n",
      "batch 4744: loss 0.002932\n",
      "batch 4745: loss 0.030447\n",
      "batch 4746: loss 0.036443\n",
      "batch 4747: loss 0.028712\n",
      "batch 4748: loss 0.134750\n",
      "batch 4749: loss 0.021205\n",
      "batch 4750: loss 0.012298\n",
      "batch 4751: loss 0.066959\n",
      "batch 4752: loss 0.006932\n",
      "batch 4753: loss 0.031335\n",
      "batch 4754: loss 0.053612\n",
      "batch 4755: loss 0.134308\n",
      "batch 4756: loss 0.077991\n",
      "batch 4757: loss 0.016343\n",
      "batch 4758: loss 0.012734\n",
      "batch 4759: loss 0.020779\n",
      "batch 4760: loss 0.081033\n",
      "batch 4761: loss 0.090648\n",
      "batch 4762: loss 0.028361\n",
      "batch 4763: loss 0.019791\n",
      "batch 4764: loss 0.015322\n",
      "batch 4765: loss 0.130523\n",
      "batch 4766: loss 0.160287\n",
      "batch 4767: loss 0.142941\n",
      "batch 4768: loss 0.020625\n",
      "batch 4769: loss 0.023114\n",
      "batch 4770: loss 0.034597\n",
      "batch 4771: loss 0.083809\n",
      "batch 4772: loss 0.061018\n",
      "batch 4773: loss 0.044689\n",
      "batch 4774: loss 0.026898\n",
      "batch 4775: loss 0.030392\n",
      "batch 4776: loss 0.055037\n",
      "batch 4777: loss 0.050527\n",
      "batch 4778: loss 0.054439\n",
      "batch 4779: loss 0.165944\n",
      "batch 4780: loss 0.121318\n",
      "batch 4781: loss 0.026897\n",
      "batch 4782: loss 0.058489\n",
      "batch 4783: loss 0.066671\n",
      "batch 4784: loss 0.045338\n",
      "batch 4785: loss 0.124217\n",
      "batch 4786: loss 0.159183\n",
      "batch 4787: loss 0.135901\n",
      "batch 4788: loss 0.021859\n",
      "batch 4789: loss 0.025447\n",
      "batch 4790: loss 0.133203\n",
      "batch 4791: loss 0.009012\n",
      "batch 4792: loss 0.036143\n",
      "batch 4793: loss 0.036920\n",
      "batch 4794: loss 0.023112\n",
      "batch 4795: loss 0.019635\n",
      "batch 4796: loss 0.046495\n",
      "batch 4797: loss 0.056087\n",
      "batch 4798: loss 0.024936\n",
      "batch 4799: loss 0.064278\n",
      "batch 4800: loss 0.063790\n",
      "batch 4801: loss 0.045500\n",
      "batch 4802: loss 0.106859\n",
      "batch 4803: loss 0.019179\n",
      "batch 4804: loss 0.118529\n",
      "batch 4805: loss 0.085846\n",
      "batch 4806: loss 0.013084\n",
      "batch 4807: loss 0.109787\n",
      "batch 4808: loss 0.110735\n",
      "batch 4809: loss 0.019464\n",
      "batch 4810: loss 0.021260\n",
      "batch 4811: loss 0.018966\n",
      "batch 4812: loss 0.102255\n",
      "batch 4813: loss 0.228206\n",
      "batch 4814: loss 0.036997\n",
      "batch 4815: loss 0.097301\n",
      "batch 4816: loss 0.089221\n",
      "batch 4817: loss 0.020931\n",
      "batch 4818: loss 0.020553\n",
      "batch 4819: loss 0.043094\n",
      "batch 4820: loss 0.043649\n",
      "batch 4821: loss 0.088117\n",
      "batch 4822: loss 0.176709\n",
      "batch 4823: loss 0.178684\n",
      "batch 4824: loss 0.030946\n",
      "batch 4825: loss 0.020648\n",
      "batch 4826: loss 0.162864\n",
      "batch 4827: loss 0.013835\n",
      "batch 4828: loss 0.020230\n",
      "batch 4829: loss 0.060406\n",
      "batch 4830: loss 0.091139\n",
      "batch 4831: loss 0.043018\n",
      "batch 4832: loss 0.020727\n",
      "batch 4833: loss 0.125937\n",
      "batch 4834: loss 0.026963\n",
      "batch 4835: loss 0.204989\n",
      "batch 4836: loss 0.011878\n",
      "batch 4837: loss 0.030321\n",
      "batch 4838: loss 0.037613\n",
      "batch 4839: loss 0.096714\n",
      "batch 4840: loss 0.018151\n",
      "batch 4841: loss 0.154432\n",
      "batch 4842: loss 0.033041\n",
      "batch 4843: loss 0.048224\n",
      "batch 4844: loss 0.019829\n",
      "batch 4845: loss 0.082247\n",
      "batch 4846: loss 0.077769\n",
      "batch 4847: loss 0.042420\n",
      "batch 4848: loss 0.031851\n",
      "batch 4849: loss 0.025027\n",
      "batch 4850: loss 0.051942\n",
      "batch 4851: loss 0.109728\n",
      "batch 4852: loss 0.032268\n",
      "batch 4853: loss 0.035286\n",
      "batch 4854: loss 0.065373\n",
      "batch 4855: loss 0.051452\n",
      "batch 4856: loss 0.033705\n",
      "batch 4857: loss 0.027804\n",
      "batch 4858: loss 0.010773\n",
      "batch 4859: loss 0.043681\n",
      "batch 4860: loss 0.080020\n",
      "batch 4861: loss 0.052978\n",
      "batch 4862: loss 0.025135\n",
      "batch 4863: loss 0.065221\n",
      "batch 4864: loss 0.015710\n",
      "batch 4865: loss 0.012095\n",
      "batch 4866: loss 0.004600\n",
      "batch 4867: loss 0.034443\n",
      "batch 4868: loss 0.029682\n",
      "batch 4869: loss 0.066519\n",
      "batch 4870: loss 0.070614\n",
      "batch 4871: loss 0.069823\n",
      "batch 4872: loss 0.148216\n",
      "batch 4873: loss 0.032537\n",
      "batch 4874: loss 0.057409\n",
      "batch 4875: loss 0.018003\n",
      "batch 4876: loss 0.075832\n",
      "batch 4877: loss 0.104024\n",
      "batch 4878: loss 0.027313\n",
      "batch 4879: loss 0.022269\n",
      "batch 4880: loss 0.060390\n",
      "batch 4881: loss 0.034089\n",
      "batch 4882: loss 0.051344\n",
      "batch 4883: loss 0.029120\n",
      "batch 4884: loss 0.048419\n",
      "batch 4885: loss 0.013469\n",
      "batch 4886: loss 0.060507\n",
      "batch 4887: loss 0.046013\n",
      "batch 4888: loss 0.160195\n",
      "batch 4889: loss 0.016326\n",
      "batch 4890: loss 0.046288\n",
      "batch 4891: loss 0.069318\n",
      "batch 4892: loss 0.031350\n",
      "batch 4893: loss 0.054040\n",
      "batch 4894: loss 0.022085\n",
      "batch 4895: loss 0.032290\n",
      "batch 4896: loss 0.161649\n",
      "batch 4897: loss 0.113719\n",
      "batch 4898: loss 0.026361\n",
      "batch 4899: loss 0.025810\n",
      "batch 4900: loss 0.069793\n",
      "batch 4901: loss 0.012825\n",
      "batch 4902: loss 0.008309\n",
      "batch 4903: loss 0.012596\n",
      "batch 4904: loss 0.057021\n",
      "batch 4905: loss 0.070350\n",
      "batch 4906: loss 0.043524\n",
      "batch 4907: loss 0.025978\n",
      "batch 4908: loss 0.050025\n",
      "batch 4909: loss 0.179930\n",
      "batch 4910: loss 0.080230\n",
      "batch 4911: loss 0.145894\n",
      "batch 4912: loss 0.028538\n",
      "batch 4913: loss 0.138635\n",
      "batch 4914: loss 0.065111\n",
      "batch 4915: loss 0.090408\n",
      "batch 4916: loss 0.049437\n",
      "batch 4917: loss 0.023329\n",
      "batch 4918: loss 0.024223\n",
      "batch 4919: loss 0.073062\n",
      "batch 4920: loss 0.105141\n",
      "batch 4921: loss 0.078759\n",
      "batch 4922: loss 0.018595\n",
      "batch 4923: loss 0.011698\n",
      "batch 4924: loss 0.013829\n",
      "batch 4925: loss 0.020814\n",
      "batch 4926: loss 0.006441\n",
      "batch 4927: loss 0.103114\n",
      "batch 4928: loss 0.040393\n",
      "batch 4929: loss 0.015879\n",
      "batch 4930: loss 0.027346\n",
      "batch 4931: loss 0.037975\n",
      "batch 4932: loss 0.046239\n",
      "batch 4933: loss 0.017218\n",
      "batch 4934: loss 0.075989\n",
      "batch 4935: loss 0.051945\n",
      "batch 4936: loss 0.073999\n",
      "batch 4937: loss 0.018777\n",
      "batch 4938: loss 0.053514\n",
      "batch 4939: loss 0.058627\n",
      "batch 4940: loss 0.119292\n",
      "batch 4941: loss 0.030160\n",
      "batch 4942: loss 0.015495\n",
      "batch 4943: loss 0.006811\n",
      "batch 4944: loss 0.013873\n",
      "batch 4945: loss 0.158878\n",
      "batch 4946: loss 0.011135\n",
      "batch 4947: loss 0.014686\n",
      "batch 4948: loss 0.126271\n",
      "batch 4949: loss 0.059675\n",
      "batch 4950: loss 0.249322\n",
      "batch 4951: loss 0.013434\n",
      "batch 4952: loss 0.007778\n",
      "batch 4953: loss 0.030758\n",
      "batch 4954: loss 0.025636\n",
      "batch 4955: loss 0.019447\n",
      "batch 4956: loss 0.011850\n",
      "batch 4957: loss 0.013088\n",
      "batch 4958: loss 0.024708\n",
      "batch 4959: loss 0.065931\n",
      "batch 4960: loss 0.054190\n",
      "batch 4961: loss 0.026908\n",
      "batch 4962: loss 0.037885\n",
      "batch 4963: loss 0.030105\n",
      "batch 4964: loss 0.056725\n",
      "batch 4965: loss 0.040564\n",
      "batch 4966: loss 0.052270\n",
      "batch 4967: loss 0.143783\n",
      "batch 4968: loss 0.006815\n",
      "batch 4969: loss 0.054192\n",
      "batch 4970: loss 0.064211\n",
      "batch 4971: loss 0.130825\n",
      "batch 4972: loss 0.022960\n",
      "batch 4973: loss 0.100339\n",
      "batch 4974: loss 0.008919\n",
      "batch 4975: loss 0.040934\n",
      "batch 4976: loss 0.158165\n",
      "batch 4977: loss 0.052869\n",
      "batch 4978: loss 0.029376\n",
      "batch 4979: loss 0.008977\n",
      "batch 4980: loss 0.033476\n",
      "batch 4981: loss 0.026640\n",
      "batch 4982: loss 0.134919\n",
      "batch 4983: loss 0.127666\n",
      "batch 4984: loss 0.083140\n",
      "batch 4985: loss 0.084204\n",
      "batch 4986: loss 0.125507\n",
      "batch 4987: loss 0.031043\n",
      "batch 4988: loss 0.033568\n",
      "batch 4989: loss 0.036659\n",
      "batch 4990: loss 0.035213\n",
      "batch 4991: loss 0.132885\n",
      "batch 4992: loss 0.035927\n",
      "batch 4993: loss 0.078822\n",
      "batch 4994: loss 0.146821\n",
      "batch 4995: loss 0.179799\n",
      "batch 4996: loss 0.040064\n",
      "batch 4997: loss 0.016515\n",
      "batch 4998: loss 0.030350\n",
      "batch 4999: loss 0.011391\n",
      "batch 5000: loss 0.022116\n",
      "batch 5001: loss 0.051958\n",
      "batch 5002: loss 0.073785\n",
      "batch 5003: loss 0.113015\n",
      "batch 5004: loss 0.023299\n",
      "batch 5005: loss 0.033598\n",
      "batch 5006: loss 0.043345\n",
      "batch 5007: loss 0.019099\n",
      "batch 5008: loss 0.133294\n",
      "batch 5009: loss 0.102599\n",
      "batch 5010: loss 0.097648\n",
      "batch 5011: loss 0.020860\n",
      "batch 5012: loss 0.039820\n",
      "batch 5013: loss 0.065754\n",
      "batch 5014: loss 0.159603\n",
      "batch 5015: loss 0.022749\n",
      "batch 5016: loss 0.035186\n",
      "batch 5017: loss 0.042579\n",
      "batch 5018: loss 0.059978\n",
      "batch 5019: loss 0.067880\n",
      "batch 5020: loss 0.031879\n",
      "batch 5021: loss 0.128128\n",
      "batch 5022: loss 0.052811\n",
      "batch 5023: loss 0.014610\n",
      "batch 5024: loss 0.030133\n",
      "batch 5025: loss 0.072549\n",
      "batch 5026: loss 0.037797\n",
      "batch 5027: loss 0.160694\n",
      "batch 5028: loss 0.056779\n",
      "batch 5029: loss 0.034238\n",
      "batch 5030: loss 0.011486\n",
      "batch 5031: loss 0.028783\n",
      "batch 5032: loss 0.090184\n",
      "batch 5033: loss 0.006271\n",
      "batch 5034: loss 0.005647\n",
      "batch 5035: loss 0.049579\n",
      "batch 5036: loss 0.252995\n",
      "batch 5037: loss 0.027316\n",
      "batch 5038: loss 0.018754\n",
      "batch 5039: loss 0.009039\n",
      "batch 5040: loss 0.016142\n",
      "batch 5041: loss 0.033191\n",
      "batch 5042: loss 0.072969\n",
      "batch 5043: loss 0.045843\n",
      "batch 5044: loss 0.076001\n",
      "batch 5045: loss 0.087901\n",
      "batch 5046: loss 0.026243\n",
      "batch 5047: loss 0.031905\n",
      "batch 5048: loss 0.014316\n",
      "batch 5049: loss 0.028279\n",
      "batch 5050: loss 0.022028\n",
      "batch 5051: loss 0.042424\n",
      "batch 5052: loss 0.117116\n",
      "batch 5053: loss 0.052954\n",
      "batch 5054: loss 0.029824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5055: loss 0.044513\n",
      "batch 5056: loss 0.005869\n",
      "batch 5057: loss 0.070658\n",
      "batch 5058: loss 0.068659\n",
      "batch 5059: loss 0.024078\n",
      "batch 5060: loss 0.036382\n",
      "batch 5061: loss 0.097462\n",
      "batch 5062: loss 0.022070\n",
      "batch 5063: loss 0.015613\n",
      "batch 5064: loss 0.048467\n",
      "batch 5065: loss 0.030624\n",
      "batch 5066: loss 0.055006\n",
      "batch 5067: loss 0.063727\n",
      "batch 5068: loss 0.024763\n",
      "batch 5069: loss 0.031105\n",
      "batch 5070: loss 0.011099\n",
      "batch 5071: loss 0.083443\n",
      "batch 5072: loss 0.011884\n",
      "batch 5073: loss 0.011722\n",
      "batch 5074: loss 0.041276\n",
      "batch 5075: loss 0.026198\n",
      "batch 5076: loss 0.015449\n",
      "batch 5077: loss 0.035771\n",
      "batch 5078: loss 0.010049\n",
      "batch 5079: loss 0.078552\n",
      "batch 5080: loss 0.036374\n",
      "batch 5081: loss 0.009637\n",
      "batch 5082: loss 0.022656\n",
      "batch 5083: loss 0.011265\n",
      "batch 5084: loss 0.044628\n",
      "batch 5085: loss 0.050601\n",
      "batch 5086: loss 0.025882\n",
      "batch 5087: loss 0.008636\n",
      "batch 5088: loss 0.020947\n",
      "batch 5089: loss 0.054255\n",
      "batch 5090: loss 0.090393\n",
      "batch 5091: loss 0.025827\n",
      "batch 5092: loss 0.011637\n",
      "batch 5093: loss 0.055618\n",
      "batch 5094: loss 0.131117\n",
      "batch 5095: loss 0.040833\n",
      "batch 5096: loss 0.013753\n",
      "batch 5097: loss 0.006849\n",
      "batch 5098: loss 0.102009\n",
      "batch 5099: loss 0.143277\n",
      "batch 5100: loss 0.093003\n",
      "batch 5101: loss 0.040481\n",
      "batch 5102: loss 0.023665\n",
      "batch 5103: loss 0.065145\n",
      "batch 5104: loss 0.047083\n",
      "batch 5105: loss 0.074808\n",
      "batch 5106: loss 0.022426\n",
      "batch 5107: loss 0.036587\n",
      "batch 5108: loss 0.056745\n",
      "batch 5109: loss 0.023199\n",
      "batch 5110: loss 0.057583\n",
      "batch 5111: loss 0.025441\n",
      "batch 5112: loss 0.038247\n",
      "batch 5113: loss 0.038369\n",
      "batch 5114: loss 0.037375\n",
      "batch 5115: loss 0.007038\n",
      "batch 5116: loss 0.065567\n",
      "batch 5117: loss 0.021522\n",
      "batch 5118: loss 0.162748\n",
      "batch 5119: loss 0.068775\n",
      "batch 5120: loss 0.064810\n",
      "batch 5121: loss 0.070089\n",
      "batch 5122: loss 0.083468\n",
      "batch 5123: loss 0.097262\n",
      "batch 5124: loss 0.064406\n",
      "batch 5125: loss 0.009065\n",
      "batch 5126: loss 0.007524\n",
      "batch 5127: loss 0.010155\n",
      "batch 5128: loss 0.075116\n",
      "batch 5129: loss 0.047149\n",
      "batch 5130: loss 0.114682\n",
      "batch 5131: loss 0.055304\n",
      "batch 5132: loss 0.018319\n",
      "batch 5133: loss 0.066935\n",
      "batch 5134: loss 0.008094\n",
      "batch 5135: loss 0.113516\n",
      "batch 5136: loss 0.074478\n",
      "batch 5137: loss 0.074127\n",
      "batch 5138: loss 0.067688\n",
      "batch 5139: loss 0.164527\n",
      "batch 5140: loss 0.035221\n",
      "batch 5141: loss 0.052866\n",
      "batch 5142: loss 0.094817\n",
      "batch 5143: loss 0.121845\n",
      "batch 5144: loss 0.046202\n",
      "batch 5145: loss 0.076435\n",
      "batch 5146: loss 0.220272\n",
      "batch 5147: loss 0.039636\n",
      "batch 5148: loss 0.016888\n",
      "batch 5149: loss 0.004464\n",
      "batch 5150: loss 0.113495\n",
      "batch 5151: loss 0.026617\n",
      "batch 5152: loss 0.082492\n",
      "batch 5153: loss 0.049969\n",
      "batch 5154: loss 0.018537\n",
      "batch 5155: loss 0.112105\n",
      "batch 5156: loss 0.176385\n",
      "batch 5157: loss 0.028655\n",
      "batch 5158: loss 0.041075\n",
      "batch 5159: loss 0.007798\n",
      "batch 5160: loss 0.013608\n",
      "batch 5161: loss 0.117518\n",
      "batch 5162: loss 0.094896\n",
      "batch 5163: loss 0.045348\n",
      "batch 5164: loss 0.011036\n",
      "batch 5165: loss 0.012108\n",
      "batch 5166: loss 0.085040\n",
      "batch 5167: loss 0.049232\n",
      "batch 5168: loss 0.010382\n",
      "batch 5169: loss 0.032912\n",
      "batch 5170: loss 0.103838\n",
      "batch 5171: loss 0.059606\n",
      "batch 5172: loss 0.027780\n",
      "batch 5173: loss 0.008158\n",
      "batch 5174: loss 0.022807\n",
      "batch 5175: loss 0.016017\n",
      "batch 5176: loss 0.027294\n",
      "batch 5177: loss 0.076276\n",
      "batch 5178: loss 0.014305\n",
      "batch 5179: loss 0.018824\n",
      "batch 5180: loss 0.063913\n",
      "batch 5181: loss 0.029405\n",
      "batch 5182: loss 0.035606\n",
      "batch 5183: loss 0.078344\n",
      "batch 5184: loss 0.048556\n",
      "batch 5185: loss 0.034482\n",
      "batch 5186: loss 0.022544\n",
      "batch 5187: loss 0.036886\n",
      "batch 5188: loss 0.019969\n",
      "batch 5189: loss 0.013054\n",
      "batch 5190: loss 0.045079\n",
      "batch 5191: loss 0.041603\n",
      "batch 5192: loss 0.104453\n",
      "batch 5193: loss 0.151827\n",
      "batch 5194: loss 0.092578\n",
      "batch 5195: loss 0.093590\n",
      "batch 5196: loss 0.186273\n",
      "batch 5197: loss 0.043641\n",
      "batch 5198: loss 0.034286\n",
      "batch 5199: loss 0.008237\n",
      "batch 5200: loss 0.070633\n",
      "batch 5201: loss 0.065809\n",
      "batch 5202: loss 0.087773\n",
      "batch 5203: loss 0.008347\n",
      "batch 5204: loss 0.025689\n",
      "batch 5205: loss 0.103122\n",
      "batch 5206: loss 0.063098\n",
      "batch 5207: loss 0.032033\n",
      "batch 5208: loss 0.123829\n",
      "batch 5209: loss 0.010417\n",
      "batch 5210: loss 0.134662\n",
      "batch 5211: loss 0.063832\n",
      "batch 5212: loss 0.052719\n",
      "batch 5213: loss 0.078740\n",
      "batch 5214: loss 0.043279\n",
      "batch 5215: loss 0.056064\n",
      "batch 5216: loss 0.205132\n",
      "batch 5217: loss 0.113533\n",
      "batch 5218: loss 0.073852\n",
      "batch 5219: loss 0.016837\n",
      "batch 5220: loss 0.007398\n",
      "batch 5221: loss 0.023332\n",
      "batch 5222: loss 0.018456\n",
      "batch 5223: loss 0.038625\n",
      "batch 5224: loss 0.104726\n",
      "batch 5225: loss 0.015690\n",
      "batch 5226: loss 0.029796\n",
      "batch 5227: loss 0.066011\n",
      "batch 5228: loss 0.025488\n",
      "batch 5229: loss 0.116214\n",
      "batch 5230: loss 0.017629\n",
      "batch 5231: loss 0.027797\n",
      "batch 5232: loss 0.015540\n",
      "batch 5233: loss 0.021734\n",
      "batch 5234: loss 0.048356\n",
      "batch 5235: loss 0.057541\n",
      "batch 5236: loss 0.016693\n",
      "batch 5237: loss 0.016326\n",
      "batch 5238: loss 0.189593\n",
      "batch 5239: loss 0.012158\n",
      "batch 5240: loss 0.033850\n",
      "batch 5241: loss 0.032445\n",
      "batch 5242: loss 0.029485\n",
      "batch 5243: loss 0.146199\n",
      "batch 5244: loss 0.012284\n",
      "batch 5245: loss 0.015695\n",
      "batch 5246: loss 0.025192\n",
      "batch 5247: loss 0.036652\n",
      "batch 5248: loss 0.036000\n",
      "batch 5249: loss 0.039122\n",
      "batch 5250: loss 0.033718\n",
      "batch 5251: loss 0.027613\n",
      "batch 5252: loss 0.007980\n",
      "batch 5253: loss 0.024539\n",
      "batch 5254: loss 0.014075\n",
      "batch 5255: loss 0.178155\n",
      "batch 5256: loss 0.040517\n",
      "batch 5257: loss 0.025876\n",
      "batch 5258: loss 0.038138\n",
      "batch 5259: loss 0.038839\n",
      "batch 5260: loss 0.198077\n",
      "batch 5261: loss 0.100652\n",
      "batch 5262: loss 0.023146\n",
      "batch 5263: loss 0.027147\n",
      "batch 5264: loss 0.184806\n",
      "batch 5265: loss 0.080525\n",
      "batch 5266: loss 0.066550\n",
      "batch 5267: loss 0.029093\n",
      "batch 5268: loss 0.056337\n",
      "batch 5269: loss 0.007638\n",
      "batch 5270: loss 0.014537\n",
      "batch 5271: loss 0.066276\n",
      "batch 5272: loss 0.081971\n",
      "batch 5273: loss 0.033477\n",
      "batch 5274: loss 0.008650\n",
      "batch 5275: loss 0.042726\n",
      "batch 5276: loss 0.005185\n",
      "batch 5277: loss 0.058222\n",
      "batch 5278: loss 0.095816\n",
      "batch 5279: loss 0.099973\n",
      "batch 5280: loss 0.020184\n",
      "batch 5281: loss 0.026858\n",
      "batch 5282: loss 0.025708\n",
      "batch 5283: loss 0.027220\n",
      "batch 5284: loss 0.045290\n",
      "batch 5285: loss 0.074287\n",
      "batch 5286: loss 0.043487\n",
      "batch 5287: loss 0.212738\n",
      "batch 5288: loss 0.023727\n",
      "batch 5289: loss 0.021676\n",
      "batch 5290: loss 0.079064\n",
      "batch 5291: loss 0.015781\n",
      "batch 5292: loss 0.030167\n",
      "batch 5293: loss 0.014909\n",
      "batch 5294: loss 0.019242\n",
      "batch 5295: loss 0.073886\n",
      "batch 5296: loss 0.062504\n",
      "batch 5297: loss 0.025259\n",
      "batch 5298: loss 0.028867\n",
      "batch 5299: loss 0.053232\n",
      "batch 5300: loss 0.028987\n",
      "batch 5301: loss 0.040676\n",
      "batch 5302: loss 0.084575\n",
      "batch 5303: loss 0.100046\n",
      "batch 5304: loss 0.017151\n",
      "batch 5305: loss 0.146399\n",
      "batch 5306: loss 0.022411\n",
      "batch 5307: loss 0.020992\n",
      "batch 5308: loss 0.182906\n",
      "batch 5309: loss 0.080043\n",
      "batch 5310: loss 0.041916\n",
      "batch 5311: loss 0.139815\n",
      "batch 5312: loss 0.042615\n",
      "batch 5313: loss 0.034475\n",
      "batch 5314: loss 0.033197\n",
      "batch 5315: loss 0.158559\n",
      "batch 5316: loss 0.009583\n",
      "batch 5317: loss 0.082475\n",
      "batch 5318: loss 0.032943\n",
      "batch 5319: loss 0.095305\n",
      "batch 5320: loss 0.047772\n",
      "batch 5321: loss 0.024835\n",
      "batch 5322: loss 0.085747\n",
      "batch 5323: loss 0.039131\n",
      "batch 5324: loss 0.039490\n",
      "batch 5325: loss 0.070711\n",
      "batch 5326: loss 0.055789\n",
      "batch 5327: loss 0.030136\n",
      "batch 5328: loss 0.083457\n",
      "batch 5329: loss 0.078812\n",
      "batch 5330: loss 0.014176\n",
      "batch 5331: loss 0.118829\n",
      "batch 5332: loss 0.097524\n",
      "batch 5333: loss 0.012208\n",
      "batch 5334: loss 0.015436\n",
      "batch 5335: loss 0.017948\n",
      "batch 5336: loss 0.051637\n",
      "batch 5337: loss 0.082086\n",
      "batch 5338: loss 0.017657\n",
      "batch 5339: loss 0.124926\n",
      "batch 5340: loss 0.077123\n",
      "batch 5341: loss 0.051700\n",
      "batch 5342: loss 0.119782\n",
      "batch 5343: loss 0.061189\n",
      "batch 5344: loss 0.039961\n",
      "batch 5345: loss 0.055135\n",
      "batch 5346: loss 0.017619\n",
      "batch 5347: loss 0.099588\n",
      "batch 5348: loss 0.016476\n",
      "batch 5349: loss 0.043330\n",
      "batch 5350: loss 0.022712\n",
      "batch 5351: loss 0.025817\n",
      "batch 5352: loss 0.127182\n",
      "batch 5353: loss 0.047969\n",
      "batch 5354: loss 0.106977\n",
      "batch 5355: loss 0.078271\n",
      "batch 5356: loss 0.029011\n",
      "batch 5357: loss 0.037726\n",
      "batch 5358: loss 0.023915\n",
      "batch 5359: loss 0.073299\n",
      "batch 5360: loss 0.017957\n",
      "batch 5361: loss 0.023713\n",
      "batch 5362: loss 0.104311\n",
      "batch 5363: loss 0.020609\n",
      "batch 5364: loss 0.030718\n",
      "batch 5365: loss 0.017337\n",
      "batch 5366: loss 0.049194\n",
      "batch 5367: loss 0.026895\n",
      "batch 5368: loss 0.067116\n",
      "batch 5369: loss 0.035829\n",
      "batch 5370: loss 0.108263\n",
      "batch 5371: loss 0.068157\n",
      "batch 5372: loss 0.113960\n",
      "batch 5373: loss 0.065613\n",
      "batch 5374: loss 0.058914\n",
      "batch 5375: loss 0.010781\n",
      "batch 5376: loss 0.041110\n",
      "batch 5377: loss 0.027517\n",
      "batch 5378: loss 0.015859\n",
      "batch 5379: loss 0.112652\n",
      "batch 5380: loss 0.126934\n",
      "batch 5381: loss 0.016613\n",
      "batch 5382: loss 0.025255\n",
      "batch 5383: loss 0.031579\n",
      "batch 5384: loss 0.017959\n",
      "batch 5385: loss 0.119822\n",
      "batch 5386: loss 0.041503\n",
      "batch 5387: loss 0.084588\n",
      "batch 5388: loss 0.068382\n",
      "batch 5389: loss 0.016566\n",
      "batch 5390: loss 0.017524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5391: loss 0.032586\n",
      "batch 5392: loss 0.061131\n",
      "batch 5393: loss 0.070526\n",
      "batch 5394: loss 0.027915\n",
      "batch 5395: loss 0.015393\n",
      "batch 5396: loss 0.022969\n",
      "batch 5397: loss 0.008124\n",
      "batch 5398: loss 0.017162\n",
      "batch 5399: loss 0.024092\n",
      "batch 5400: loss 0.122628\n",
      "batch 5401: loss 0.013741\n",
      "batch 5402: loss 0.145304\n",
      "batch 5403: loss 0.006706\n",
      "batch 5404: loss 0.061381\n",
      "batch 5405: loss 0.005992\n",
      "batch 5406: loss 0.101179\n",
      "batch 5407: loss 0.030472\n",
      "batch 5408: loss 0.046592\n",
      "batch 5409: loss 0.134839\n",
      "batch 5410: loss 0.059967\n",
      "batch 5411: loss 0.035152\n",
      "batch 5412: loss 0.012176\n",
      "batch 5413: loss 0.021970\n",
      "batch 5414: loss 0.014461\n",
      "batch 5415: loss 0.046102\n",
      "batch 5416: loss 0.106599\n",
      "batch 5417: loss 0.068721\n",
      "batch 5418: loss 0.023385\n",
      "batch 5419: loss 0.048124\n",
      "batch 5420: loss 0.039097\n",
      "batch 5421: loss 0.028251\n",
      "batch 5422: loss 0.052256\n",
      "batch 5423: loss 0.041946\n",
      "batch 5424: loss 0.183886\n",
      "batch 5425: loss 0.078213\n",
      "batch 5426: loss 0.108326\n",
      "batch 5427: loss 0.035426\n",
      "batch 5428: loss 0.018738\n",
      "batch 5429: loss 0.062939\n",
      "batch 5430: loss 0.046671\n",
      "batch 5431: loss 0.012338\n",
      "batch 5432: loss 0.085923\n",
      "batch 5433: loss 0.044112\n",
      "batch 5434: loss 0.030130\n",
      "batch 5435: loss 0.025370\n",
      "batch 5436: loss 0.019668\n",
      "batch 5437: loss 0.053127\n",
      "batch 5438: loss 0.052000\n",
      "batch 5439: loss 0.192879\n",
      "batch 5440: loss 0.047033\n",
      "batch 5441: loss 0.038232\n",
      "batch 5442: loss 0.031887\n",
      "batch 5443: loss 0.007804\n",
      "batch 5444: loss 0.079207\n",
      "batch 5445: loss 0.011879\n",
      "batch 5446: loss 0.029069\n",
      "batch 5447: loss 0.018478\n",
      "batch 5448: loss 0.112605\n",
      "batch 5449: loss 0.051517\n",
      "batch 5450: loss 0.035971\n",
      "batch 5451: loss 0.013167\n",
      "batch 5452: loss 0.053466\n",
      "batch 5453: loss 0.047172\n",
      "batch 5454: loss 0.110018\n",
      "batch 5455: loss 0.040014\n",
      "batch 5456: loss 0.050910\n",
      "batch 5457: loss 0.296641\n",
      "batch 5458: loss 0.017455\n",
      "batch 5459: loss 0.024538\n",
      "batch 5460: loss 0.017178\n",
      "batch 5461: loss 0.065282\n",
      "batch 5462: loss 0.007204\n",
      "batch 5463: loss 0.002908\n",
      "batch 5464: loss 0.151277\n",
      "batch 5465: loss 0.005226\n",
      "batch 5466: loss 0.067611\n",
      "batch 5467: loss 0.039481\n",
      "batch 5468: loss 0.021929\n",
      "batch 5469: loss 0.040294\n",
      "batch 5470: loss 0.016179\n",
      "batch 5471: loss 0.085010\n",
      "batch 5472: loss 0.011557\n",
      "batch 5473: loss 0.010888\n",
      "batch 5474: loss 0.021693\n",
      "batch 5475: loss 0.048756\n",
      "batch 5476: loss 0.071022\n",
      "batch 5477: loss 0.083747\n",
      "batch 5478: loss 0.066141\n",
      "batch 5479: loss 0.049152\n",
      "batch 5480: loss 0.120972\n",
      "batch 5481: loss 0.102145\n",
      "batch 5482: loss 0.040741\n",
      "batch 5483: loss 0.026619\n",
      "batch 5484: loss 0.078852\n",
      "batch 5485: loss 0.085591\n",
      "batch 5486: loss 0.086197\n",
      "batch 5487: loss 0.013662\n",
      "batch 5488: loss 0.214788\n",
      "batch 5489: loss 0.022113\n",
      "batch 5490: loss 0.031198\n",
      "batch 5491: loss 0.019033\n",
      "batch 5492: loss 0.044907\n",
      "batch 5493: loss 0.021554\n",
      "batch 5494: loss 0.165033\n",
      "batch 5495: loss 0.024901\n",
      "batch 5496: loss 0.011225\n",
      "batch 5497: loss 0.135349\n",
      "batch 5498: loss 0.020644\n",
      "batch 5499: loss 0.022574\n",
      "batch 5500: loss 0.079059\n",
      "batch 5501: loss 0.036549\n",
      "batch 5502: loss 0.147175\n",
      "batch 5503: loss 0.064764\n",
      "batch 5504: loss 0.036607\n",
      "batch 5505: loss 0.029482\n",
      "batch 5506: loss 0.101660\n",
      "batch 5507: loss 0.080097\n",
      "batch 5508: loss 0.028190\n",
      "batch 5509: loss 0.052676\n",
      "batch 5510: loss 0.054118\n",
      "batch 5511: loss 0.032537\n",
      "batch 5512: loss 0.133906\n",
      "batch 5513: loss 0.032496\n",
      "batch 5514: loss 0.008950\n",
      "batch 5515: loss 0.080436\n",
      "batch 5516: loss 0.065908\n",
      "batch 5517: loss 0.012736\n",
      "batch 5518: loss 0.005065\n",
      "batch 5519: loss 0.047640\n",
      "batch 5520: loss 0.021477\n",
      "batch 5521: loss 0.141385\n",
      "batch 5522: loss 0.071911\n",
      "batch 5523: loss 0.118857\n",
      "batch 5524: loss 0.013726\n",
      "batch 5525: loss 0.231975\n",
      "batch 5526: loss 0.026817\n",
      "batch 5527: loss 0.008350\n",
      "batch 5528: loss 0.037037\n",
      "batch 5529: loss 0.016645\n",
      "batch 5530: loss 0.039947\n",
      "batch 5531: loss 0.024647\n",
      "batch 5532: loss 0.104862\n",
      "batch 5533: loss 0.019158\n",
      "batch 5534: loss 0.084578\n",
      "batch 5535: loss 0.042355\n",
      "batch 5536: loss 0.030884\n",
      "batch 5537: loss 0.090518\n",
      "batch 5538: loss 0.049708\n",
      "batch 5539: loss 0.040033\n",
      "batch 5540: loss 0.048562\n",
      "batch 5541: loss 0.012449\n",
      "batch 5542: loss 0.032040\n",
      "batch 5543: loss 0.017586\n",
      "batch 5544: loss 0.023338\n",
      "batch 5545: loss 0.011729\n",
      "batch 5546: loss 0.003814\n",
      "batch 5547: loss 0.007562\n",
      "batch 5548: loss 0.013563\n",
      "batch 5549: loss 0.041884\n",
      "batch 5550: loss 0.057038\n",
      "batch 5551: loss 0.022938\n",
      "batch 5552: loss 0.232464\n",
      "batch 5553: loss 0.031612\n",
      "batch 5554: loss 0.137446\n",
      "batch 5555: loss 0.023181\n",
      "batch 5556: loss 0.013379\n",
      "batch 5557: loss 0.026904\n",
      "batch 5558: loss 0.129027\n",
      "batch 5559: loss 0.019874\n",
      "batch 5560: loss 0.078740\n",
      "batch 5561: loss 0.003272\n",
      "batch 5562: loss 0.106661\n",
      "batch 5563: loss 0.031416\n",
      "batch 5564: loss 0.101739\n",
      "batch 5565: loss 0.011736\n",
      "batch 5566: loss 0.097710\n",
      "batch 5567: loss 0.024010\n",
      "batch 5568: loss 0.046898\n",
      "batch 5569: loss 0.042424\n",
      "batch 5570: loss 0.202972\n",
      "batch 5571: loss 0.023894\n",
      "batch 5572: loss 0.037404\n",
      "batch 5573: loss 0.060303\n",
      "batch 5574: loss 0.019493\n",
      "batch 5575: loss 0.007727\n",
      "batch 5576: loss 0.036053\n",
      "batch 5577: loss 0.074902\n",
      "batch 5578: loss 0.021378\n",
      "batch 5579: loss 0.026807\n",
      "batch 5580: loss 0.086873\n",
      "batch 5581: loss 0.017334\n",
      "batch 5582: loss 0.058954\n",
      "batch 5583: loss 0.040756\n",
      "batch 5584: loss 0.083067\n",
      "batch 5585: loss 0.032929\n",
      "batch 5586: loss 0.018806\n",
      "batch 5587: loss 0.045888\n",
      "batch 5588: loss 0.003911\n",
      "batch 5589: loss 0.030636\n",
      "batch 5590: loss 0.055325\n",
      "batch 5591: loss 0.028887\n",
      "batch 5592: loss 0.101885\n",
      "batch 5593: loss 0.195031\n",
      "batch 5594: loss 0.037672\n",
      "batch 5595: loss 0.047591\n",
      "batch 5596: loss 0.140918\n",
      "batch 5597: loss 0.063633\n",
      "batch 5598: loss 0.014120\n",
      "batch 5599: loss 0.009498\n",
      "batch 5600: loss 0.193614\n",
      "batch 5601: loss 0.106208\n",
      "batch 5602: loss 0.125768\n",
      "batch 5603: loss 0.080993\n",
      "batch 5604: loss 0.024500\n",
      "batch 5605: loss 0.097981\n",
      "batch 5606: loss 0.017792\n",
      "batch 5607: loss 0.055345\n",
      "batch 5608: loss 0.006499\n",
      "batch 5609: loss 0.014096\n",
      "batch 5610: loss 0.089845\n",
      "batch 5611: loss 0.045943\n",
      "batch 5612: loss 0.043328\n",
      "batch 5613: loss 0.015117\n",
      "batch 5614: loss 0.017503\n",
      "batch 5615: loss 0.065083\n",
      "batch 5616: loss 0.011811\n",
      "batch 5617: loss 0.039586\n",
      "batch 5618: loss 0.118403\n",
      "batch 5619: loss 0.010612\n",
      "batch 5620: loss 0.017329\n",
      "batch 5621: loss 0.029448\n",
      "batch 5622: loss 0.129170\n",
      "batch 5623: loss 0.077454\n",
      "batch 5624: loss 0.101638\n",
      "batch 5625: loss 0.019792\n",
      "batch 5626: loss 0.034605\n",
      "batch 5627: loss 0.024496\n",
      "batch 5628: loss 0.151218\n",
      "batch 5629: loss 0.058006\n",
      "batch 5630: loss 0.055463\n",
      "batch 5631: loss 0.037372\n",
      "batch 5632: loss 0.020269\n",
      "batch 5633: loss 0.022849\n",
      "batch 5634: loss 0.063762\n",
      "batch 5635: loss 0.032604\n",
      "batch 5636: loss 0.028075\n",
      "batch 5637: loss 0.092006\n",
      "batch 5638: loss 0.009902\n",
      "batch 5639: loss 0.056572\n",
      "batch 5640: loss 0.021943\n",
      "batch 5641: loss 0.140127\n",
      "batch 5642: loss 0.026559\n",
      "batch 5643: loss 0.008215\n",
      "batch 5644: loss 0.008375\n",
      "batch 5645: loss 0.027581\n",
      "batch 5646: loss 0.015480\n",
      "batch 5647: loss 0.011964\n",
      "batch 5648: loss 0.059548\n",
      "batch 5649: loss 0.013413\n",
      "batch 5650: loss 0.013071\n",
      "batch 5651: loss 0.054191\n",
      "batch 5652: loss 0.157734\n",
      "batch 5653: loss 0.038230\n",
      "batch 5654: loss 0.030827\n",
      "batch 5655: loss 0.064524\n",
      "batch 5656: loss 0.032636\n",
      "batch 5657: loss 0.084949\n",
      "batch 5658: loss 0.031110\n",
      "batch 5659: loss 0.021130\n",
      "batch 5660: loss 0.008712\n",
      "batch 5661: loss 0.007494\n",
      "batch 5662: loss 0.055294\n",
      "batch 5663: loss 0.034188\n",
      "batch 5664: loss 0.012498\n",
      "batch 5665: loss 0.020547\n",
      "batch 5666: loss 0.060537\n",
      "batch 5667: loss 0.038965\n",
      "batch 5668: loss 0.011876\n",
      "batch 5669: loss 0.081798\n",
      "batch 5670: loss 0.019511\n",
      "batch 5671: loss 0.101802\n",
      "batch 5672: loss 0.043067\n",
      "batch 5673: loss 0.026563\n",
      "batch 5674: loss 0.025800\n",
      "batch 5675: loss 0.116308\n",
      "batch 5676: loss 0.076181\n",
      "batch 5677: loss 0.017368\n",
      "batch 5678: loss 0.048361\n",
      "batch 5679: loss 0.088517\n",
      "batch 5680: loss 0.244111\n",
      "batch 5681: loss 0.092290\n",
      "batch 5682: loss 0.011604\n",
      "batch 5683: loss 0.055212\n",
      "batch 5684: loss 0.094290\n",
      "batch 5685: loss 0.026358\n",
      "batch 5686: loss 0.024188\n",
      "batch 5687: loss 0.015848\n",
      "batch 5688: loss 0.093273\n",
      "batch 5689: loss 0.012602\n",
      "batch 5690: loss 0.024538\n",
      "batch 5691: loss 0.090589\n",
      "batch 5692: loss 0.053404\n",
      "batch 5693: loss 0.018089\n",
      "batch 5694: loss 0.027007\n",
      "batch 5695: loss 0.054261\n",
      "batch 5696: loss 0.086995\n",
      "batch 5697: loss 0.078046\n",
      "batch 5698: loss 0.064646\n",
      "batch 5699: loss 0.056121\n",
      "batch 5700: loss 0.043405\n",
      "batch 5701: loss 0.012585\n",
      "batch 5702: loss 0.012750\n",
      "batch 5703: loss 0.143850\n",
      "batch 5704: loss 0.097243\n",
      "batch 5705: loss 0.168191\n",
      "batch 5706: loss 0.030981\n",
      "batch 5707: loss 0.140273\n",
      "batch 5708: loss 0.138802\n",
      "batch 5709: loss 0.017388\n",
      "batch 5710: loss 0.071706\n",
      "batch 5711: loss 0.049574\n",
      "batch 5712: loss 0.009205\n",
      "batch 5713: loss 0.029728\n",
      "batch 5714: loss 0.015309\n",
      "batch 5715: loss 0.015877\n",
      "batch 5716: loss 0.035216\n",
      "batch 5717: loss 0.005705\n",
      "batch 5718: loss 0.130686\n",
      "batch 5719: loss 0.017278\n",
      "batch 5720: loss 0.010584\n",
      "batch 5721: loss 0.019085\n",
      "batch 5722: loss 0.103581\n",
      "batch 5723: loss 0.113741\n",
      "batch 5724: loss 0.007473\n",
      "batch 5725: loss 0.071487\n",
      "batch 5726: loss 0.028802\n",
      "batch 5727: loss 0.004570\n",
      "batch 5728: loss 0.027949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5729: loss 0.079636\n",
      "batch 5730: loss 0.087026\n",
      "batch 5731: loss 0.032402\n",
      "batch 5732: loss 0.025816\n",
      "batch 5733: loss 0.011451\n",
      "batch 5734: loss 0.032417\n",
      "batch 5735: loss 0.084475\n",
      "batch 5736: loss 0.013100\n",
      "batch 5737: loss 0.006147\n",
      "batch 5738: loss 0.011537\n",
      "batch 5739: loss 0.038000\n",
      "batch 5740: loss 0.005562\n",
      "batch 5741: loss 0.018352\n",
      "batch 5742: loss 0.121740\n",
      "batch 5743: loss 0.015971\n",
      "batch 5744: loss 0.031160\n",
      "batch 5745: loss 0.060675\n",
      "batch 5746: loss 0.011252\n",
      "batch 5747: loss 0.037928\n",
      "batch 5748: loss 0.005231\n",
      "batch 5749: loss 0.014073\n",
      "batch 5750: loss 0.012757\n",
      "batch 5751: loss 0.289059\n",
      "batch 5752: loss 0.046656\n",
      "batch 5753: loss 0.060204\n",
      "batch 5754: loss 0.014990\n",
      "batch 5755: loss 0.029703\n",
      "batch 5756: loss 0.015125\n",
      "batch 5757: loss 0.022769\n",
      "batch 5758: loss 0.018195\n",
      "batch 5759: loss 0.024059\n",
      "batch 5760: loss 0.036038\n",
      "batch 5761: loss 0.019679\n",
      "batch 5762: loss 0.058995\n",
      "batch 5763: loss 0.028026\n",
      "batch 5764: loss 0.084823\n",
      "batch 5765: loss 0.019581\n",
      "batch 5766: loss 0.055665\n",
      "batch 5767: loss 0.020169\n",
      "batch 5768: loss 0.033644\n",
      "batch 5769: loss 0.036358\n",
      "batch 5770: loss 0.012533\n",
      "batch 5771: loss 0.074036\n",
      "batch 5772: loss 0.035185\n",
      "batch 5773: loss 0.032206\n",
      "batch 5774: loss 0.024502\n",
      "batch 5775: loss 0.035143\n",
      "batch 5776: loss 0.032589\n",
      "batch 5777: loss 0.013091\n",
      "batch 5778: loss 0.148261\n",
      "batch 5779: loss 0.072594\n",
      "batch 5780: loss 0.045276\n",
      "batch 5781: loss 0.018702\n",
      "batch 5782: loss 0.065069\n",
      "batch 5783: loss 0.034232\n",
      "batch 5784: loss 0.162847\n",
      "batch 5785: loss 0.119412\n",
      "batch 5786: loss 0.062895\n",
      "batch 5787: loss 0.034949\n",
      "batch 5788: loss 0.024119\n",
      "batch 5789: loss 0.010194\n",
      "batch 5790: loss 0.024435\n",
      "batch 5791: loss 0.021467\n",
      "batch 5792: loss 0.059076\n",
      "batch 5793: loss 0.018641\n",
      "batch 5794: loss 0.050580\n",
      "batch 5795: loss 0.074096\n",
      "batch 5796: loss 0.020701\n",
      "batch 5797: loss 0.141929\n",
      "batch 5798: loss 0.033220\n",
      "batch 5799: loss 0.010834\n",
      "batch 5800: loss 0.209630\n",
      "batch 5801: loss 0.023164\n",
      "batch 5802: loss 0.035845\n",
      "batch 5803: loss 0.075739\n",
      "batch 5804: loss 0.021487\n",
      "batch 5805: loss 0.032520\n",
      "batch 5806: loss 0.013722\n",
      "batch 5807: loss 0.056927\n",
      "batch 5808: loss 0.059719\n",
      "batch 5809: loss 0.007113\n",
      "batch 5810: loss 0.004045\n",
      "batch 5811: loss 0.025124\n",
      "batch 5812: loss 0.052222\n",
      "batch 5813: loss 0.023470\n",
      "batch 5814: loss 0.036064\n",
      "batch 5815: loss 0.014541\n",
      "batch 5816: loss 0.025695\n",
      "batch 5817: loss 0.012690\n",
      "batch 5818: loss 0.018542\n",
      "batch 5819: loss 0.006071\n",
      "batch 5820: loss 0.022806\n",
      "batch 5821: loss 0.106304\n",
      "batch 5822: loss 0.015361\n",
      "batch 5823: loss 0.010243\n",
      "batch 5824: loss 0.012835\n",
      "batch 5825: loss 0.076913\n",
      "batch 5826: loss 0.031223\n",
      "batch 5827: loss 0.053640\n",
      "batch 5828: loss 0.037619\n",
      "batch 5829: loss 0.107814\n",
      "batch 5830: loss 0.011303\n",
      "batch 5831: loss 0.025847\n",
      "batch 5832: loss 0.064109\n",
      "batch 5833: loss 0.033963\n",
      "batch 5834: loss 0.056591\n",
      "batch 5835: loss 0.036659\n",
      "batch 5836: loss 0.088498\n",
      "batch 5837: loss 0.052133\n",
      "batch 5838: loss 0.034132\n",
      "batch 5839: loss 0.128838\n",
      "batch 5840: loss 0.077815\n",
      "batch 5841: loss 0.106485\n",
      "batch 5842: loss 0.063908\n",
      "batch 5843: loss 0.025634\n",
      "batch 5844: loss 0.034321\n",
      "batch 5845: loss 0.005033\n",
      "batch 5846: loss 0.052033\n",
      "batch 5847: loss 0.071482\n",
      "batch 5848: loss 0.050428\n",
      "batch 5849: loss 0.020706\n",
      "batch 5850: loss 0.044440\n",
      "batch 5851: loss 0.036949\n",
      "batch 5852: loss 0.044268\n",
      "batch 5853: loss 0.010696\n",
      "batch 5854: loss 0.048046\n",
      "batch 5855: loss 0.034523\n",
      "batch 5856: loss 0.026351\n",
      "batch 5857: loss 0.094945\n",
      "batch 5858: loss 0.008204\n",
      "batch 5859: loss 0.070051\n",
      "batch 5860: loss 0.014365\n",
      "batch 5861: loss 0.046505\n",
      "batch 5862: loss 0.069275\n",
      "batch 5863: loss 0.059089\n",
      "batch 5864: loss 0.013798\n",
      "batch 5865: loss 0.005758\n",
      "batch 5866: loss 0.017044\n",
      "batch 5867: loss 0.077778\n",
      "batch 5868: loss 0.024441\n",
      "batch 5869: loss 0.014225\n",
      "batch 5870: loss 0.028667\n",
      "batch 5871: loss 0.022552\n",
      "batch 5872: loss 0.027447\n",
      "batch 5873: loss 0.015176\n",
      "batch 5874: loss 0.012201\n",
      "batch 5875: loss 0.049734\n",
      "batch 5876: loss 0.025743\n",
      "batch 5877: loss 0.027744\n",
      "batch 5878: loss 0.009822\n",
      "batch 5879: loss 0.014038\n",
      "batch 5880: loss 0.050452\n",
      "batch 5881: loss 0.089535\n",
      "batch 5882: loss 0.131129\n",
      "batch 5883: loss 0.058428\n",
      "batch 5884: loss 0.016498\n",
      "batch 5885: loss 0.177278\n",
      "batch 5886: loss 0.047912\n",
      "batch 5887: loss 0.022639\n",
      "batch 5888: loss 0.088291\n",
      "batch 5889: loss 0.013290\n",
      "batch 5890: loss 0.084201\n",
      "batch 5891: loss 0.005150\n",
      "batch 5892: loss 0.043937\n",
      "batch 5893: loss 0.094732\n",
      "batch 5894: loss 0.011751\n",
      "batch 5895: loss 0.005018\n",
      "batch 5896: loss 0.014820\n",
      "batch 5897: loss 0.010203\n",
      "batch 5898: loss 0.040026\n",
      "batch 5899: loss 0.188388\n",
      "batch 5900: loss 0.085507\n",
      "batch 5901: loss 0.049188\n",
      "batch 5902: loss 0.204065\n",
      "batch 5903: loss 0.036611\n",
      "batch 5904: loss 0.029538\n",
      "batch 5905: loss 0.018295\n",
      "batch 5906: loss 0.073724\n",
      "batch 5907: loss 0.053388\n",
      "batch 5908: loss 0.137598\n",
      "batch 5909: loss 0.114199\n",
      "batch 5910: loss 0.078642\n",
      "batch 5911: loss 0.009254\n",
      "batch 5912: loss 0.031252\n",
      "batch 5913: loss 0.145725\n",
      "batch 5914: loss 0.036887\n",
      "batch 5915: loss 0.034848\n",
      "batch 5916: loss 0.077432\n",
      "batch 5917: loss 0.008449\n",
      "batch 5918: loss 0.022463\n",
      "batch 5919: loss 0.015348\n",
      "batch 5920: loss 0.008130\n",
      "batch 5921: loss 0.061104\n",
      "batch 5922: loss 0.054485\n",
      "batch 5923: loss 0.067133\n",
      "batch 5924: loss 0.020066\n",
      "batch 5925: loss 0.053408\n",
      "batch 5926: loss 0.033309\n",
      "batch 5927: loss 0.119251\n",
      "batch 5928: loss 0.027199\n",
      "batch 5929: loss 0.113349\n",
      "batch 5930: loss 0.012950\n",
      "batch 5931: loss 0.152535\n",
      "batch 5932: loss 0.038186\n",
      "batch 5933: loss 0.050040\n",
      "batch 5934: loss 0.030335\n",
      "batch 5935: loss 0.036191\n",
      "batch 5936: loss 0.031848\n",
      "batch 5937: loss 0.270172\n",
      "batch 5938: loss 0.109541\n",
      "batch 5939: loss 0.156765\n",
      "batch 5940: loss 0.023714\n",
      "batch 5941: loss 0.088466\n",
      "batch 5942: loss 0.010854\n",
      "batch 5943: loss 0.099130\n",
      "batch 5944: loss 0.064425\n",
      "batch 5945: loss 0.008741\n",
      "batch 5946: loss 0.054131\n",
      "batch 5947: loss 0.022673\n",
      "batch 5948: loss 0.028656\n",
      "batch 5949: loss 0.043569\n",
      "batch 5950: loss 0.058789\n",
      "batch 5951: loss 0.030079\n",
      "batch 5952: loss 0.041434\n",
      "batch 5953: loss 0.064549\n",
      "batch 5954: loss 0.012198\n",
      "batch 5955: loss 0.046694\n",
      "batch 5956: loss 0.023115\n",
      "batch 5957: loss 0.079392\n",
      "batch 5958: loss 0.044306\n",
      "batch 5959: loss 0.023489\n",
      "batch 5960: loss 0.071415\n",
      "batch 5961: loss 0.064876\n",
      "batch 5962: loss 0.100115\n",
      "batch 5963: loss 0.137266\n",
      "batch 5964: loss 0.020808\n",
      "batch 5965: loss 0.038457\n",
      "batch 5966: loss 0.023573\n",
      "batch 5967: loss 0.009835\n",
      "batch 5968: loss 0.010891\n",
      "batch 5969: loss 0.127312\n",
      "batch 5970: loss 0.055792\n",
      "batch 5971: loss 0.297364\n",
      "batch 5972: loss 0.007509\n",
      "batch 5973: loss 0.029306\n",
      "batch 5974: loss 0.018194\n",
      "batch 5975: loss 0.096358\n",
      "batch 5976: loss 0.071746\n",
      "batch 5977: loss 0.058357\n",
      "batch 5978: loss 0.014847\n",
      "batch 5979: loss 0.134511\n",
      "batch 5980: loss 0.018535\n",
      "batch 5981: loss 0.131660\n",
      "batch 5982: loss 0.092739\n",
      "batch 5983: loss 0.016244\n",
      "batch 5984: loss 0.111254\n",
      "batch 5985: loss 0.036629\n",
      "batch 5986: loss 0.002523\n",
      "batch 5987: loss 0.018045\n",
      "batch 5988: loss 0.173731\n",
      "batch 5989: loss 0.123576\n",
      "batch 5990: loss 0.128780\n",
      "batch 5991: loss 0.036926\n",
      "batch 5992: loss 0.027810\n",
      "batch 5993: loss 0.088625\n",
      "batch 5994: loss 0.042322\n",
      "batch 5995: loss 0.013444\n",
      "batch 5996: loss 0.020967\n",
      "batch 5997: loss 0.265841\n",
      "batch 5998: loss 0.025262\n",
      "batch 5999: loss 0.020039\n"
     ]
    }
   ],
   "source": [
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is: 0.972600\n"
     ]
    }
   ],
   "source": [
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model.predict(data_loader.test_data[start_index: end_index])\n",
    "    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index],y_pred=y_pred)\n",
    "print(\"test accuracy is: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.applications有预设好的经典卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNetV2 = tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 0.097656\n",
      "batch 1: loss 0.024151\n",
      "batch 2: loss 0.060104\n",
      "batch 3: loss 0.061753\n",
      "batch 4: loss 0.032853\n",
      "batch 5: loss 0.035715\n",
      "batch 6: loss 0.057404\n",
      "batch 7: loss 0.015279\n",
      "batch 8: loss 0.016809\n",
      "batch 9: loss 0.030208\n",
      "batch 10: loss 0.019344\n",
      "batch 11: loss 0.022033\n",
      "batch 12: loss 0.035137\n",
      "batch 13: loss 0.063398\n",
      "batch 14: loss 0.006787\n",
      "batch 15: loss 0.019287\n",
      "batch 16: loss 0.016559\n",
      "batch 17: loss 0.046116\n",
      "batch 18: loss 0.082925\n",
      "batch 19: loss 0.069273\n",
      "batch 20: loss 0.054044\n",
      "batch 21: loss 0.028652\n",
      "batch 22: loss 0.011470\n",
      "batch 23: loss 0.083892\n",
      "batch 24: loss 0.018970\n",
      "batch 25: loss 0.174090\n",
      "batch 26: loss 0.066221\n",
      "batch 27: loss 0.014929\n",
      "batch 28: loss 0.020009\n",
      "batch 29: loss 0.018535\n",
      "batch 30: loss 0.153087\n",
      "batch 31: loss 0.038780\n",
      "batch 32: loss 0.036895\n",
      "batch 33: loss 0.018429\n",
      "batch 34: loss 0.105709\n",
      "batch 35: loss 0.047600\n",
      "batch 36: loss 0.080029\n",
      "batch 37: loss 0.007364\n",
      "batch 38: loss 0.007831\n",
      "batch 39: loss 0.012204\n",
      "batch 40: loss 0.013503\n",
      "batch 41: loss 0.009332\n",
      "batch 42: loss 0.087288\n",
      "batch 43: loss 0.196942\n",
      "batch 44: loss 0.144867\n",
      "batch 45: loss 0.017707\n",
      "batch 46: loss 0.007735\n",
      "batch 47: loss 0.056385\n",
      "batch 48: loss 0.004778\n",
      "batch 49: loss 0.040609\n",
      "batch 50: loss 0.011754\n",
      "batch 51: loss 0.313179\n",
      "batch 52: loss 0.043760\n",
      "batch 53: loss 0.048513\n",
      "batch 54: loss 0.036086\n",
      "batch 55: loss 0.027780\n",
      "batch 56: loss 0.045266\n",
      "batch 57: loss 0.032044\n",
      "batch 58: loss 0.147869\n",
      "batch 59: loss 0.069627\n",
      "batch 60: loss 0.059354\n",
      "batch 61: loss 0.050804\n",
      "batch 62: loss 0.149659\n",
      "batch 63: loss 0.038926\n",
      "batch 64: loss 0.013456\n",
      "batch 65: loss 0.033627\n",
      "batch 66: loss 0.016429\n",
      "batch 67: loss 0.014267\n",
      "batch 68: loss 0.128147\n",
      "batch 69: loss 0.043894\n",
      "batch 70: loss 0.014529\n",
      "batch 71: loss 0.205091\n",
      "batch 72: loss 0.104350\n",
      "batch 73: loss 0.021645\n",
      "batch 74: loss 0.024314\n",
      "batch 75: loss 0.014276\n",
      "batch 76: loss 0.039079\n",
      "batch 77: loss 0.018356\n",
      "batch 78: loss 0.005735\n",
      "batch 79: loss 0.165470\n",
      "batch 80: loss 0.054150\n",
      "batch 81: loss 0.023941\n",
      "batch 82: loss 0.065104\n",
      "batch 83: loss 0.088532\n",
      "batch 84: loss 0.025761\n",
      "batch 85: loss 0.085696\n",
      "batch 86: loss 0.067225\n",
      "batch 87: loss 0.074604\n",
      "batch 88: loss 0.210473\n",
      "batch 89: loss 0.152582\n",
      "batch 90: loss 0.011071\n",
      "batch 91: loss 0.031479\n",
      "batch 92: loss 0.013654\n",
      "batch 93: loss 0.021219\n",
      "batch 94: loss 0.045613\n",
      "batch 95: loss 0.015877\n",
      "batch 96: loss 0.087392\n",
      "batch 97: loss 0.087186\n",
      "batch 98: loss 0.011922\n",
      "batch 99: loss 0.022589\n",
      "batch 100: loss 0.009344\n",
      "batch 101: loss 0.139286\n",
      "batch 102: loss 0.003866\n",
      "batch 103: loss 0.013815\n",
      "batch 104: loss 0.057682\n",
      "batch 105: loss 0.023964\n",
      "batch 106: loss 0.007908\n",
      "batch 107: loss 0.008253\n",
      "batch 108: loss 0.110545\n",
      "batch 109: loss 0.123780\n",
      "batch 110: loss 0.020926\n",
      "batch 111: loss 0.064397\n",
      "batch 112: loss 0.008827\n",
      "batch 113: loss 0.185526\n",
      "batch 114: loss 0.158335\n",
      "batch 115: loss 0.023364\n",
      "batch 116: loss 0.037208\n",
      "batch 117: loss 0.073840\n",
      "batch 118: loss 0.010315\n",
      "batch 119: loss 0.058106\n",
      "batch 120: loss 0.080061\n",
      "batch 121: loss 0.025435\n",
      "batch 122: loss 0.048183\n",
      "batch 123: loss 0.002544\n",
      "batch 124: loss 0.073064\n",
      "batch 125: loss 0.016216\n",
      "batch 126: loss 0.053500\n",
      "batch 127: loss 0.044780\n",
      "batch 128: loss 0.029706\n",
      "batch 129: loss 0.033378\n",
      "batch 130: loss 0.015040\n",
      "batch 131: loss 0.024386\n",
      "batch 132: loss 0.028628\n",
      "batch 133: loss 0.004773\n",
      "batch 134: loss 0.037010\n",
      "batch 135: loss 0.067650\n",
      "batch 136: loss 0.125958\n",
      "batch 137: loss 0.024653\n",
      "batch 138: loss 0.021371\n",
      "batch 139: loss 0.070573\n",
      "batch 140: loss 0.023722\n",
      "batch 141: loss 0.008308\n",
      "batch 142: loss 0.015830\n",
      "batch 143: loss 0.009920\n",
      "batch 144: loss 0.023292\n",
      "batch 145: loss 0.028504\n",
      "batch 146: loss 0.012296\n",
      "batch 147: loss 0.179578\n",
      "batch 148: loss 0.026635\n",
      "batch 149: loss 0.035106\n",
      "batch 150: loss 0.027390\n",
      "batch 151: loss 0.017616\n",
      "batch 152: loss 0.024916\n",
      "batch 153: loss 0.013071\n",
      "batch 154: loss 0.020591\n",
      "batch 155: loss 0.083132\n",
      "batch 156: loss 0.059941\n",
      "batch 157: loss 0.005239\n",
      "batch 158: loss 0.012016\n",
      "batch 159: loss 0.011812\n",
      "batch 160: loss 0.087612\n",
      "batch 161: loss 0.061760\n",
      "batch 162: loss 0.017652\n",
      "batch 163: loss 0.021559\n",
      "batch 164: loss 0.064631\n",
      "batch 165: loss 0.013058\n",
      "batch 166: loss 0.015538\n",
      "batch 167: loss 0.012055\n",
      "batch 168: loss 0.019171\n",
      "batch 169: loss 0.022563\n",
      "batch 170: loss 0.088239\n",
      "batch 171: loss 0.014075\n",
      "batch 172: loss 0.024972\n",
      "batch 173: loss 0.112817\n",
      "batch 174: loss 0.007410\n",
      "batch 175: loss 0.027558\n",
      "batch 176: loss 0.057940\n",
      "batch 177: loss 0.013097\n",
      "batch 178: loss 0.016551\n",
      "batch 179: loss 0.034843\n",
      "batch 180: loss 0.043043\n",
      "batch 181: loss 0.084481\n",
      "batch 182: loss 0.003683\n",
      "batch 183: loss 0.219194\n",
      "batch 184: loss 0.031616\n",
      "batch 185: loss 0.065881\n",
      "batch 186: loss 0.030203\n",
      "batch 187: loss 0.024939\n",
      "batch 188: loss 0.033066\n",
      "batch 189: loss 0.035721\n",
      "batch 190: loss 0.016802\n",
      "batch 191: loss 0.011646\n",
      "batch 192: loss 0.024925\n",
      "batch 193: loss 0.033257\n",
      "batch 194: loss 0.005252\n",
      "batch 195: loss 0.026476\n",
      "batch 196: loss 0.186446\n",
      "batch 197: loss 0.018745\n",
      "batch 198: loss 0.006977\n",
      "batch 199: loss 0.087840\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is: 0.972500\n"
     ]
    }
   ],
   "source": [
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model.predict(data_loader.test_data[start_index: end_index])\n",
    "    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index],y_pred=y_pred)\n",
    "print(\"test accuracy is: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        path = tf.keras.utils.get_file('nietzsche.txt',\n",
    "            origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            self.raw_text = f.read().lower()\n",
    "        self.chars = sorted(list(set(self.raw_text)))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        self.text = [self.char_indices[c] for c in self.raw_text]\n",
    "\n",
    "    def get_batch(self, seq_length, batch_size):\n",
    "        seq = []\n",
    "        next_char = []\n",
    "        for i in range(batch_size):\n",
    "            index = np.random.randint(0, len(self.text) - seq_length)\n",
    "            seq.append(self.text[index:index+seq_length])\n",
    "            next_char.append(self.text[index+seq_length])\n",
    "        return np.array(seq), np.array(next_char)       # [batch_size, seq_length], [num_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(tf.keras.Model):\n",
    "    def __init__(self, num_chars, batch_size, seq_length):\n",
    "        super().__init__()\n",
    "        self.num_chars = num_chars\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.cell = tf.keras.layers.LSTMCell(units=256)\n",
    "        self.dense = tf.keras.layers.Dense(units=self.num_chars)\n",
    "\n",
    "    def call(self, inputs, from_logits=False):\n",
    "        inputs = tf.one_hot(inputs, depth=self.num_chars)       # [batch_size, seq_length, num_chars]\n",
    "        state = self.cell.get_initial_state(batch_size=self.batch_size, dtype=tf.float32)\n",
    "        for t in range(self.seq_length):\n",
    "            output, state = self.cell(inputs[:, t, :], state)\n",
    "        logits = self.dense(output)\n",
    "        if from_logits:\n",
    "            return logits\n",
    "        else:\n",
    "            return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 100\n",
    "seq_length = 40\n",
    "batch_size = 50\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps:\n",
    "* randomly select data from `DataLoader`\n",
    "* calculate the predict value\n",
    "* calculate the loss function\n",
    "* calculate the dirivertive of the function. `tape.gradient`\n",
    "* `optimizer.apply_gradients` to update the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(num_chars=len(data_loader.chars), batch_size=batch_size, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 2.300979\n",
      "batch 1: loss 2.425753\n",
      "batch 2: loss 2.269445\n",
      "batch 3: loss 2.435592\n",
      "batch 4: loss 2.547582\n",
      "batch 5: loss 2.410161\n",
      "batch 6: loss 2.166223\n",
      "batch 7: loss 2.303907\n",
      "batch 8: loss 2.346618\n",
      "batch 9: loss 2.537049\n",
      "batch 10: loss 2.499943\n",
      "batch 11: loss 2.077685\n",
      "batch 12: loss 2.248216\n",
      "batch 13: loss 2.012670\n",
      "batch 14: loss 2.319809\n",
      "batch 15: loss 2.266413\n",
      "batch 16: loss 2.519976\n",
      "batch 17: loss 2.334644\n",
      "batch 18: loss 2.093357\n",
      "batch 19: loss 2.661996\n",
      "batch 20: loss 1.888312\n",
      "batch 21: loss 2.135050\n",
      "batch 22: loss 2.407631\n",
      "batch 23: loss 2.454175\n",
      "batch 24: loss 2.599524\n",
      "batch 25: loss 2.216748\n",
      "batch 26: loss 2.301447\n",
      "batch 27: loss 2.187305\n",
      "batch 28: loss 2.659596\n",
      "batch 29: loss 2.703160\n",
      "batch 30: loss 2.532776\n",
      "batch 31: loss 2.870480\n",
      "batch 32: loss 2.358199\n",
      "batch 33: loss 2.418718\n",
      "batch 34: loss 2.341374\n",
      "batch 35: loss 1.977418\n",
      "batch 36: loss 2.228302\n",
      "batch 37: loss 2.138907\n",
      "batch 38: loss 2.348046\n",
      "batch 39: loss 2.205188\n",
      "batch 40: loss 2.309159\n",
      "batch 41: loss 2.554825\n",
      "batch 42: loss 2.431189\n",
      "batch 43: loss 2.336750\n",
      "batch 44: loss 2.352017\n",
      "batch 45: loss 2.558008\n",
      "batch 46: loss 2.602825\n",
      "batch 47: loss 2.172488\n",
      "batch 48: loss 2.416368\n",
      "batch 49: loss 2.781678\n",
      "batch 50: loss 2.456343\n",
      "batch 51: loss 2.410509\n",
      "batch 52: loss 2.677808\n",
      "batch 53: loss 2.285848\n",
      "batch 54: loss 2.572879\n",
      "batch 55: loss 2.000528\n",
      "batch 56: loss 2.286259\n",
      "batch 57: loss 2.471130\n",
      "batch 58: loss 2.028175\n",
      "batch 59: loss 2.419409\n",
      "batch 60: loss 2.445923\n",
      "batch 61: loss 2.542719\n",
      "batch 62: loss 2.582991\n",
      "batch 63: loss 2.393735\n",
      "batch 64: loss 2.362523\n",
      "batch 65: loss 2.491625\n",
      "batch 66: loss 2.255546\n",
      "batch 67: loss 2.301741\n",
      "batch 68: loss 2.592161\n",
      "batch 69: loss 2.162047\n",
      "batch 70: loss 2.485293\n",
      "batch 71: loss 2.264264\n",
      "batch 72: loss 2.198246\n",
      "batch 73: loss 2.229640\n",
      "batch 74: loss 2.463139\n",
      "batch 75: loss 2.498099\n",
      "batch 76: loss 2.669433\n",
      "batch 77: loss 2.731086\n",
      "batch 78: loss 2.174956\n",
      "batch 79: loss 2.407752\n",
      "batch 80: loss 2.387315\n",
      "batch 81: loss 2.650808\n",
      "batch 82: loss 2.813378\n",
      "batch 83: loss 2.431571\n",
      "batch 84: loss 2.278954\n",
      "batch 85: loss 1.993178\n",
      "batch 86: loss 2.554437\n",
      "batch 87: loss 2.454825\n",
      "batch 88: loss 2.211303\n",
      "batch 89: loss 2.240351\n",
      "batch 90: loss 2.352852\n",
      "batch 91: loss 2.350999\n",
      "batch 92: loss 2.349697\n",
      "batch 93: loss 2.124092\n",
      "batch 94: loss 2.483489\n",
      "batch 95: loss 2.335853\n",
      "batch 96: loss 2.293109\n",
      "batch 97: loss 2.491374\n",
      "batch 98: loss 2.532936\n",
      "batch 99: loss 2.183427\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(seq_length, batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = modelRNN(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_pred=y_pred, y_true=y)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, modelRNN.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, modelRNN.variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于文本生成的过程有一点需要特别注意。之前，我们一直使用 tf.argmax() 函数，将对应概率最大的值作为预测值。然而对于文本生成而言，这样的预测方式过于绝对，会使得生成的文本失去丰富性。于是，我们使用 np.random.choice() 函数按照生成的概率分布取样。这样，即使是对应概率较小的字符，也有机会被取样到。同时，我们加入一个 temperature 参数控制分布的形状，参数值越大则分布越平缓（最大值和最小值的差值越小），生成文本的丰富度越高；参数值越小则分布越陡峭，生成文本的丰富度越低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, inputs, temperature=1.):\n",
    "    batch_size, _ = tf.shape(inputs)\n",
    "    logits = self(inputs, from_logits=True)\n",
    "    prob = tf.nn.softmax(logits / temperature).numpy()\n",
    "    return np.array([np.random.choice(self.num_chars, p=prob[i,:]) \n",
    "                     for i in range(batch_size.numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_, _ = data_loader.get_batch(seq_length, 1)\n",
    "# for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "#     X = X_\n",
    "#     print(\"diversity %f:\" % diversity)\n",
    "#     for t in range(400):\n",
    "#         y_pred = modelRNN.predict(X, diversity)\n",
    "#         print(data_loader.indices_char[y_pred[0]], end='', flush=True)\n",
    "#         X = np.concatenate([X[:, 1:], np.expand_dims(y_pred, axis=1)], axis=-1)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement Learning RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
